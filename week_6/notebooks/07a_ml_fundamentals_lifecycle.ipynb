{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** · *Intermediate AI & Data Science*\n",
    "### Week 7 - Notebook 01: ML Fundamentals & The ML Lifecycle\n",
    "**Instructor:** Amir Charkhi |  **Goal:** Understanding Machine Learning Foundations\n",
    "\n",
    "> Format: theory → implementation → best practices → real-world application.\n",
    "\n",
    "## Welcome to Machine Learning! 🎯\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what machine learning is and when to use it\n",
    "- Learn the complete ML lifecycle that you'll use for every project\n",
    "- Distinguish between classification and regression problems\n",
    "- Master train/test split - the foundation of all ML\n",
    "- Build your first ML model end-to-end\n",
    "- Establish a framework you'll use for Weeks 7-12\n",
    "\n",
    "**Prerequisites:** Python, pandas, data visualization basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤔 What Exactly is Machine Learning?\n",
    "\n",
    "Let's start with the big picture. You've spent Phase 1 learning to:\n",
    "- Clean data (Pandas)\n",
    "- Visualize patterns (Plotly, dashboards)\n",
    "- Query databases (SQL)\n",
    "- Understand causality (A/B testing)\n",
    "\n",
    "**Machine Learning is the next step**: Teaching computers to find patterns and make predictions.\n",
    "\n",
    "### Traditional Programming vs Machine Learning\n",
    "\n",
    "**Traditional Programming:**\n",
    "```\n",
    "Rules + Data → Output\n",
    "```\n",
    "Example: \"If temperature > 30°C, send 'It's hot' alert\"\n",
    "\n",
    "**Machine Learning:**\n",
    "```\n",
    "Data + Output → Rules (learned automatically)\n",
    "```\n",
    "Example: \"Here's 10,000 images of cats and dogs. Learn to distinguish them yourself.\"\n",
    "\n",
    "### When to Use ML vs Traditional Analysis\n",
    "\n",
    "**Use ML when:**\n",
    "- ✅ The rules are too complex to code manually\n",
    "- ✅ You need predictions (\"What will happen?\")\n",
    "- ✅ Patterns exist in data but aren't obvious\n",
    "- ✅ You have enough historical data\n",
    "\n",
    "**Don't use ML when:**\n",
    "- ❌ Simple rules work fine (don't use ML to check if a number is even)\n",
    "- ❌ You need to understand WHY (ML is often a black box)\n",
    "- ❌ You have too little data (< 100 samples)\n",
    "- ❌ The stakes are too high without explainability (medical diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for this week\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"📚 Library Guide for Week 7:\")\n",
    "print(\"\")\n",
    "print(\"1. scikit-learn (sklearn): The #1 ML library in Python\")\n",
    "print(\"   - Consistent API for all algorithms\")\n",
    "print(\"   - Built-in datasets for learning\")\n",
    "print(\"   - Comprehensive evaluation tools\")\n",
    "print(\"\")\n",
    "print(\"2. Key sklearn modules we'll use:\")\n",
    "print(\"   - model_selection: Split data, cross-validation\")\n",
    "print(\"   - linear_model: Linear/Logistic regression\")\n",
    "print(\"   - tree: Decision trees\")\n",
    "print(\"   - metrics: Evaluate model performance\")\n",
    "print(\"\")\n",
    "print(\"✅ All libraries loaded and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 The Two Main Types of ML Problems\n",
    "\n",
    "Before we dive into the lifecycle, you need to know what type of problem you're solving.\n",
    "\n",
    "### 1. Classification: Predicting Categories\n",
    "\n",
    "**Question format:** \"Which group does this belong to?\"\n",
    "\n",
    "**Examples:**\n",
    "- Is this email spam or not spam? (Binary classification)\n",
    "- Will this customer churn? (Binary: Yes/No)\n",
    "- What species is this flower? (Multi-class: setosa/versicolor/virginica)\n",
    "- Which product category? (Multi-class: electronics/clothing/food)\n",
    "\n",
    "**Output:** Discrete categories (labels)\n",
    "\n",
    "### 2. Regression: Predicting Numbers\n",
    "\n",
    "**Question format:** \"What's the value?\"\n",
    "\n",
    "**Examples:**\n",
    "- What will the house price be? (Continuous number: $450,000)\n",
    "- How much revenue next month? (Continuous: $1.2M)\n",
    "- What's the temperature tomorrow? (Continuous: 23.5°C)\n",
    "- Customer lifetime value? (Continuous: $2,340)\n",
    "\n",
    "**Output:** Continuous numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the difference\n",
    "print(\"🎨 VISUALIZING CLASSIFICATION vs REGRESSION\\n\")\n",
    "\n",
    "# Create sample data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Classification example: Iris dataset\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# Regression example: Simple house price simulation\n",
    "size_sqft = np.random.uniform(800, 3000, 100)\n",
    "price = 200 * size_sqft + np.random.normal(0, 50000, 100)\n",
    "house_df = pd.DataFrame({'size_sqft': size_sqft, 'price': price})\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Classification plot\n",
    "for species in iris_df['species_name'].unique():\n",
    "    subset = iris_df[iris_df['species_name'] == species]\n",
    "    axes[0].scatter(subset['petal length (cm)'], subset['petal width (cm)'], \n",
    "                    label=species, s=100, alpha=0.6)\n",
    "axes[0].set_xlabel('Petal Length (cm)', fontsize=12)\n",
    "axes[0].set_ylabel('Petal Width (cm)', fontsize=12)\n",
    "axes[0].set_title('CLASSIFICATION: Predict Discrete Categories\\n(Iris Species)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Regression plot\n",
    "axes[1].scatter(house_df['size_sqft'], house_df['price'], alpha=0.6, s=100, color='coral')\n",
    "z = np.polyfit(house_df['size_sqft'], house_df['price'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1].plot(house_df['size_sqft'], p(house_df['size_sqft']), \"r--\", linewidth=2, label='Trend line')\n",
    "axes[1].set_xlabel('House Size (sqft)', fontsize=12)\n",
    "axes[1].set_ylabel('Price ($)', fontsize=12)\n",
    "axes[1].set_title('REGRESSION: Predict Continuous Values\\n(House Prices)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 Key Insight:\")\n",
    "print(\"  LEFT: Classification → Predicting which colored group a point belongs to\")\n",
    "print(\"  RIGHT: Regression → Predicting the exact y-value on the line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔄 The Complete ML Lifecycle\n",
    "\n",
    "This is your framework for EVERY ML project. Memorize this!\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│              THE ML PROJECT LIFECYCLE                   │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "\n",
    "1. 📊 UNDERSTAND THE PROBLEM\n",
    "   ↓ What are we trying to predict? Why?\n",
    "   \n",
    "2. 📁 COLLECT & PREPARE DATA\n",
    "   ↓ Get data, clean it, handle missing values\n",
    "   \n",
    "3. 🔍 EXPLORATORY DATA ANALYSIS (EDA)\n",
    "   ↓ Visualize, find patterns, understand distributions\n",
    "   \n",
    "4. 🛠️ FEATURE ENGINEERING\n",
    "   ↓ Create new features, encode categories, scale data\n",
    "   \n",
    "5. ✂️ SPLIT DATA (Train/Validation/Test)\n",
    "   ↓ CRITICAL: Never touch test set until the end!\n",
    "   \n",
    "6. 🤖 BUILD MODELS\n",
    "   ↓ Try different algorithms (linear, tree-based, etc.)\n",
    "   \n",
    "7. ⚙️ TUNE HYPERPARAMETERS\n",
    "   ↓ Optimize model settings for best performance\n",
    "   \n",
    "8. 📊 EVALUATE & COMPARE\n",
    "   ↓ Use metrics to find the best model\n",
    "   \n",
    "9. 🎯 FINAL EVALUATION (Test Set)\n",
    "   ↓ Get unbiased performance estimate\n",
    "   \n",
    "10. 🚀 DEPLOY & MONITOR\n",
    "    ↓ Put model in production, track performance over time\n",
    "```\n",
    "\n",
    "### Why This Order Matters\n",
    "\n",
    "**Common mistakes:**\n",
    "- ❌ Jumping straight to modeling without EDA\n",
    "- ❌ Not splitting data properly (data leakage!)\n",
    "- ❌ Testing on training data (overly optimistic results)\n",
    "- ❌ Touching test set multiple times\n",
    "\n",
    "**We'll focus on steps 5-9 this week**, assuming you already know steps 1-4 from Phase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✂️ The Foundation: Train/Test Split\n",
    "\n",
    "This is THE MOST IMPORTANT concept in ML. Get this wrong, and everything else fails.\n",
    "\n",
    "### Why We Need Train/Test Split\n",
    "\n",
    "**The Problem:**\n",
    "If I give you the answers before a test, you'll ace it. But did you really learn?\n",
    "\n",
    "**In ML:**\n",
    "- If we train AND test on the same data, models will look amazing\n",
    "- But they'll fail miserably on new, unseen data\n",
    "- This is called **OVERFITTING** - memorizing instead of learning\n",
    "\n",
    "### The Solution: Data Splitting\n",
    "\n",
    "```\n",
    "Your Complete Dataset (100%)\n",
    "        |\n",
    "        ├─── Training Set (70-80%)\n",
    "        |    → Model learns patterns from this\n",
    "        |    → Adjust model based on this data\n",
    "        |\n",
    "        ├─── Validation Set (10-15%) [Optional but recommended]\n",
    "        |    → Tune hyperparameters\n",
    "        |    → Compare different models\n",
    "        |    → Can use multiple times\n",
    "        |\n",
    "        └─── Test Set (10-15%)\n",
    "             → NEVER TOUCH until the very end!\n",
    "             → Final, unbiased performance check\n",
    "             → Use ONLY ONCE\n",
    "```\n",
    "\n",
    "### Critical Rules:\n",
    "\n",
    "1. **Split BEFORE any analysis** (to avoid data leakage)\n",
    "2. **Test set = vault** (locked until final evaluation)\n",
    "3. **Random splitting** (to avoid bias)\n",
    "4. **Same seed** (for reproducibility)\n",
    "5. **Stratified split** (for classification, to keep class balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✂️ TRAIN/TEST SPLIT - PRACTICAL IMPLEMENTATION\\n\")\n",
    "\n",
    "# Load a simple dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "print(f\"📊 Dataset Info:\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Features: {X.shape[1]} ({list(X.columns)})\")\n",
    "print(f\"   Target variable: {y.name}\")\n",
    "print(f\"   Classes: {np.unique(y)}\")\n",
    "print()\n",
    "\n",
    "# Method 1: Simple train/test split (80/20)\n",
    "print(\"Method 1: Simple 80/20 Split\")\n",
    "print(\"=\"*50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,        # 20% for testing\n",
    "    random_state=42       # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"✅ Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"✅ Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print()\n",
    "\n",
    "# Method 2: Stratified split (recommended for classification)\n",
    "print(\"Method 2: Stratified Split (BETTER for classification)\")\n",
    "print(\"=\"*50)\n",
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y            # Maintains class proportions!\n",
    ")\n",
    "\n",
    "# Compare class distributions\n",
    "print(\"\\n📊 Class Distribution Comparison:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Original': y.value_counts(normalize=True).sort_index(),\n",
    "    'Simple Split (Train)': y_train.value_counts(normalize=True).sort_index(),\n",
    "    'Stratified Split (Train)': y_train_strat.value_counts(normalize=True).sort_index()\n",
    "})\n",
    "print(comparison_df)\n",
    "\n",
    "print(\"\\n💡 Key Insight:\")\n",
    "print(\"   Stratified split preserves class proportions better!\")\n",
    "print(\"   This is especially important for imbalanced datasets.\")\n",
    "\n",
    "# Visualize the split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Simple split\n",
    "y_train.value_counts().plot(kind='bar', ax=axes[0], color='skyblue', alpha=0.7)\n",
    "axes[0].set_title('Simple Train/Test Split\\n(Class Counts in Training Set)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Setosa', 'Versicolor', 'Virginica'], rotation=0)\n",
    "\n",
    "# Plot 2: Stratified split\n",
    "y_train_strat.value_counts().plot(kind='bar', ax=axes[1], color='coral', alpha=0.7)\n",
    "axes[1].set_title('Stratified Train/Test Split\\n(Class Counts in Training Set)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticklabels(['Setosa', 'Versicolor', 'Virginica'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 Remember: Use stratified split for classification problems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🚀 Your First End-to-End ML Project\n",
    "\n",
    "Let's put everything together and build a complete ML pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Understanding the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 PROJECT: Iris Species Classification\\n\")\n",
    "print(\"Problem: Given flower measurements, predict the species\")\n",
    "print(\"Type: Multi-class classification (3 species)\")\n",
    "print(\"Why it matters: Foundation for plant identification systems\")\n",
    "print(\"\\nLet's follow the ML lifecycle!\\n\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 STEP 2: DATA EXPLORATION\\n\")\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\\n\")\n",
    "\n",
    "# Quick EDA\n",
    "print(\"Basic statistics:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(X.columns):\n",
    "    for species in [0, 1, 2]:\n",
    "        data = X[y == species][col]\n",
    "        axes[i].hist(data, alpha=0.5, bins=15, \n",
    "                    label=iris.target_names[species])\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ EDA complete: Features look reasonable, no obvious outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✂️ STEP 3: TRAIN/TEST SPLIT\\n\")\n",
    "\n",
    "# Split the data (stratified for classification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\n✅ Data split complete. Test set locked away!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🤖 STEP 4: BUILD MODEL\\n\")\n",
    "\n",
    "# Create a model - we'll use Logistic Regression\n",
    "# (Don't worry about the algorithm details yet - we'll cover this in Week 8)\n",
    "model = LogisticRegression(max_iter=200, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Model trained!\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(f\"\\nThe model has learned patterns from {len(X_train)} training examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔮 STEP 5: MAKE PREDICTIONS\\n\")\n",
    "\n",
    "# Make predictions on training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Sample predictions on test set:\")\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test[:10],\n",
    "    'Predicted': y_test_pred[:10]\n",
    "})\n",
    "results_df['Correct'] = results_df['Actual'] == results_df['Predicted']\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n✅ Predictions made!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 STEP 6: EVALUATE MODEL\\n\")\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "accuracies = [train_accuracy, test_accuracy]\n",
    "labels = ['Training\\nAccuracy', 'Test\\nAccuracy']\n",
    "colors = ['skyblue', 'coral']\n",
    "axes[0].bar(labels, accuracies, color=colors, alpha=0.7, width=0.5)\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Performance', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "# Prediction distribution\n",
    "prediction_counts = pd.Series(y_test_pred).value_counts().sort_index()\n",
    "actual_counts = y_test.value_counts().sort_index()\n",
    "x = np.arange(len(prediction_counts))\n",
    "width = 0.35\n",
    "axes[1].bar(x - width/2, actual_counts, width, label='Actual', alpha=0.7, color='skyblue')\n",
    "axes[1].bar(x + width/2, prediction_counts, width, label='Predicted', alpha=0.7, color='coral')\n",
    "axes[1].set_xlabel('Species', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Actual vs Predicted Counts', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(['Setosa', 'Versicolor', 'Virginica'])\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Evaluation complete!\")\n",
    "print(\"\\n💡 Key Insights:\")\n",
    "if train_accuracy - test_accuracy < 0.05:\n",
    "    print(\"   ✅ Train and test accuracy are similar - good generalization!\")\n",
    "elif train_accuracy - test_accuracy > 0.15:\n",
    "    print(\"   ⚠️ Train accuracy much higher than test - possible overfitting!\")\n",
    "    \n",
    "if test_accuracy > 0.9:\n",
    "    print(f\"   ✅ {test_accuracy:.1%} test accuracy is excellent!\")\n",
    "elif test_accuracy > 0.7:\n",
    "    print(f\"   ✅ {test_accuracy:.1%} test accuracy is good!\")\n",
    "else:\n",
    "    print(f\"   ⚠️ {test_accuracy:.1%} test accuracy - room for improvement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🌟 STEP 7: INFERENCE (Making Predictions on New Data)\\n\")\n",
    "\n",
    "# Simulate new flower measurements\n",
    "new_flowers = pd.DataFrame({\n",
    "    'sepal length (cm)': [5.1, 6.5, 7.0],\n",
    "    'sepal width (cm)': [3.5, 3.0, 3.2],\n",
    "    'petal length (cm)': [1.4, 5.5, 4.7],\n",
    "    'petal width (cm)': [0.2, 1.8, 1.4]\n",
    "})\n",
    "\n",
    "print(\"New flower measurements:\")\n",
    "print(new_flowers)\n",
    "print()\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_flowers)\n",
    "prediction_proba = model.predict_proba(new_flowers)\n",
    "\n",
    "# Show results\n",
    "species_names = ['setosa', 'versicolor', 'virginica']\n",
    "print(\"Predictions:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"\\nFlower {i+1}:\")\n",
    "    print(f\"  Predicted species: {species_names[pred]}\")\n",
    "    print(f\"  Confidence:\")\n",
    "    for j, prob in enumerate(prediction_proba[i]):\n",
    "        print(f\"    {species_names[j]}: {prob:.1%}\")\n",
    "\n",
    "print(\"\\n✅ Model is now ready for production inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎓 Key Takeaways\n",
    "\n",
    "Congratulations! You've completed your first ML project! Here's what you learned:\n",
    "\n",
    "### Core Concepts:\n",
    "1. **ML Definition**: Teaching computers to find patterns and make predictions\n",
    "2. **Two Problem Types**: Classification (categories) vs Regression (numbers)\n",
    "3. **ML Lifecycle**: The 10-step framework you'll use for every project\n",
    "4. **Train/Test Split**: THE foundational concept preventing overfitting\n",
    "5. **Stratification**: Preserving class balance in classification problems\n",
    "\n",
    "### The sklearn API Pattern:\n",
    "You'll use this pattern for EVERY model in Weeks 7-12:\n",
    "```python\n",
    "# 1. Create model\n",
    "model = SomeAlgorithm()\n",
    "\n",
    "# 2. Train (fit)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate\n",
    "score = some_metric(y_test, predictions)\n",
    "```\n",
    "\n",
    "### Critical Rules:\n",
    "- ✅ Always split data BEFORE any analysis\n",
    "- ✅ Use stratified split for classification\n",
    "- ✅ Test set = sacred vault (use only once!)\n",
    "- ✅ Train accuracy > Test accuracy is normal\n",
    "- ✅ If gap is huge → overfitting!\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "You now have the foundation! Next up:\n",
    "\n",
    "1. **Notebook 02**: Deep dive into evaluation metrics (accuracy, precision, recall, F1, ROC-AUC, MSE, R²)\n",
    "2. **Notebook 03**: Cross-validation and proper model selection\n",
    "\n",
    "Then in Weeks 8-12, you'll learn different algorithms:\n",
    "- Week 8: Linear Models, Tree-Based Methods\n",
    "- Week 9: Advanced ML & MLOps\n",
    "- Week 10: Time Series\n",
    "- Week 11: Unsupervised Learning\n",
    "- Week 12: Network Analysis\n",
    "\n",
    "**The framework you learned today applies to ALL of them!** 🎯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 Congratulations! You've completed Notebook 01!\")\n",
    "print(\"\")\n",
    "print(\"📚 You learned:\")\n",
    "print(\"   ✅ What ML is and when to use it\")\n",
    "print(\"   ✅ Classification vs Regression\")\n",
    "print(\"   ✅ The complete ML lifecycle\")\n",
    "print(\"   ✅ Train/test split mastery\")\n",
    "print(\"   ✅ Built your first ML model!\")\n",
    "print(\"\")\n",
    "print(\"🎯 Next: Notebook 02 - Model Evaluation Metrics\")\n",
    "print(\"   Learn how to properly evaluate and compare models!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
