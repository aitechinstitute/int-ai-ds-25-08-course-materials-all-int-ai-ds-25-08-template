{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** · *Intermediate AI & Data Science*\n",
    "### Week 04 · Notebook 01 — Introduction to Statistics\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Build foundation in statistical thinking for AI & data science.\n",
    "\n",
    "> Format: short theory → quick practice → build understanding → mini-challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Distinguish between descriptive and inferential statistics\n",
    "- Set up Python environment for statistical analysis\n",
    "- Apply basic statistical concepts to real data\n",
    "- Understand statistics' role in AI and machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Statistics?\n",
    "Statistics is the science of **collecting, organizing, analyzing, and interpreting** data to make informed decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries for statistical analysis\n",
    "import numpy as np              # Numerical operations\n",
    "import pandas as pd             # Data manipulation\n",
    "import matplotlib.pyplot as plt # Basic plotting\n",
    "import seaborn as sns          # Statistical visualization\n",
    "from scipy import stats        # Statistical functions\n",
    "\n",
    "# Set style for nice plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world example: Daily app downloads\n",
    "app_downloads = [1250, 1180, 1320, 1450, 1380, 1100, 980]\n",
    "\n",
    "print(\"📱 Daily App Downloads (Week 1):\")\n",
    "print(app_downloads)\n",
    "print(f\"\\nQuick insights:\")\n",
    "print(f\"Average: {np.mean(app_downloads):.0f} downloads/day\")\n",
    "print(f\"Best day: {max(app_downloads)} downloads\")\n",
    "print(f\"Worst day: {min(app_downloads)} downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Two Types of Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Descriptive Statistics\n",
    "**What happened?** - Summarizes and describes data you already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer satisfaction scores (1-10 scale)\n",
    "satisfaction = [8, 9, 7, 8, 9, 6, 8, 9, 7, 8]\n",
    "\n",
    "print(\"📊 Customer Satisfaction Analysis:\")\n",
    "print(f\"Average rating: {np.mean(satisfaction):.1f}/10\")\n",
    "mode_result = stats.mode(satisfaction, keepdims=True)  # ensures result is always array\n",
    "print(f\"Most common rating: {mode_result.mode[0]}/10\")\n",
    "print(f\"Range: {min(satisfaction)} to {max(satisfaction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Inferential Statistics\n",
    "**What will happen?** - Makes predictions about larger populations from samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey sample: 100 customers out of 10,000 total\n",
    "sample_satisfaction = np.random.normal(7.8, 1.2, 100)  # Sample data\n",
    "\n",
    "# Estimate population parameters\n",
    "sample_mean = np.mean(sample_satisfaction)\n",
    "margin_error = 1.96 * (np.std(sample_satisfaction) / np.sqrt(100))\n",
    "\n",
    "print(\"🔮 Population Prediction (from 100-person sample):\")\n",
    "print(f\"Estimated population satisfaction: {sample_mean:.1f}\")\n",
    "print(f\"95% confidence: {sample_mean:.1f} ± {margin_error:.1f}\")\n",
    "print(f\"Prediction for all 10,000 customers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 — Statistics Type Recognition (easy)**  \n",
    "Classify each statement as descriptive or inferential:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "statements = [\n",
    "    \"75% of our customers rated us 8+ last month\",\n",
    "    \"Based on this test, the new algorithm will improve accuracy by 5%\", \n",
    "    \"Average response time was 2.3 seconds yesterday\",\n",
    "    \"This sample suggests 60% of voters support the candidate\"\n",
    "]\n",
    "\n",
    "# Classify each as 'descriptive' or 'inferential'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "classifications = [\n",
    "    \"Descriptive - summarizes past data\",\n",
    "    \"Inferential - predicts future performance\", \n",
    "    \"Descriptive - reports what happened\",\n",
    "    \"Inferential - estimates population from sample\"\n",
    "]\n",
    "\n",
    "for i, (stmt, classification) in enumerate(zip(statements, classifications)):\n",
    "    print(f\"{i+1}. {stmt}\")\n",
    "    print(f\"   → {classification}\\n\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistics in AI & Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Statistics Matters for AI:\n",
    "1. **Model Performance** - Accuracy, precision, recall\n",
    "2. **Data Quality** - Outliers, missing values, distributions\n",
    "3. **Uncertainty** - Confidence in predictions\n",
    "4. **A/B Testing** - Which model performs better?\n",
    "5. **Feature Selection** - Which variables matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Model Performance Example\n",
    "model_accuracies = [0.87, 0.89, 0.85, 0.91, 0.88, 0.90, 0.86]\n",
    "\n",
    "print(\"🤖 AI Model Performance Analysis:\")\n",
    "print(f\"Average accuracy: {np.mean(model_accuracies):.1%}\")\n",
    "print(f\"Standard deviation: {np.std(model_accuracies):.1%}\")\n",
    "print(f\"Model consistency: {'High' if np.std(model_accuracies) < 0.02 else 'Low'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 8), model_accuracies, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axhline(np.mean(model_accuracies), color='red', linestyle='--', \n",
    "           label=f'Average: {np.mean(model_accuracies):.1%}')\n",
    "plt.xlabel('Test Run')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Across Multiple Runs')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. First Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-commerce website data\n",
    "daily_visitors = [1250, 1180, 1320, 1450, 1380, 1100, 980, \n",
    "                 1200, 1290, 1400, 1520, 1350, 1150, 1050]\n",
    "\n",
    "# Calculate key statistics\n",
    "mean_visitors = np.mean(daily_visitors)\n",
    "median_visitors = np.median(daily_visitors)\n",
    "std_visitors = np.std(daily_visitors)\n",
    "\n",
    "print(\"🌐 Website Analytics (2 weeks):\")\n",
    "print(f\"Average daily visitors: {mean_visitors:.0f}\")\n",
    "print(f\"Median daily visitors: {median_visitors:.0f}\")\n",
    "print(f\"Variability (std dev): {std_visitors:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Time series plot\n",
    "ax1.plot(range(1, 15), daily_visitors, 'o-', linewidth=2, markersize=6)\n",
    "ax1.axhline(mean_visitors, color='red', linestyle='--', label='Mean')\n",
    "ax1.set_xlabel('Day')\n",
    "ax1.set_ylabel('Visitors')\n",
    "ax1.set_title('Daily Visitors Over Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution histogram\n",
    "ax2.hist(daily_visitors, bins=8, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.axvline(mean_visitors, color='red', linestyle='--', label=f'Mean: {mean_visitors:.0f}')\n",
    "ax2.axvline(median_visitors, color='green', linestyle='--', label=f'Median: {median_visitors:.0f}')\n",
    "ax2.set_xlabel('Daily Visitors')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Daily Visitors')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 — Website Performance Analysis (medium)**  \n",
    "Analyze conversion rates and identify trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Daily conversions data\n",
    "conversions = [48, 52, 45, 61, 58, 42, 38, 51, 49, 67, 72, 55, 46, 43]\n",
    "visitors = daily_visitors  # Use same visitor data\n",
    "\n",
    "# Calculate conversion rates and analyze\n",
    "# conversion_rates = [conversions[i]/visitors[i] for i in range(len(conversions))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Calculate conversion rates\n",
    "conversion_rates = [conversions[i]/visitors[i] for i in range(len(conversions))]\n",
    "\n",
    "print(\"🎯 Conversion Rate Analysis:\")\n",
    "print(f\"Average conversion rate: {np.mean(conversion_rates):.1%}\")\n",
    "print(f\"Best day: {max(conversion_rates):.1%}\")\n",
    "print(f\"Worst day: {min(conversion_rates):.1%}\")\n",
    "print(f\"Rate variability: {np.std(conversion_rates):.3f}\")\n",
    "\n",
    "# Find correlation between visitors and conversion rate\n",
    "correlation = np.corrcoef(visitors, conversion_rates)[0,1]\n",
    "print(f\"\\nVisitors vs Conv. Rate correlation: {correlation:.3f}\")\n",
    "if correlation < -0.3:\n",
    "    print(\"⚠️ Higher traffic may hurt conversion rate!\")\n",
    "elif correlation > 0.3:\n",
    "    print(\"✅ Higher traffic improves conversion rate!\")\n",
    "else:\n",
    "    print(\"➡️ Traffic and conversion rate seem independent\")\n",
    "\n",
    "# Plot conversion rates\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(1, 15), [r*100 for r in conversion_rates], 'o-', linewidth=2)\n",
    "plt.axhline(np.mean(conversion_rates)*100, color='red', linestyle='--', \n",
    "           label=f'Average: {np.mean(conversion_rates):.1%}')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.title('Daily Conversion Rates')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding Data Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different data patterns\n",
    "np.random.seed(42)\n",
    "\n",
    "# Three different datasets with same mean\n",
    "consistent = [100, 101, 99, 100, 101, 99, 100]  # Low variance\n",
    "variable = [85, 120, 95, 110, 90, 115, 85]      # High variance\n",
    "outlier_data = [100, 100, 99, 101, 100, 99, 150] # Has outlier\n",
    "\n",
    "datasets = [consistent, variable, outlier_data]\n",
    "names = ['Consistent', 'Variable', 'With Outlier']\n",
    "\n",
    "print(\"📈 Comparing Data Patterns:\")\n",
    "for name, data in zip(names, datasets):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Mean: {np.mean(data):.1f}\")\n",
    "    print(f\"  Std Dev: {np.std(data):.1f}\")\n",
    "    print(f\"  Range: {max(data) - min(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "for i, (name, data) in enumerate(zip(names, datasets)):\n",
    "    axes[i].plot(data, 'o-', linewidth=2, markersize=8)\n",
    "    axes[i].axhline(np.mean(data), color='red', linestyle='--', alpha=0.7)\n",
    "    axes[i].set_title(f'{name}\\nMean: {np.mean(data):.1f}')\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 — Data Quality Assessment (hard)**  \n",
    "Detect outliers and assess data quality using statistical methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Response times (in seconds) - some may be outliers\n",
    "response_times = [0.8, 1.2, 0.9, 1.1, 0.7, 15.3, 0.8, 0.9, 1.0, 1.3, \n",
    "                 0.6, 1.4, 0.8, 12.7, 0.9, 1.1, 0.7, 0.8, 1.2, 0.9]\n",
    "\n",
    "# Use IQR method to detect outliers\n",
    "# Calculate Q1, Q3, IQR, and identify outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Calculate quartiles and IQR\n",
    "Q1 = np.percentile(response_times, 25)\n",
    "Q3 = np.percentile(response_times, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = [x for x in response_times if x < lower_bound or x > upper_bound]\n",
    "clean_data = [x for x in response_times if lower_bound <= x <= upper_bound]\n",
    "\n",
    "print(\"🔍 Data Quality Assessment:\")\n",
    "print(f\"Total data points: {len(response_times)}\")\n",
    "print(f\"Q1: {Q1:.2f}s, Q3: {Q3:.2f}s, IQR: {IQR:.2f}s\")\n",
    "print(f\"Outlier boundaries: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "print(f\"Outliers detected: {outliers}\")\n",
    "print(f\"Clean data points: {len(clean_data)} ({len(clean_data)/len(response_times):.1%})\")\n",
    "\n",
    "print(f\"\\n📊 Impact of outliers:\")\n",
    "print(f\"Mean with outliers: {np.mean(response_times):.2f}s\")\n",
    "print(f\"Mean without outliers: {np.mean(clean_data):.2f}s\")\n",
    "print(f\"Median (robust): {np.median(response_times):.2f}s\")\n",
    "\n",
    "# Visualize with outliers highlighted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.scatter(range(len(response_times)), response_times, \n",
    "           c=['red' if x in outliers else 'blue' for x in response_times], \n",
    "           s=50, alpha=0.7)\n",
    "plt.axhline(np.mean(response_times), color='green', linestyle='--', \n",
    "           label=f'Mean: {np.mean(response_times):.2f}s')\n",
    "plt.axhline(np.median(response_times), color='orange', linestyle='--', \n",
    "           label=f'Median: {np.median(response_times):.2f}s')\n",
    "plt.xlabel('Measurement')\n",
    "plt.ylabel('Response Time (s)')\n",
    "plt.title('Response Times (Red = Outliers)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mini-Challenges\n",
    "- **M1 (easy):** Calculate summary statistics for mobile app ratings (1-5 stars)\n",
    "- **M2 (medium):** Compare performance metrics between two ML models using statistical measures\n",
    "- **M3 (hard):** Design an A/B test framework with proper statistical foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n",
    "# M1 data:\n",
    "app_ratings = [4, 5, 3, 4, 5, 4, 3, 5, 4, 4, 2, 5, 4, 3, 4, 5, 4, 3, 4, 5]\n",
    "\n",
    "# M2 data:\n",
    "model_a_accuracy = [0.87, 0.89, 0.85, 0.91, 0.88]\n",
    "model_b_accuracy = [0.84, 0.86, 0.88, 0.89, 0.87]\n",
    "\n",
    "# M3: Design framework (conceptual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - App ratings analysis\n",
    "print(\"⭐ App Ratings Analysis:\")\n",
    "print(f\"Average rating: {np.mean(app_ratings):.1f}/5\")\n",
    "print(f\"Median rating: {np.median(app_ratings):.1f}/5\")\n",
    "print(f\"Most common rating: {stats.mode(app_ratings).mode[0]}/5\")\n",
    "print(f\"Rating variability: {np.std(app_ratings):.2f}\")\n",
    "\n",
    "# Rating distribution\n",
    "unique, counts = np.unique(app_ratings, return_counts=True)\n",
    "for rating, count in zip(unique, counts):\n",
    "    percentage = count/len(app_ratings)*100\n",
    "    print(f\"{rating} stars: {count} ratings ({percentage:.1f}%)\")\n",
    "\n",
    "# M2 - Model comparison\n",
    "print(\"\\n🤖 Model Comparison:\")\n",
    "print(f\"Model A: {np.mean(model_a_accuracy):.1%} ± {np.std(model_a_accuracy):.1%}\")\n",
    "print(f\"Model B: {np.mean(model_b_accuracy):.1%} ± {np.std(model_b_accuracy):.1%}\")\n",
    "\n",
    "# Statistical significance (simple t-test concept)\n",
    "diff_means = np.mean(model_a_accuracy) - np.mean(model_b_accuracy)\n",
    "print(f\"Difference: {diff_means:.1%}\")\n",
    "if abs(diff_means) > 0.02:\n",
    "    print(\"📈 Potentially significant difference (>2%)\")\n",
    "else:\n",
    "    print(\"📊 Difference may not be significant\")\n",
    "\n",
    "# M3 - A/B Test Framework\n",
    "print(\"\\n🧪 A/B Test Framework:\")\n",
    "print(\"1. Define hypothesis: Version B increases conversion by 10%\")\n",
    "print(\"2. Set significance level: α = 0.05 (95% confidence)\")\n",
    "print(\"3. Calculate sample size needed\")\n",
    "print(\"4. Random assignment: 50/50 split\")\n",
    "print(\"5. Collect data for minimum duration\")\n",
    "print(\"6. Statistical test: Compare conversion rates\")\n",
    "print(\"7. Decision: Implement if statistically significant\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up & Next Steps\n",
    "✅ You understand the difference between descriptive and inferential statistics  \n",
    "✅ You can perform basic statistical analysis in Python  \n",
    "✅ You recognize statistics' crucial role in AI and data science  \n",
    "✅ You can identify data quality issues and outliers  \n",
    "\n",
    "**Next:** Data Types & Visualization - Choose the right charts and handle different data types!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
