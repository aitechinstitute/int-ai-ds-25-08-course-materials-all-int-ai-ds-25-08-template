{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 04 ¬∑ Notebook 06 ‚Äî Sampling and Populations\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master the art of making big conclusions from small samples.\n",
    "\n",
    "> Format: short theory ‚Üí quick practice ‚Üí build understanding ‚Üí mini-challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Distinguish between populations and samples like a pro\n",
    "- Master different sampling methods and when to use each\n",
    "- Calculate and interpret sampling distributions\n",
    "- Understand sampling bias and how to avoid the traps\n",
    "- Apply sampling concepts to solve real business problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Population vs Sample: The Foundation\n",
    "**Your statistical compass**: Understanding this difference is the key to everything in data science!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style for nice plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fundamental distinction\n",
    "concepts = {\n",
    "    \"Population\": {\n",
    "        \"definition\": \"Complete set of ALL possible observations\",\n",
    "        \"symbol\": \"Greek letters (Œº, œÉ, œÄ)\",\n",
    "        \"examples\": [\"All Netflix subscribers worldwide\", \"Every student at your university\", \"All products manufactured this year\"],\n",
    "        \"challenge\": \"Usually too large/expensive to study completely\"\n",
    "    },\n",
    "    \"Sample\": {\n",
    "        \"definition\": \"Subset of the population we actually study\",\n",
    "        \"symbol\": \"Latin letters (xÃÑ, s, p)\", \n",
    "        \"examples\": [\"1,000 randomly selected subscribers\", \"500 survey respondents\", \"100 products tested daily\"],\n",
    "        \"challenge\": \"Must be representative of the population\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Population vs Sample Quick Guide:\")\n",
    "for concept, details in concepts.items():\n",
    "    print(f\"\\n{concept}:\")\n",
    "    print(f\"   Definition: {details['definition']}\")\n",
    "    print(f\"   Symbols: {details['symbol']}\")\n",
    "    print(f\"   Challenge: {details['challenge']}\")\n",
    "    \n",
    "print(\"\\nKey Insight: We study samples to learn about populations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Our Population Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic population: customer spending at an e-commerce site\n",
    "np.random.seed(42)\n",
    "population_size = 100000\n",
    "\n",
    "# Most customers spend little, few spend a lot (log-normal distribution)\n",
    "population_spending = np.random.lognormal(mean=4.2, sigma=0.8, size=population_size)\n",
    "\n",
    "# Population parameters (the \"truth\" we're trying to discover)\n",
    "pop_mean = np.mean(population_spending)\n",
    "pop_std = np.std(population_spending)\n",
    "pop_median = np.median(population_spending)\n",
    "\n",
    "print(f\"E-Commerce Customer Population ({population_size:,} customers):\")\n",
    "print(f\"   True mean spending: ${pop_mean:.2f}\")\n",
    "print(f\"   True std deviation: ${pop_std:.2f}\")\n",
    "print(f\"   True median: ${pop_median:.2f}\")\n",
    "print(f\"\\nThese are the population parameters we want to estimate from samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our population\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(population_spending, bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "plt.axvline(pop_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: ${pop_mean:.0f}')\n",
    "plt.axvline(pop_median, color='green', linestyle='--', linewidth=2, \n",
    "           label=f'Median: ${pop_median:.0f}')\n",
    "plt.title('Customer Spending Population')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(population_spending, bins=50, alpha=0.7, color='lightcoral')\n",
    "plt.title('Population (Log Scale)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Most customers spend little, but some big spenders pull the mean up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling Methods: Your Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple Random Sampling: The Gold Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple random sampling\n",
    "sample_size = 1000\n",
    "random_sample = np.random.choice(population_spending, size=sample_size, replace=False)\n",
    "\n",
    "sample_mean = np.mean(random_sample)\n",
    "sample_std = np.std(random_sample, ddof=1)\n",
    "sample_median = np.median(random_sample)\n",
    "\n",
    "print(f\"Random Sample Results (n={sample_size}):\")\n",
    "print(f\"   Sample mean: ${sample_mean:.2f} (vs population: ${pop_mean:.2f})\")\n",
    "print(f\"   Sample std: ${sample_std:.2f} (vs population: ${pop_std:.2f})\")\n",
    "print(f\"   Sample median: ${sample_median:.2f} (vs population: ${pop_median:.2f})\")\n",
    "\n",
    "# Calculate errors\n",
    "mean_error = abs(sample_mean - pop_mean)\n",
    "print(f\"\\nEstimation accuracy:\")\n",
    "print(f\"   Mean error: ${mean_error:.2f} ({mean_error/pop_mean:.1%} off)\")\n",
    "print(f\"\\nNot bad for studying only {sample_size/population_size:.1%} of the population!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stratified Sampling: Ensuring Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer segments\n",
    "low_spenders = population_spending[population_spending < 50]\n",
    "medium_spenders = population_spending[(population_spending >= 50) & (population_spending < 150)]\n",
    "high_spenders = population_spending[population_spending >= 150]\n",
    "\n",
    "print(\"Customer Segmentation:\")\n",
    "print(f\"   Low spenders (<$50): {len(low_spenders):,} ({len(low_spenders)/population_size:.1%})\")\n",
    "print(f\"   Medium spenders ($50-150): {len(medium_spenders):,} ({len(medium_spenders)/population_size:.1%})\")\n",
    "print(f\"   High spenders (>$150): {len(high_spenders):,} ({len(high_spenders)/population_size:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified sampling: maintain proportions\n",
    "n_low = int(sample_size * len(low_spenders) / population_size)\n",
    "n_medium = int(sample_size * len(medium_spenders) / population_size)\n",
    "n_high = sample_size - n_low - n_medium  # Remainder to avoid rounding errors\n",
    "\n",
    "stratified_sample = np.concatenate([\n",
    "    np.random.choice(low_spenders, n_low, replace=False),\n",
    "    np.random.choice(medium_spenders, n_medium, replace=False),\n",
    "    np.random.choice(high_spenders, n_high, replace=False)\n",
    "])\n",
    "\n",
    "stratified_mean = np.mean(stratified_sample)\n",
    "stratified_error = abs(stratified_mean - pop_mean)\n",
    "\n",
    "print(f\"Stratified Sample Results:\")\n",
    "print(f\"   Sample composition: {n_low} low + {n_medium} medium + {n_high} high\")\n",
    "print(f\"   Sample mean: ${stratified_mean:.2f}\")\n",
    "print(f\"   Error: ${stratified_error:.2f} ({stratified_error/pop_mean:.1%} off)\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"   Random sampling error: ${mean_error:.2f}\")\n",
    "print(f\"   Stratified sampling error: ${stratified_error:.2f}\")\n",
    "print(f\"   Stratified is {'better' if stratified_error < mean_error else 'worse'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 ‚Äî Sampling Method Selection (easy)**  \n",
    "Choose the best sampling method for each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - match scenarios to sampling methods\n",
    "scenarios = [\n",
    "    \"Survey customer satisfaction across all age groups\",\n",
    "    \"Test product quality from assembly line\",\n",
    "    \"Study voting intentions in election with diverse districts\", \n",
    "    \"Evaluate employee performance across departments\",\n",
    "    \"Quality control for large batch of identical products\"\n",
    "]\n",
    "\n",
    "methods = [\"Simple Random\", \"Systematic\", \"Stratified\", \"Cluster\", \"Convenience\"]\n",
    "\n",
    "# Match each scenario with the best sampling method and explain why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "print(\"Sampling Method Selection Guide:\")\n",
    "print()\n",
    "\n",
    "matches = [\n",
    "    {\n",
    "        'scenario': \"Survey customer satisfaction across all age groups\",\n",
    "        'method': \"Stratified\",\n",
    "        'reason': \"Need to ensure all age groups are represented proportionally\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Test product quality from assembly line\",\n",
    "        'method': \"Systematic\", \n",
    "        'reason': \"Take every nth product - efficient and avoids time-based patterns\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Study voting intentions with diverse districts\",\n",
    "        'method': \"Stratified\",\n",
    "        'reason': \"Each district is a stratum - need proportional representation\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Evaluate employee performance across departments\",\n",
    "        'method': \"Stratified\",\n",
    "        'reason': \"Each department is different - need samples from all\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Quality control for identical products\",\n",
    "        'method': \"Simple Random\",\n",
    "        'reason': \"Products are homogeneous - simple random is sufficient\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, match in enumerate(matches, 1):\n",
    "    print(f\"{i}. {match['scenario']}\")\n",
    "    print(f\"   Best method: {match['method']}\")\n",
    "    print(f\"   Why: {match['reason']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Key principle: Use stratified when subgroups matter,\")\n",
    "print(\"systematic for ordered populations, random for homogeneous groups.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Magic of Sampling Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 What Happens When We Sample Many Times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take many samples and see what happens\n",
    "num_samples = 1000\n",
    "sample_size = 100\n",
    "sample_means = []\n",
    "\n",
    "print(f\"Sampling Distribution Experiment:\")\n",
    "print(f\"   Taking {num_samples} samples of size {sample_size} each...\")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = np.random.choice(population_spending, size=sample_size, replace=False)\n",
    "    sample_means.append(np.mean(sample))\n",
    "\n",
    "sample_means = np.array(sample_means)\n",
    "\n",
    "# Analyze the sampling distribution\n",
    "mean_of_means = np.mean(sample_means)\n",
    "std_of_means = np.std(sample_means, ddof=1)\n",
    "theoretical_se = pop_std / np.sqrt(sample_size)\n",
    "\n",
    "print(f\"\\nSampling Distribution Results:\")\n",
    "print(f\"   Population mean: ${pop_mean:.2f}\")\n",
    "print(f\"   Mean of sample means: ${mean_of_means:.2f}\")\n",
    "print(f\"   Standard error (actual): ${std_of_means:.2f}\")\n",
    "print(f\"   Standard error (theory): ${theoretical_se:.2f}\")\n",
    "print(f\"\\nMagic: The sample means center around the population mean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sampling distribution magic\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(population_spending, bins=50, alpha=0.7, density=True, \n",
    "         color='lightblue', label='Population')\n",
    "plt.axvline(pop_mean, color='red', linestyle='--', linewidth=2, label='Population Mean')\n",
    "plt.title('Original Population\\n(Right-skewed)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sample_means, bins=30, alpha=0.7, density=True, \n",
    "         color='lightcoral', label='Sample Means')\n",
    "plt.axvline(mean_of_means, color='red', linestyle='--', linewidth=2, \n",
    "           label='Mean of Sample Means')\n",
    "plt.title('Sampling Distribution of Means\\n(Beautiful Bell Curve!)')\n",
    "plt.xlabel('Sample Mean ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Amazing transformation: Skewed population ‚Üí Normal sampling distribution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Power of Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different sample sizes\n",
    "sample_sizes = [10, 25, 50, 100, 500]\n",
    "num_samples = 500\n",
    "\n",
    "results = {}\n",
    "for size in sample_sizes:\n",
    "    means = []\n",
    "    for i in range(num_samples):\n",
    "        sample = np.random.choice(population_spending, size=size, replace=False)\n",
    "        means.append(np.mean(sample))\n",
    "    results[size] = np.array(means)\n",
    "\n",
    "print(\"Sample Size Impact Analysis:\")\n",
    "print(\"Sample Size | Standard Error | Theoretical SE | Accuracy\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for size in sample_sizes:\n",
    "    actual_se = np.std(results[size], ddof=1)\n",
    "    theoretical_se = pop_std / np.sqrt(size)\n",
    "    accuracy = f\"¬±${1.96 * actual_se:.0f}\" # 95% confidence\n",
    "    \n",
    "    print(f\"    {size:3d}     |     ${actual_se:6.2f}     |     ${theoretical_se:6.2f}     |  {accuracy}\")\n",
    "    \n",
    "print(f\"\\nKey insight: Larger samples ‚Üí smaller standard error ‚Üí better estimates!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample size effect\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, size in enumerate(sample_sizes):\n",
    "    axes[i].hist(results[size], bins=25, alpha=0.7, density=True, color=f'C{i}')\n",
    "    axes[i].axvline(pop_mean, color='red', linestyle='--', linewidth=2, \n",
    "                   label='True Mean')\n",
    "    \n",
    "    se = np.std(results[size], ddof=1)\n",
    "    axes[i].set_title(f'Sample Size = {size}\\nStandard Error = ${se:.2f}')\n",
    "    axes[i].set_xlabel('Sample Mean ($)')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide the last subplot\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.suptitle('Sample Size Effect: Larger Samples = More Precise Estimates', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sampling Bias: The Silent Killer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Response Bias Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate response bias: high spenders more likely to respond to surveys\n",
    "response_prob_low = 0.1    # Low spenders rarely respond\n",
    "response_prob_high = 0.8   # High spenders love surveys\n",
    "\n",
    "# Create biased sample\n",
    "biased_sample = []\n",
    "for spending in population_spending[:5000]:  # Use subset for speed\n",
    "    # Higher spenders more likely to respond\n",
    "    response_prob = response_prob_low + (response_prob_high - response_prob_low) * min(spending/200, 1)\n",
    "    if np.random.random() < response_prob:\n",
    "        biased_sample.append(spending)\n",
    "\n",
    "biased_sample = np.array(biased_sample)\n",
    "\n",
    "# Compare results\n",
    "random_mean = np.mean(random_sample)\n",
    "biased_mean = np.mean(biased_sample)\n",
    "bias_amount = biased_mean - pop_mean\n",
    "\n",
    "print(f\"Response Bias Impact:\")\n",
    "print(f\"   Population mean: ${pop_mean:.2f}\")\n",
    "print(f\"   Random sample mean: ${random_mean:.2f}\")\n",
    "print(f\"   Biased sample mean: ${biased_mean:.2f}\")\n",
    "print(f\"\\nBias analysis:\")\n",
    "print(f\"   Random sample error: ${abs(random_mean - pop_mean):.2f}\")\n",
    "print(f\"   Biased sample error: ${abs(bias_amount):.2f}\")\n",
    "print(f\"   Bias makes estimate {abs(bias_amount)/pop_mean:.1%} too high!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bias\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(population_spending, bins=30, alpha=0.7, density=True, color='lightblue')\n",
    "plt.axvline(pop_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'True Mean: ${pop_mean:.0f}')\n",
    "plt.title('Population\\n(The Truth)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(random_sample, bins=30, alpha=0.7, density=True, color='lightgreen')\n",
    "plt.axvline(random_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Sample Mean: ${random_mean:.0f}')\n",
    "plt.title('Random Sample\\n(Good Estimate)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(biased_sample, bins=30, alpha=0.7, density=True, color='lightcoral')\n",
    "plt.axvline(biased_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Biased Mean: ${biased_mean:.0f}')\n",
    "plt.title('Biased Sample\\n(High Spenders Over-represented)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Lesson: Biased sampling can completely mislead your conclusions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 ‚Äî Bias Detection (medium)**  \n",
    "Identify potential sources of bias in these sampling scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - identify bias sources\n",
    "bias_scenarios = [\n",
    "    \"Online survey about internet usage habits\",\n",
    "    \"Phone survey conducted during business hours\",\n",
    "    \"University study using only psychology students\", \n",
    "    \"Mall survey about shopping preferences\",\n",
    "    \"Social media poll about political opinions\"\n",
    "]\n",
    "\n",
    "# For each scenario, identify:\n",
    "# 1. What bias is likely present?\n",
    "# 2. Who might be excluded?\n",
    "# 3. How would this affect results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "print(\"Bias Detection Analysis:\")\n",
    "print()\n",
    "\n",
    "bias_analyses = [\n",
    "    {\n",
    "        'scenario': \"Online survey about internet usage\",\n",
    "        'bias_type': \"Selection bias\",\n",
    "        'excluded': \"People with limited internet access\",\n",
    "        'effect': \"Overestimates internet usage in general population\",\n",
    "        'fix': \"Include phone interviews, mail surveys\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Phone survey during business hours\", \n",
    "        'bias_type': \"Response bias\",\n",
    "        'excluded': \"Working people, students\",\n",
    "        'effect': \"Overrepresents retirees, unemployed, stay-at-home parents\",\n",
    "        'fix': \"Call evenings/weekends, use multiple contact methods\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"University study using psychology students\",\n",
    "        'bias_type': \"Convenience sampling bias\",\n",
    "        'excluded': \"Non-students, other majors, different ages\",\n",
    "        'effect': \"Results may not generalize beyond young, educated population\",\n",
    "        'fix': \"Recruit from broader community, multiple universities\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Mall survey about shopping preferences\",\n",
    "        'bias_type': \"Location bias\",\n",
    "        'excluded': \"Online shoppers, people who avoid malls\",\n",
    "        'effect': \"Overrepresents people who like physical shopping\",\n",
    "        'fix': \"Include online surveys, home visits, multiple locations\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Social media poll about political opinions\",\n",
    "        'bias_type': \"Self-selection bias\",\n",
    "        'excluded': \"Non-social media users, people with different political views\",\n",
    "        'effect': \"May skew toward certain demographics or viewpoints\",\n",
    "        'fix': \"Random digit dialing, representative panels\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, analysis in enumerate(bias_analyses, 1):\n",
    "    print(f\"{i}. {analysis['scenario']}\")\n",
    "    print(f\"   Bias type: {analysis['bias_type']}\")\n",
    "    print(f\"   Who's excluded: {analysis['excluded']}\")\n",
    "    print(f\"   Effect: {analysis['effect']}\")\n",
    "    print(f\"   How to fix: {analysis['fix']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Golden rule: Always ask 'Who might we be missing?' and 'Why?'\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real Business Application: Customer Survey Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic customer database\n",
    "np.random.seed(789)\n",
    "n_customers = 50000\n",
    "\n",
    "customer_db = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': np.random.randint(18, 80, n_customers),\n",
    "    'annual_spending': np.random.lognormal(6.5, 0.8, n_customers),\n",
    "    'satisfaction': np.clip(np.random.normal(7.5, 1.8, n_customers), 1, 10),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_customers),\n",
    "    'customer_type': np.random.choice(['Regular', 'Premium', 'VIP'], \n",
    "                                    n_customers, p=[0.7, 0.25, 0.05])\n",
    "})\n",
    "\n",
    "# True population satisfaction\n",
    "true_satisfaction = customer_db['satisfaction'].mean()\n",
    "\n",
    "print(f\"Customer Database: {len(customer_db):,} customers\")\n",
    "print(f\"True average satisfaction: {true_satisfaction:.2f}/10\")\n",
    "print(\"\\nCustomer breakdown:\")\n",
    "print(customer_db['customer_type'].value_counts())\n",
    "print(\"\\nFirst few customers:\")\n",
    "print(customer_db.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 ‚Äî Survey Design Challenge (hard)**  \n",
    "Design the best sampling strategy for a customer satisfaction survey.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your mission: Design a sampling strategy for 1000 customers\n",
    "# Consider:\n",
    "# 1. What's the population satisfaction mean?\n",
    "# 2. How would simple random sampling perform?\n",
    "# 3. How would stratified sampling (by customer type) perform?\n",
    "# 4. Which method gives better estimates?\n",
    "\n",
    "survey_budget = 1000  # Can survey 1000 customers\n",
    "\n",
    "# Task 1: Population mean\n",
    "\n",
    "\n",
    "# Task 2: Simple random sampling\n",
    "\n",
    "\n",
    "# Task 3: Stratified sampling by customer type\n",
    "\n",
    "\n",
    "# Task 4: Compare methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Task 1: Population satisfaction mean\n",
    "population_satisfaction = customer_db['satisfaction'].mean()\n",
    "print(f\"Task 1 - True Population Satisfaction: {population_satisfaction:.3f}/10\")\n",
    "\n",
    "# Task 2: Simple random sampling\n",
    "random_sample_indices = np.random.choice(customer_db.index, size=survey_budget, replace=False)\n",
    "random_sample_satisfaction = customer_db.loc[random_sample_indices, 'satisfaction'].mean()\n",
    "random_error = abs(random_sample_satisfaction - population_satisfaction)\n",
    "\n",
    "print(f\"\\nTask 2 - Simple Random Sampling:\")\n",
    "print(f\"   Sample mean: {random_sample_satisfaction:.3f}\")\n",
    "print(f\"   Error: {random_error:.3f} points\")\n",
    "\n",
    "# Task 3: Stratified sampling by customer type\n",
    "# Get proportions of each customer type\n",
    "type_counts = customer_db['customer_type'].value_counts()\n",
    "type_props = type_counts / len(customer_db)\n",
    "\n",
    "print(f\"\\nCustomer type proportions:\")\n",
    "for ctype, prop in type_props.items():\n",
    "    print(f\"   {ctype}: {prop:.1%}\")\n",
    "\n",
    "# Calculate sample sizes for each stratum\n",
    "stratified_samples = {}\n",
    "stratified_means = {}\n",
    "\n",
    "total_sampled = 0\n",
    "for ctype in ['Regular', 'Premium']:\n",
    "    n_stratum = int(survey_budget * type_props[ctype])\n",
    "    stratum_data = customer_db[customer_db['customer_type'] == ctype]\n",
    "    sample_indices = np.random.choice(stratum_data.index, size=n_stratum, replace=False)\n",
    "    stratified_samples[ctype] = customer_db.loc[sample_indices, 'satisfaction']\n",
    "    stratified_means[ctype] = stratified_samples[ctype].mean()\n",
    "    total_sampled += n_stratum\n",
    "    print(f\"   {ctype}: {n_stratum} customers sampled\")\n",
    "\n",
    "# Handle VIP (small group - sample remaining)\n",
    "n_vip = survey_budget - total_sampled\n",
    "vip_data = customer_db[customer_db['customer_type'] == 'VIP']\n",
    "vip_sample_indices = np.random.choice(vip_data.index, size=min(n_vip, len(vip_data)), replace=False)\n",
    "stratified_samples['VIP'] = customer_db.loc[vip_sample_indices, 'satisfaction']\n",
    "stratified_means['VIP'] = stratified_samples['VIP'].mean()\n",
    "print(f\"   VIP: {len(vip_sample_indices)} customers sampled\")\n",
    "\n",
    "# Calculate weighted average\n",
    "stratified_overall = 0\n",
    "for ctype, mean_sat in stratified_means.items():\n",
    "    weight = type_props[ctype]\n",
    "    stratified_overall += weight * mean_sat\n",
    "\n",
    "stratified_error = abs(stratified_overall - population_satisfaction)\n",
    "\n",
    "print(f\"\\nTask 3 - Stratified Sampling Results:\")\n",
    "for ctype, mean_sat in stratified_means.items():\n",
    "    print(f\"   {ctype} satisfaction: {mean_sat:.3f}\")\n",
    "print(f\"   Weighted average: {stratified_overall:.3f}\")\n",
    "print(f\"   Error: {stratified_error:.3f} points\")\n",
    "\n",
    "# Task 4: Compare methods\n",
    "print(f\"\\nTask 4 - Method Comparison:\")\n",
    "print(f\"   Population truth: {population_satisfaction:.3f}\")\n",
    "print(f\"   Random sampling error: {random_error:.3f}\")\n",
    "print(f\"   Stratified sampling error: {stratified_error:.3f}\")\n",
    "\n",
    "if stratified_error < random_error:\n",
    "    print(f\"   Winner: Stratified sampling (better by {random_error - stratified_error:.3f} points)\")\n",
    "    print(f\"   Why: Ensures all customer types are properly represented\")\n",
    "else:\n",
    "    print(f\"   Winner: Random sampling (better by {stratified_error - random_error:.3f} points)\")\n",
    "    print(f\"   Note: This can happen by chance, but stratified is usually better\")\n",
    "\n",
    "print(f\"\\nBusiness recommendation:\")\n",
    "print(f\"   Use stratified sampling to ensure insights from all customer segments\")\n",
    "print(f\"   This prevents VIP customers (only 5%) from being missed entirely\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. The Standard Error Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the standard error formula: SE = œÉ/‚àön\n",
    "population_std = np.std(population_spending)\n",
    "test_sizes = [25, 100, 400, 1600, 6400]\n",
    "\n",
    "print(\"Standard Error Formula Validation:\")\n",
    "print(\"Sample Size | Theoretical SE | Empirical SE | Difference\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for n in test_sizes:\n",
    "    # Theoretical standard error\n",
    "    theoretical_se = population_std / np.sqrt(n)\n",
    "    \n",
    "    # Empirical standard error (from 500 samples)\n",
    "    sample_means = []\n",
    "    for i in range(500):\n",
    "        sample = np.random.choice(population_spending, size=n, replace=True)\n",
    "        sample_means.append(np.mean(sample))\n",
    "    empirical_se = np.std(sample_means, ddof=1)\n",
    "    \n",
    "    difference = abs(theoretical_se - empirical_se)\n",
    "    \n",
    "    print(f\"    {n:4d}    |     ${theoretical_se:7.2f}    |    ${empirical_se:7.2f}   |   ${difference:.2f}\")\n",
    "\n",
    "print(f\"\\nKey insights:\")\n",
    "print(f\"‚Ä¢ Standard error decreases as sample size increases\")\n",
    "print(f\"‚Ä¢ To cut error in half, need 4x the sample size\")\n",
    "print(f\"‚Ä¢ Formula works regardless of population size!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mini-Challenges\n",
    "- **M1 (easy):** Design a sampling strategy for employee satisfaction across departments\n",
    "- **M2 (medium):** Build a bias detection system for survey data\n",
    "- **M3 (hard):** Create a sample size calculator for different precision requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n",
    "# M1 Data: 10,000 employees across 5 departments with different sizes\n",
    "# M2 Data: Survey responses with potential demographic biases\n",
    "# M3 Data: Business scenarios requiring different levels of precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - Employee Satisfaction Sampling Strategy\n",
    "np.random.seed(123)\n",
    "departments = {\n",
    "    'Engineering': 4000,\n",
    "    'Sales': 2500, \n",
    "    'Marketing': 1500,\n",
    "    'HR': 1000,\n",
    "    'Operations': 1000\n",
    "}\n",
    "total_employees = sum(departments.values())\n",
    "survey_size = 500\n",
    "\n",
    "print(\"M1 - Employee Satisfaction Sampling:\")\n",
    "print(f\"Total employees: {total_employees:,}\")\n",
    "print(f\"Survey budget: {survey_size} employees\")\n",
    "print(\"\\nStratified sampling by department:\")\n",
    "\n",
    "for dept, size in departments.items():\n",
    "    proportion = size / total_employees\n",
    "    sample_size = int(survey_size * proportion)\n",
    "    print(f\"   {dept}: {size:,} employees ({proportion:.1%}) ‚Üí sample {sample_size}\")\n",
    "\n",
    "print(\"\\nWhy stratified? Ensures each department is represented proportionally.\")\n",
    "\n",
    "# M2 - Bias Detection System\n",
    "def detect_response_bias(responses, population_demographics):\n",
    "    \"\"\"Detect if survey responses match population demographics\"\"\"\n",
    "    print(\"\\nM2 - Bias Detection Analysis:\")\n",
    "    \n",
    "    biases_found = []\n",
    "    \n",
    "    for demographic, pop_prop in population_demographics.items():\n",
    "        if demographic in responses.columns:\n",
    "            resp_prop = responses[demographic].mean()\n",
    "            bias = abs(resp_prop - pop_prop)\n",
    "            \n",
    "            if bias > 0.05:  # 5% threshold\n",
    "                biases_found.append((demographic, bias, resp_prop, pop_prop))\n",
    "                \n",
    "            print(f\"   {demographic}: Population {pop_prop:.1%}, Sample {resp_prop:.1%} (bias: {bias:.1%})\")\n",
    "    \n",
    "    if biases_found:\n",
    "        print(f\"\\nBiases detected in: {[b[0] for b in biases_found]}\")\n",
    "        print(\"Recommendation: Weight responses or collect more representative sample\")\n",
    "    else:\n",
    "        print(\"\\nNo significant biases detected - sample appears representative\")\n",
    "\n",
    "# Test bias detection\n",
    "sample_demographics = pd.DataFrame({\n",
    "    'age_over_50': np.random.binomial(1, 0.6, 1000),  # Overrepresented\n",
    "    'college_educated': np.random.binomial(1, 0.8, 1000),  # Overrepresented\n",
    "    'urban': np.random.binomial(1, 0.5, 1000)  # Representative\n",
    "})\n",
    "\n",
    "population_props = {\n",
    "    'age_over_50': 0.4,\n",
    "    'college_educated': 0.6,\n",
    "    'urban': 0.5\n",
    "}\n",
    "\n",
    "detect_response_bias(sample_demographics, population_props)\n",
    "\n",
    "# M3 - Sample Size Calculator\n",
    "def calculate_sample_size(population_std, desired_error, confidence_level=0.95):\n",
    "    \"\"\"Calculate required sample size for desired precision\"\"\"\n",
    "    # Z-score for confidence level\n",
    "    z_scores = {0.90: 1.645, 0.95: 1.96, 0.99: 2.576}\n",
    "    z = z_scores[confidence_level]\n",
    "    \n",
    "    # Sample size formula: n = (z * œÉ / E)¬≤\n",
    "    n = (z * population_std / desired_error) ** 2\n",
    "    return int(np.ceil(n))\n",
    "\n",
    "print(\"\\nM3 - Sample Size Calculator:\")\n",
    "scenarios = [\n",
    "    (\"Customer satisfaction (1-10 scale)\", 1.5, 0.1),\n",
    "    (\"Average order value\", 25, 2),\n",
    "    (\"Employee productivity score\", 12, 1),\n",
    "    (\"Website load time (seconds)\", 0.8, 0.05)\n",
    "]\n",
    "\n",
    "for scenario, std, error in scenarios:\n",
    "    n_90 = calculate_sample_size(std, error, 0.90)\n",
    "    n_95 = calculate_sample_size(std, error, 0.95)\n",
    "    n_99 = calculate_sample_size(std, error, 0.99)\n",
    "    \n",
    "    print(f\"\\n{scenario}:\")\n",
    "    print(f\"   For ¬±{error} precision: {n_90} (90%), {n_95} (95%), {n_99} (99%)\")\n",
    "\n",
    "print(\"\\nKey insight: Higher precision and confidence require larger samples!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up & Next Steps\n",
    "‚úÖ You understand the crucial difference between populations and samples  \n",
    "‚úÖ You can choose the right sampling method for any situation  \n",
    "‚úÖ You know how sampling distributions work their magic  \n",
    "‚úÖ You can spot and avoid dangerous sampling biases  \n",
    "‚úÖ You can design professional survey strategies  \n",
    "\n",
    "**Quick Reference Card:**\n",
    "- üéØ **Population**: Everyone/everything you want to know about\n",
    "- üìä **Sample**: The subset you actually study\n",
    "- üîÄ **Random**: Best default choice for homogeneous populations\n",
    "- üìö **Stratified**: Essential when subgroups matter\n",
    "- ‚ö†Ô∏è **Watch for bias**: Always ask \"Who might we be missing?\"\n",
    "- üìè **Standard Error**: œÉ/‚àön (bigger samples = smaller error)\n",
    "\n",
    "**Next:** Central Limit Theorem - Discover the most beautiful theorem in statistics!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"\n",
  },\n",
  "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.13.1"\n",
  }\n",
 },\n",
 "nbformat": 4,\n",
 "nbformat_minor": 4\n}