{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** · *Intermediate AI & Data Science*\n",
    "### Week 04 · Notebook 06 — Sampling and Populations\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master the art of making big conclusions from small samples.\n",
    "\n",
    "> Format: short theory → quick practice → build understanding → mini-challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Distinguish between populations and samples like a pro\n",
    "- Master different sampling methods and when to use each\n",
    "- Calculate and interpret sampling distributions\n",
    "- Understand sampling bias and how to avoid the traps\n",
    "- Apply sampling concepts to solve real business problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Population vs Sample: The Foundation\n",
    "**Your statistical compass**: Understanding this difference is the key to everything in data science!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style for nice plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fundamental distinction\n",
    "concepts = {\n",
    "    \"Population\": {\n",
    "        \"definition\": \"Complete set of ALL possible observations\",\n",
    "        \"symbol\": \"Greek letters (μ, σ, π)\",\n",
    "        \"examples\": [\"All Netflix subscribers worldwide\", \"Every student at your university\", \"All products manufactured this year\"],\n",
    "        \"challenge\": \"Usually too large/expensive to study completely\"\n",
    "    },\n",
    "    \"Sample\": {\n",
    "        \"definition\": \"Subset of the population we actually study\",\n",
    "        \"symbol\": \"Latin letters (x̄, s, p)\", \n",
    "        \"examples\": [\"1,000 randomly selected subscribers\", \"500 survey respondents\", \"100 products tested daily\"],\n",
    "        \"challenge\": \"Must be representative of the population\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Population vs Sample Quick Guide:\")\n",
    "for concept, details in concepts.items():\n",
    "    print(f\"\\n{concept}:\")\n",
    "    print(f\"   Definition: {details['definition']}\")\n",
    "    print(f\"   Symbols: {details['symbol']}\")\n",
    "    print(f\"   Challenge: {details['challenge']}\")\n",
    "    \n",
    "print(\"\\nKey Insight: We study samples to learn about populations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Our Population Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic population: customer spending at an e-commerce site\n",
    "np.random.seed(42)\n",
    "population_size = 100000\n",
    "\n",
    "# Most customers spend little, few spend a lot (log-normal distribution)\n",
    "population_spending = np.random.lognormal(mean=4.2, sigma=0.8, size=population_size)\n",
    "\n",
    "# Population parameters (the \"truth\" we're trying to discover)\n",
    "pop_mean = np.mean(population_spending)\n",
    "pop_std = np.std(population_spending)\n",
    "pop_median = np.median(population_spending)\n",
    "\n",
    "print(f\"E-Commerce Customer Population ({population_size:,} customers):\")\n",
    "print(f\"   True mean spending: ${pop_mean:.2f}\")\n",
    "print(f\"   True std deviation: ${pop_std:.2f}\")\n",
    "print(f\"   True median: ${pop_median:.2f}\")\n",
    "print(f\"\\nThese are the population parameters we want to estimate from samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our population\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(population_spending, bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "plt.axvline(pop_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: ${pop_mean:.0f}')\n",
    "plt.axvline(pop_median, color='green', linestyle='--', linewidth=2, \n",
    "           label=f'Median: ${pop_median:.0f}')\n",
    "plt.title('Customer Spending Population')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(population_spending, bins=50, alpha=0.7, color='lightcoral')\n",
    "plt.title('Population (Log Scale)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Most customers spend little, but some big spenders pull the mean up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling Methods: Your Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple Random Sampling: The Gold Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple random sampling\n",
    "sample_size = 1000\n",
    "random_sample = np.random.choice(population_spending, size=sample_size, replace=False)\n",
    "\n",
    "sample_mean = np.mean(random_sample)\n",
    "sample_std = np.std(random_sample, ddof=1)\n",
    "sample_median = np.median(random_sample)\n",
    "\n",
    "print(f\"Random Sample Results (n={sample_size}):\")\n",
    "print(f\"   Sample mean: ${sample_mean:.2f} (vs population: ${pop_mean:.2f})\")\n",
    "print(f\"   Sample std: ${sample_std:.2f} (vs population: ${pop_std:.2f})\")\n",
    "print(f\"   Sample median: ${sample_median:.2f} (vs population: ${pop_median:.2f})\")\n",
    "\n",
    "# Calculate errors\n",
    "mean_error = abs(sample_mean - pop_mean)\n",
    "print(f\"\\nEstimation accuracy:\")\n",
    "print(f\"   Mean error: ${mean_error:.2f} ({mean_error/pop_mean:.1%} off)\")\n",
    "print(f\"\\nNot bad for studying only {sample_size/population_size:.1%} of the population!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stratified Sampling: Ensuring Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer segments\n",
    "low_spenders = population_spending[population_spending < 50]\n",
    "medium_spenders = population_spending[(population_spending >= 50) & (population_spending < 150)]\n",
    "high_spenders = population_spending[population_spending >= 150]\n",
    "\n",
    "print(\"Customer Segmentation:\")\n",
    "print(f\"   Low spenders (<$50): {len(low_spenders):,} ({len(low_spenders)/population_size:.1%})\")\n",
    "print(f\"   Medium spenders ($50-150): {len(medium_spenders):,} ({len(medium_spenders)/population_size:.1%})\")\n",
    "print(f\"   High spenders (>$150): {len(high_spenders):,} ({len(high_spenders)/population_size:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified sampling: maintain proportions\n",
    "n_low = int(sample_size * len(low_spenders) / population_size)\n",
    "n_medium = int(sample_size * len(medium_spenders) / population_size)\n",
    "n_high = sample_size - n_low - n_medium  # Remainder to avoid rounding errors\n",
    "\n",
    "stratified_sample = np.concatenate([\n",
    "    np.random.choice(low_spenders, n_low, replace=False),\n",
    "    np.random.choice(medium_spenders, n_medium, replace=False),\n",
    "    np.random.choice(high_spenders, n_high, replace=False)\n",
    "])\n",
    "\n",
    "stratified_mean = np.mean(stratified_sample)\n",
    "stratified_error = abs(stratified_mean - pop_mean)\n",
    "\n",
    "print(f\"Stratified Sample Results:\")\n",
    "print(f\"   Sample composition: {n_low} low + {n_medium} medium + {n_high} high\")\n",
    "print(f\"   Sample mean: ${stratified_mean:.2f}\")\n",
    "print(f\"   Error: ${stratified_error:.2f} ({stratified_error/pop_mean:.1%} off)\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"   Random sampling error: ${mean_error:.2f}\")\n",
    "print(f\"   Stratified sampling error: ${stratified_error:.2f}\")\n",
    "print(f\"   Stratified is {'better' if stratified_error < mean_error else 'worse'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 — Sampling Method Selection (easy)**  \n",
    "Choose the best sampling method for each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - match scenarios to sampling methods\n",
    "scenarios = [\n",
    "    \"Survey customer satisfaction across all age groups\",\n",
    "    \"Test product quality from assembly line\",\n",
    "    \"Study voting intentions in election with diverse districts\", \n",
    "    \"Evaluate employee performance across departments\",\n",
    "    \"Quality control for large batch of identical products\"\n",
    "]\n",
    "\n",
    "methods = [\"Simple Random\", \"Systematic\", \"Stratified\", \"Cluster\", \"Convenience\"]\n",
    "\n",
    "# Match each scenario with the best sampling method and explain why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "print(\"Sampling Method Selection Guide:\")\n",
    "print()\n",
    "\n",
    "matches = [\n",
    "    {\n",
    "        'scenario': \"Survey customer satisfaction across all age groups\",\n",
    "        'method': \"Stratified\",\n",
    "        'reason': \"Need to ensure all age groups are represented proportionally\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Test product quality from assembly line\",\n",
    "        'method': \"Systematic\", \n",
    "        'reason': \"Take every nth product - efficient and avoids time-based patterns\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Study voting intentions with diverse districts\",\n",
    "        'method': \"Stratified\",\n",
    "        'reason': \"Each district is a stratum - need proportional representation\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Evaluate employee performance across departments\",\n",
    "        'method': \"Stratified\",\n",
    "        'reason': \"Each department is different - need samples from all\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Quality control for identical products\",\n",
    "        'method': \"Simple Random\",\n",
    "        'reason': \"Products are homogeneous - simple random is sufficient\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, match in enumerate(matches, 1):\n",
    "    print(f\"{i}. {match['scenario']}\")\n",
    "    print(f\"   Best method: {match['method']}\")\n",
    "    print(f\"   Why: {match['reason']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Key principle: Use stratified when subgroups matter,\")\n",
    "print(\"systematic for ordered populations, random for homogeneous groups.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Magic of Sampling Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 What Happens When We Sample Many Times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take many samples and see what happens\n",
    "num_samples = 1000\n",
    "sample_size = 100\n",
    "sample_means = []\n",
    "\n",
    "print(f\"Sampling Distribution Experiment:\")\n",
    "print(f\"   Taking {num_samples} samples of size {sample_size} each...\")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = np.random.choice(population_spending, size=sample_size, replace=False)\n",
    "    sample_means.append(np.mean(sample))\n",
    "\n",
    "sample_means = np.array(sample_means)\n",
    "\n",
    "# Analyze the sampling distribution\n",
    "mean_of_means = np.mean(sample_means)\n",
    "std_of_means = np.std(sample_means, ddof=1)\n",
    "theoretical_se = pop_std / np.sqrt(sample_size)\n",
    "\n",
    "print(f\"\\nSampling Distribution Results:\")\n",
    "print(f\"   Population mean: ${pop_mean:.2f}\")\n",
    "print(f\"   Mean of sample means: ${mean_of_means:.2f}\")\n",
    "print(f\"   Standard error (actual): ${std_of_means:.2f}\")\n",
    "print(f\"   Standard error (theory): ${theoretical_se:.2f}\")\n",
    "print(f\"\\nMagic: The sample means center around the population mean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sampling distribution magic\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(population_spending, bins=50, alpha=0.7, density=True, \n",
    "         color='lightblue', label='Population')\n",
    "plt.axvline(pop_mean, color='red', linestyle='--', linewidth=2, label='Population Mean')\n",
    "plt.title('Original Population\\n(Right-skewed)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sample_means, bins=30, alpha=0.7, density=True, \n",
    "         color='lightcoral', label='Sample Means')\n",
    "plt.axvline(mean_of_means, color='red', linestyle='--', linewidth=2, \n",
    "           label='Mean of Sample Means')\n",
    "plt.title('Sampling Distribution of Means\\n(Beautiful Bell Curve!)')\n",
    "plt.xlabel('Sample Mean ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Amazing transformation: Skewed population → Normal sampling distribution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Power of Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different sample sizes\n",
    "sample_sizes = [10, 25, 50, 100, 500]\n",
    "num_samples = 500\n",
    "\n",
    "results = {}\n",
    "for size in sample_sizes:\n",
    "    means = []\n",
    "    for i in range(num_samples):\n",
    "        sample = np.random.choice(population_spending, size=size, replace=False)\n",
    "        means.append(np.mean(sample))\n",
    "    results[size] = np.array(means)\n",
    "\n",
    "print(\"Sample Size Impact Analysis:\")\n",
    "print(\"Sample Size | Standard Error | Theoretical SE | Accuracy\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for size in sample_sizes:\n",
    "    actual_se = np.std(results[size], ddof=1)\n",
    "    theoretical_se = pop_std / np.sqrt(size)\n",
    "    accuracy = f\"±${1.96 * actual_se:.0f}\" # 95% confidence\n",
    "    \n",
    "    print(f\"    {size:3d}     |     ${actual_se:6.2f}     |     ${theoretical_se:6.2f}     |  {accuracy}\")\n",
    "    \n",
    "print(f\"\\nKey insight: Larger samples → smaller standard error → better estimates!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample size effect\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, size in enumerate(sample_sizes):\n",
    "    axes[i].hist(results[size], bins=25, alpha=0.7, density=True, color=f'C{i}')\n",
    "    axes[i].axvline(pop_mean, color='red', linestyle='--', linewidth=2, \n",
    "                   label='True Mean')\n",
    "    \n",
    "    se = np.std(results[size], ddof=1)\n",
    "    axes[i].set_title(f'Sample Size = {size}\\nStandard Error = ${se:.2f}')\n",
    "    axes[i].set_xlabel('Sample Mean ($)')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide the last subplot\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.suptitle('Sample Size Effect: Larger Samples = More Precise Estimates', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sampling Bias: The Silent Killer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Response Bias Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate response bias: high spenders more likely to respond to surveys\n",
    "response_prob_low = 0.1    # Low spenders rarely respond\n",
    "response_prob_high = 0.8   # High spenders love surveys\n",
    "\n",
    "# Create biased sample\n",
    "biased_sample = []\n",
    "for spending in population_spending[:5000]:  # Use subset for speed\n",
    "    # Higher spenders more likely to respond\n",
    "    response_prob = response_prob_low + (response_prob_high - response_prob_low) * min(spending/200, 1)\n",
    "    if np.random.random() < response_prob:\n",
    "        biased_sample.append(spending)\n",
    "\n",
    "biased_sample = np.array(biased_sample)\n",
    "\n",
    "# Compare results\n",
    "random_mean = np.mean(random_sample)\n",
    "biased_mean = np.mean(biased_sample)\n",
    "bias_amount = biased_mean - pop_mean\n",
    "\n",
    "print(f\"Response Bias Impact:\")\n",
    "print(f\"   Population mean: ${pop_mean:.2f}\")\n",
    "print(f\"   Random sample mean: ${random_mean:.2f}\")\n",
    "print(f\"   Biased sample mean: ${biased_mean:.2f}\")\n",
    "print(f\"\\nBias analysis:\")\n",
    "print(f\"   Random sample error: ${abs(random_mean - pop_mean):.2f}\")\n",
    "print(f\"   Biased sample error: ${abs(bias_amount):.2f}\")\n",
    "print(f\"   Bias makes estimate {abs(bias_amount)/pop_mean:.1%} too high!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bias\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(population_spending, bins=30, alpha=0.7, density=True, color='lightblue')\n",
    "plt.axvline(pop_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'True Mean: ${pop_mean:.0f}')\n",
    "plt.title('Population\\n(The Truth)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(random_sample, bins=30, alpha=0.7, density=True, color='lightgreen')\n",
    "plt.axvline(random_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Sample Mean: ${random_mean:.0f}')\n",
    "plt.title('Random Sample\\n(Good Estimate)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(biased_sample, bins=30, alpha=0.7, density=True, color='lightcoral')\n",
    "plt.axvline(biased_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Biased Mean: ${biased_mean:.0f}')\n",
    "plt.title('Biased Sample\\n(High Spenders Over-represented)')\n",
    "plt.xlabel('Spending ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Lesson: Biased sampling can completely mislead your conclusions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 — Bias Detection (medium)**  \n",
    "Identify potential sources of bias in these sampling scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - identify bias sources\n",
    "bias_scenarios = [\n",
    "    \"Online survey about internet usage habits\",\n",
    "    \"Phone survey conducted during business hours\",\n",
    "    \"University study using only psychology students\", \n",
    "    \"Mall survey about shopping preferences\",\n",
    "    \"Social media poll about political opinions\"\n",
    "]\n",
    "\n",
    "# For each scenario, identify:\n",
    "# 1. What bias is likely present?\n",
    "# 2. Who might be excluded?\n",
    "# 3. How would this affect results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "print(\"Bias Detection Analysis:\")\n",
    "print()\n",
    "\n",
    "bias_analyses = [\n",
    "    {\n",
    "        'scenario': \"Online survey about internet usage\",\n",
    "        'bias_type': \"Selection bias\",\n",
    "        'excluded': \"People with limited internet access\",\n",
    "        'effect': \"Overestimates internet usage in general population\",\n",
    "        'fix': \"Include phone interviews, mail surveys\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Phone survey during business hours\", \n",
    "        'bias_type': \"Response bias\",\n",
    "        'excluded': \"Working people, students\",\n",
    "        'effect': \"Overrepresents retirees, unemployed, stay-at-home parents\",\n",
    "        'fix': \"Call evenings/weekends, use multiple contact methods\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"University study using psychology students\",\n",
    "        'bias_type': \"Convenience sampling bias\",\n",
    "        'excluded': \"Non-students, other majors, different ages\",\n",
    "        'effect': \"Results may not generalize beyond young, educated population\",\n",
    "        'fix': \"Recruit from broader community, multiple universities\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Mall survey about shopping preferences\",\n",
    "        'bias_type': \"Location bias\",\n",
    "        'excluded': \"Online shoppers, people who avoid malls\",\n",
    "        'effect': \"Overrepresents people who like physical shopping\",\n",
    "        'fix': \"Include online surveys, home visits, multiple locations\"\n",
    "    },\n",
    "    {\n",
    "        'scenario': \"Social media poll about political opinions\",\n",
    "        'bias_type': \"Self-selection bias\",\n",
    "        'excluded': \"Non-social media users, people with different political views\",\n",
    "        'effect': \"May skew toward certain demographics or viewpoints\",\n",
    "        'fix': \"Random digit dialing, representative panels\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, analysis in enumerate(bias_analyses, 1):\n",
    "    print(f\"{i}. {analysis['scenario']}\")\n",
    "    print(f\"   Bias type: {analysis['bias_type']}\")\n",
    "    print(f\"   Who's excluded: {analysis['excluded']}\")\n",
    "    print(f\"   Effect: {analysis['effect']}\")\n",
    "    print(f\"   How to fix: {analysis['fix']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Golden rule: Always ask 'Who might we be missing?' and 'Why?'\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real Business Application: Customer Survey Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic customer database\n",
    "np.random.seed(789)\n",
    "n_customers = 50000\n",
    "\n",
    "customer_db = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': np.random.randint(18, 80, n_customers),\n",
    "    'annual_spending': np.random.lognormal(6.5, 0.8, n_customers),\n",
    "    'satisfaction': np.clip(np.random.normal(7.5, 1.8, n_customers), 1, 10),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_customers),\n",
    "    'customer_type': np.random.choice(['Regular', 'Premium', 'VIP'], \n",
    "                                    n_customers, p=[0.7, 0.25, 0.05])\n",
    "})\n",
    "\n",
    "# True population satisfaction\n",
    "true_satisfaction = customer_db['satisfaction'].mean()\n",
    "\n",
    "print(f\"Customer Database: {len(customer_db):,} customers\")\n",
    "print(f\"True average satisfaction: {true_satisfaction:.2f}/10\")\n",
    "print(\"\\nCustomer breakdown:\")\n",
    "print(customer_db['customer_type'].value_counts())\n",
    "print(\"\\nFirst few customers:\")\n",
    "print(customer_db.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 — Survey Design Challenge (hard)**  \n",
    "Design the best sampling strategy for a customer satisfaction survey.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your mission: Design a sampling strategy for 1000 customers\n",
    "# Consider:\n",
    "# 1. What's the population satisfaction mean?\n",
    "# 2. How would simple random sampling perform?\n",
    "# 3. How would stratified sampling (by customer type) perform?\n",
    "# 4. Which method gives better estimates?\n",
    "\n",
    "survey_budget = 1000  # Can survey 1000 customers\n",
    "\n",
    "# Task 1: Population mean\n",
    "\n",
    "\n",
    "# Task 2: Simple random sampling\n",
    "\n",
    "\n",
    "# Task 3: Stratified sampling by customer type\n",
    "\n",
    "\n",
    "# Task 4: Compare methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Task 1: Population satisfaction mean\n",
    "population_satisfaction = customer_db['satisfaction'].mean()\n",
    "print(f\"Task 1 - True Population Satisfaction: {population_satisfaction:.3f}/10\")\n",
    "\n",
    "# Task 2: Simple random sampling\n",
    "random_sample_indices = np.random.choice(customer_db.index, size=survey_budget, replace=False)\n",
    "random_sample_satisfaction = customer_db.loc[random_sample_indices, 'satisfaction'].mean()\n",
    "random_error = abs(random_sample_satisfaction - population_satisfaction)\n",
    "\n",
    "print(f\"\\nTask 2 - Simple Random Sampling:\")\n",
    "print(f\"   Sample mean: {random_sample_satisfaction:.3f}\")\n",
    "print(f\"   Error: {random_error:.3f} points\")\n",
    "\n",
    "# Task 3: Stratified sampling by customer type\n",
    "# Get proportions of each customer type\n",
    "type_counts = customer_db['customer_type'].value_counts()\n",
    "type_props = type_counts / len(customer_db)\n",
    "\n",
    "print(f\"\\nCustomer type proportions:\")\n",
    "for ctype, prop in type_props.items():\n",
    "    print(f\"   {ctype}: {prop:.1%}\")\n",
    "\n",
    "# Calculate sample sizes for each stratum\n",
    "stratified_samples = {}\n",
    "stratified_means = {}\n",
    "\n",
    "total_sampled = 0\n",
    "for ctype in ['Regular', 'Premium']:\n",
    "    n_stratum = int(survey_budget * type_props[ctype])\n",
    "    stratum_data = customer_db[customer_db['customer_type'] == ctype]\n",
    "    sample_indices = np.random.choice(stratum_data.index, size=n_stratum, replace=False)\n",
    "    stratified_samples[ctype] = customer_db.loc[sample_indices, 'satisfaction']\n",
    "    stratified_means[ctype] = stratified_samples[ctype].mean()\n",
    "    total_sampled += n_stratum\n",
    "    print(f\"   {ctype}: {n_stratum} customers sampled\")\n",
    "\n",
    "# Handle VIP (small group - sample remaining)\n",
    "n_vip = survey_budget - total_sampled\n",
    "vip_data = customer_db[customer_db['customer_type'] == 'VIP']\n",
    "vip_sample_indices = np.random.choice(vip_data.index, size=min(n_vip, len(vip_data)), replace=False)\n",
    "stratified_samples['VIP'] = customer_db.loc[vip_sample_indices, 'satisfaction']\n",
    "stratified_means['VIP'] = stratified_samples['VIP'].mean()\n",
    "print(f\"   VIP: {len(vip_sample_indices)} customers sampled\")\n",
    "\n",
    "# Calculate weighted average\n",
    "stratified_overall = 0\n",
    "for ctype, mean_sat in stratified_means.items():\n",
    "    weight = type_props[ctype]\n",
    "    stratified_overall += weight * mean_sat\n",
    "\n",
    "stratified_error = abs(stratified_overall - population_satisfaction)\n",
    "\n",
    "print(f\"\\nTask 3 - Stratified Sampling Results:\")\n",
    "for ctype, mean_sat in stratified_means.items():\n",
    "    print(f\"   {ctype} satisfaction: {mean_sat:.3f}\")\n",
    "print(f\"   Weighted average: {stratified_overall:.3f}\")\n",
    "print(f\"   Error: {stratified_error:.3f} points\")\n",
    "\n",
    "# Task 4: Compare methods\n",
    "print(f\"\\nTask 4 - Method Comparison:\")\n",
    "print(f\"   Population truth: {population_satisfaction:.3f}\")\n",
    "print(f\"   Random sampling error: {random_error:.3f}\")\n",
    "print(f\"   Stratified sampling error: {stratified_error:.3f}\")\n",
    "\n",
    "if stratified_error < random_error:\n",
    "    print(f\"   Winner: Stratified sampling (better by {random_error - stratified_error:.3f} points)\")\n",
    "    print(f\"   Why: Ensures all customer types are properly represented\")\n",
    "else:\n",
    "    print(f\"   Winner: Random sampling (better by {stratified_error - random_error:.3f} points)\")\n",
    "    print(f\"   Note: This can happen by chance, but stratified is usually better\")\n",
    "\n",
    "print(f\"\\nBusiness recommendation:\")\n",
    "print(f\"   Use stratified sampling to ensure insights from all customer segments\")\n",
    "print(f\"   This prevents VIP customers (only 5%) from being missed entirely\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. The Standard Error Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the standard error formula: SE = σ/√n\n",
    "population_std = np.std(population_spending)\n",
    "test_sizes = [25, 100, 400, 1600, 6400]\n",
    "\n",
    "print(\"Standard Error Formula Validation:\")\n",
    "print(\"Sample Size | Theoretical SE | Empirical SE | Difference\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for n in test_sizes:\n",
    "    # Theoretical standard error\n",
    "    theoretical_se = population_std / np.sqrt(n)\n",
    "    \n",
    "    # Empirical standard error (from 500 samples)\n",
    "    sample_means = []\n",
    "    for i in range(500):\n",
    "        sample = np.random.choice(population_spending, size=n, replace=True)\n",
    "        sample_means.append(np.mean(sample))\n",
    "    empirical_se = np.std(sample_means, ddof=1)\n",
    "    \n",
    "    difference = abs(theoretical_se - empirical_se)\n",
    "    \n",
    "    print(f\"    {n:4d}    |     ${theoretical_se:7.2f}    |    ${empirical_se:7.2f}   |   ${difference:.2f}\")\n",
    "\n",
    "print(f\"\\nKey insights:\")\n",
    "print(f\"• Standard error decreases as sample size increases\")\n",
    "print(f\"• To cut error in half, need 4x the sample size\")\n",
    "print(f\"• Formula works regardless of population size!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mini-Challenges\n",
    "- **M1 (easy):** Design a sampling strategy for employee satisfaction across departments\n",
    "- **M2 (medium):** Build a bias detection system for survey data\n",
    "- **M3 (hard):** Create a sample size calculator for different precision requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n",
    "# M1 Data: 10,000 employees across 5 departments with different sizes\n",
    "# M2 Data: Survey responses with potential demographic biases\n",
    "# M3 Data: Business scenarios requiring different levels of precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - Employee Satisfaction Sampling Strategy\n",
    "np.random.seed(123)\n",
    "departments = {\n",
    "    'Engineering': 4000,\n",
    "    'Sales': 2500, \n",
    "    'Marketing': 1500,\n",
    "    'HR': 1000,\n",
    "    'Operations': 1000\n",
    "}\n",
    "total_employees = sum(departments.values())\n",
    "survey_size = 500\n",
    "\n",
    "print(\"M1 - Employee Satisfaction Sampling:\")\n",
    "print(f\"Total employees: {total_employees:,}\")\n",
    "print(f\"Survey budget: {survey_size} employees\")\n",
    "print(\"\\nStratified sampling by department:\")\n",
    "\n",
    "for dept, size in departments.items():\n",
    "    proportion = size / total_employees\n",
    "    sample_size = int(survey_size * proportion)\n",
    "    print(f\"   {dept}: {size:,} employees ({proportion:.1%}) → sample {sample_size}\")\n",
    "\n",
    "print(\"\\nWhy stratified? Ensures each department is represented proportionally.\")\n",
    "\n",
    "# M2 - Bias Detection System\n",
    "def detect_response_bias(responses, population_demographics):\n",
    "    \"\"\"Detect if survey responses match population demographics\"\"\"\n",
    "    print(\"\\nM2 - Bias Detection Analysis:\")\n",
    "    \n",
    "    biases_found = []\n",
    "    \n",
    "    for demographic, pop_prop in population_demographics.items():\n",
    "        if demographic in responses.columns:\n",
    "            resp_prop = responses[demographic].mean()\n",
    "            bias = abs(resp_prop - pop_prop)\n",
    "            \n",
    "            if bias > 0.05:  # 5% threshold\n",
    "                biases_found.append((demographic, bias, resp_prop, pop_prop))\n",
    "                \n",
    "            print(f\"   {demographic}: Population {pop_prop:.1%}, Sample {resp_prop:.1%} (bias: {bias:.1%})\")\n",
    "    \n",
    "    if biases_found:\n",
    "        print(f\"\\nBiases detected in: {[b[0] for b in biases_found]}\")\n",
    "        print(\"Recommendation: Weight responses or collect more representative sample\")\n",
    "    else:\n",
    "        print(\"\\nNo significant biases detected - sample appears representative\")\n",
    "\n",
    "# Test bias detection\n",
    "sample_demographics = pd.DataFrame({\n",
    "    'age_over_50': np.random.binomial(1, 0.6, 1000),  # Overrepresented\n",
    "    'college_educated': np.random.binomial(1, 0.8, 1000),  # Overrepresented\n",
    "    'urban': np.random.binomial(1, 0.5, 1000)  # Representative\n",
    "})\n",
    "\n",
    "population_props = {\n",
    "    'age_over_50': 0.4,\n",
    "    'college_educated': 0.6,\n",
    "    'urban': 0.5\n",
    "}\n",
    "\n",
    "detect_response_bias(sample_demographics, population_props)\n",
    "\n",
    "# M3 - Sample Size Calculator\n",
    "def calculate_sample_size(population_std, desired_error, confidence_level=0.95):\n",
    "    \"\"\"Calculate required sample size for desired precision\"\"\"\n",
    "    # Z-score for confidence level\n",
    "    z_scores = {0.90: 1.645, 0.95: 1.96, 0.99: 2.576}\n",
    "    z = z_scores[confidence_level]\n",
    "    \n",
    "    # Sample size formula: n = (z * σ / E)²\n",
    "    n = (z * population_std / desired_error) ** 2\n",
    "    return int(np.ceil(n))\n",
    "\n",
    "print(\"\\nM3 - Sample Size Calculator:\")\n",
    "scenarios = [\n",
    "    (\"Customer satisfaction (1-10 scale)\", 1.5, 0.1),\n",
    "    (\"Average order value\", 25, 2),\n",
    "    (\"Employee productivity score\", 12, 1),\n",
    "    (\"Website load time (seconds)\", 0.8, 0.05)\n",
    "]\n",
    "\n",
    "for scenario, std, error in scenarios:\n",
    "    n_90 = calculate_sample_size(std, error, 0.90)\n",
    "    n_95 = calculate_sample_size(std, error, 0.95)\n",
    "    n_99 = calculate_sample_size(std, error, 0.99)\n",
    "    \n",
    "    print(f\"\\n{scenario}:\")\n",
    "    print(f\"   For ±{error} precision: {n_90} (90%), {n_95} (95%), {n_99} (99%)\")\n",
    "\n",
    "print(\"\\nKey insight: Higher precision and confidence require larger samples!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up & Next Steps\n",
    "✅ You understand the crucial difference between populations and samples  \n",
    "✅ You can choose the right sampling method for any situation  \n",
    "✅ You know how sampling distributions work their magic  \n",
    "✅ You can spot and avoid dangerous sampling biases  \n",
    "✅ You can design professional survey strategies  \n",
    "\n",
    "**Quick Reference Card:**\n",
    "- 🎯 **Population**: Everyone/everything you want to know about\n",
    "- 📊 **Sample**: The subset you actually study\n",
    "- 🔀 **Random**: Best default choice for homogeneous populations\n",
    "- 📚 **Stratified**: Essential when subgroups matter\n",
    "- ⚠️ **Watch for bias**: Always ask \"Who might we be missing?\"\n",
    "- 📏 **Standard Error**: σ/√n (bigger samples = smaller error)\n",
    "\n",
    "**Next:** Central Limit Theorem - Discover the most beautiful theorem in statistics!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"\n",
  },\n",
  "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.13.1"\n",
  }\n",
 },\n",
 "nbformat": 4,\n",
 "nbformat_minor": 4\n}