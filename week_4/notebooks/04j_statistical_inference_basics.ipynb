{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 04 ¬∑ Notebook 10 ‚Äî Statistical Inference Basics: Z-Scores, T-Tests & Confidence Intervals\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master the building blocks of statistical inference with crystal-clear explanations and beautiful visuals.\n",
    "\n",
    "> Format: simple concepts ‚Üí colorful visuals ‚Üí intuitive understanding ‚Üí hands-on practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Understand what z-scores really mean and how to interpret them\n",
    "- Learn when and how to use different types of t-tests\n",
    "- Build intuitive understanding of confidence intervals\n",
    "- See these concepts come alive through colorful, engaging visualizations\n",
    "- Apply these tools to solve real-world problems with confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Z-Scores: Your Statistical GPS\n",
    "**Think of z-scores as GPS coordinates for your data**: They tell you exactly where any data point sits relative to the average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up beautiful seaborn styling\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "colors = sns.color_palette(\"husl\", 10)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a z-score? Let's start with a simple explanation\n",
    "zscore_explanation = {\n",
    "    \"üéØ What it is\": \"A z-score tells you how many standard deviations a value is from the mean\",\n",
    "    \"üìè The formula\": \"z = (your_value - mean) / standard_deviation\",\n",
    "    \"üîç What it means\": \"z = 0 means exactly average, z = 1 means 1 std dev above average\",\n",
    "    \"üìä Why it's useful\": \"Compare apples to oranges by putting everything on the same scale\",\n",
    "    \"üí° Real example\": \"Your test score vs. class average, your height vs. population average\"\n",
    "}\n",
    "\n",
    "print(\"üß≠ Z-Scores: Your Statistical GPS System\")\n",
    "for key, value in zscore_explanation.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "    \n",
    "print(\"\\nüöÄ Let's see z-scores in action with beautiful visualizations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visualizing Z-Scores with Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic dataset: student test scores\n",
    "np.random.seed(42)\n",
    "n_students = 1000\n",
    "test_scores = np.random.normal(75, 12, n_students)  # mean=75, std=12\n",
    "\n",
    "# Calculate z-scores\n",
    "mean_score = np.mean(test_scores)\n",
    "std_score = np.std(test_scores, ddof=1)\n",
    "z_scores = (test_scores - mean_score) / std_score\n",
    "\n",
    "print(f\"üìö Student Test Scores Dataset:\")\n",
    "print(f\"   Number of students: {n_students:,}\")\n",
    "print(f\"   Average score: {mean_score:.1f}\")\n",
    "print(f\"   Standard deviation: {std_score:.1f}\")\n",
    "print(f\"   Score range: {test_scores.min():.1f} to {test_scores.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stunning visualization of original scores vs z-scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Original test scores\n",
    "ax1.hist(test_scores, bins=40, alpha=0.7, color=colors[0], edgecolor='white', linewidth=1)\n",
    "ax1.axvline(mean_score, color=colors[1], linestyle='--', linewidth=3, \n",
    "           label=f'Mean: {mean_score:.1f}')\n",
    "ax1.axvline(mean_score + std_score, color=colors[2], linestyle=':', linewidth=2, \n",
    "           label=f'+1 SD: {mean_score + std_score:.1f}')\n",
    "ax1.axvline(mean_score - std_score, color=colors[2], linestyle=':', linewidth=2, \n",
    "           label=f'-1 SD: {mean_score - std_score:.1f}')\n",
    "ax1.set_title('üìä Original Test Scores\\n(Raw Data)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Test Score', fontsize=12)\n",
    "ax1.set_ylabel('Number of Students', fontsize=12)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Z-scores\n",
    "ax2.hist(z_scores, bins=40, alpha=0.7, color=colors[3], edgecolor='white', linewidth=1)\n",
    "ax2.axvline(0, color=colors[1], linestyle='--', linewidth=3, label='Mean: 0')\n",
    "ax2.axvline(1, color=colors[2], linestyle=':', linewidth=2, label='+1 SD')\n",
    "ax2.axvline(-1, color=colors[2], linestyle=':', linewidth=2, label='-1 SD')\n",
    "ax2.axvline(2, color=colors[4], linestyle=':', linewidth=2, alpha=0.7, label='+2 SD')\n",
    "ax2.axvline(-2, color=colors[4], linestyle=':', linewidth=2, alpha=0.7, label='-2 SD')\n",
    "ax2.set_title('üéØ Z-Scores\\n(Standardized Data)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Z-Score', fontsize=12)\n",
    "ax2.set_ylabel('Number of Students', fontsize=12)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚ú® Amazing! The z-scores have mean=0 and std=1, making comparison so much easier!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Interpreting Z-Scores Like a Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some specific students and their z-scores\n",
    "students_examples = [\n",
    "    (\"Alice\", 95),\n",
    "    (\"Bob\", 85),\n",
    "    (\"Charlie\", 75),\n",
    "    (\"Diana\", 65),\n",
    "    (\"Eve\", 45)\n",
    "]\n",
    "\n",
    "print(\"üéì Individual Student Analysis:\")\n",
    "print(f\"{'Student':<10} | {'Score':<6} | {'Z-Score':<8} | {'Interpretation':<30}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, score in students_examples:\n",
    "    z_score = (score - mean_score) / std_score\n",
    "    \n",
    "    # Create interpretations\n",
    "    if z_score > 2:\n",
    "        interpretation = \"üåü Exceptional (top 2.5%)\"\n",
    "    elif z_score > 1:\n",
    "        interpretation = \"üìà Above average (top 16%)\"\n",
    "    elif z_score > -1:\n",
    "        interpretation = \"üìä Around average (middle 68%)\"\n",
    "    elif z_score > -2:\n",
    "        interpretation = \"üìâ Below average (bottom 16%)\"\n",
    "    else:\n",
    "        interpretation = \"‚ö†Ô∏è Needs support (bottom 2.5%)\"\n",
    "    \n",
    "    print(f\"{name:<10} | {score:<6.0f} | {z_score:<8.2f} | {interpretation}\")\n",
    "\n",
    "print(\"\\nüí° Z-scores make it easy to see who needs help and who's excelling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a beautiful z-score interpretation chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create normal distribution\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = stats.norm.pdf(x)\n",
    "\n",
    "# Plot the main curve\n",
    "plt.plot(x, y, linewidth=3, color=colors[0], label='Normal Distribution')\n",
    "\n",
    "# Color different regions\n",
    "regions = [\n",
    "    (-4, -2, colors[8], \"Bottom 2.5%\"),\n",
    "    (-2, -1, colors[6], \"Below Average\"),\n",
    "    (-1, 1, colors[2], \"Average Range (68%)\"),\n",
    "    (1, 2, colors[4], \"Above Average\"),\n",
    "    (2, 4, colors[3], \"Top 2.5%\")\n",
    "]\n",
    "\n",
    "for start, end, color, label in regions:\n",
    "    x_fill = x[(x >= start) & (x <= end)]\n",
    "    y_fill = stats.norm.pdf(x_fill)\n",
    "    plt.fill_between(x_fill, y_fill, alpha=0.6, color=color, label=label)\n",
    "\n",
    "# Add vertical lines for key z-scores\n",
    "key_z_scores = [-2, -1, 0, 1, 2]\n",
    "for z in key_z_scores:\n",
    "    plt.axvline(z, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.text(z, 0.45, f'z={z}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add example students\n",
    "for name, score in students_examples:\n",
    "    z = (score - mean_score) / std_score\n",
    "    y_pos = stats.norm.pdf(z) + 0.02\n",
    "    plt.annotate(f'{name}\\n({score:.0f})', xy=(z, stats.norm.pdf(z)), \n",
    "                xytext=(z, y_pos), ha='center', fontsize=9,\n",
    "                arrowprops=dict(arrowstyle='->', color='black', alpha=0.7))\n",
    "\n",
    "plt.title('üéØ The Z-Score Universe: Where Does Everyone Stand?', \n",
    "         fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Z-Score (Standard Deviations from Mean)', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Beautiful! Now you can see exactly where everyone stands in the big picture!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 ‚Äî Z-Score Detective (easy)**  \n",
    "Calculate and interpret z-scores for different scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: You're analyzing employee salaries at a company\n",
    "# Company salary data: mean = $65,000, standard deviation = $12,000\n",
    "\n",
    "company_mean_salary = 65000\n",
    "company_std_salary = 12000\n",
    "\n",
    "employees = [\n",
    "    (\"Manager Alex\", 85000),\n",
    "    (\"Developer Sam\", 72000),\n",
    "    (\"Intern Jordan\", 35000),\n",
    "    (\"Senior Dev Taylor\", 95000)\n",
    "]\n",
    "\n",
    "print(\"üí∞ Company Salary Analysis Exercise:\")\n",
    "print(f\"   Company average: ${company_mean_salary:,}\")\n",
    "print(f\"   Standard deviation: ${company_std_salary:,}\")\n",
    "print(\"\\nYour task: Calculate z-scores and interpret them!\")\n",
    "\n",
    "# Your code here - calculate z-scores for each employee\n",
    "# Then interpret: Are they above/below average? By how much?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "print(\"üí∞ Employee Salary Z-Score Analysis:\")\n",
    "print(f\"{'Employee':<15} | {'Salary':<8} | {'Z-Score':<8} | {'Interpretation':<25}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, salary in employees:\n",
    "    z_score = (salary - company_mean_salary) / company_std_salary\n",
    "    \n",
    "    # Interpretation based on z-score\n",
    "    if z_score > 2:\n",
    "        interpretation = \"üåü Top tier (>2 SD above)\"\n",
    "    elif z_score > 1:\n",
    "        interpretation = \"üìà Well above average\"\n",
    "    elif z_score > 0:\n",
    "        interpretation = \"‚ÜóÔ∏è Above average\"\n",
    "    elif z_score > -1:\n",
    "        interpretation = \"‚ÜôÔ∏è Below average\"\n",
    "    elif z_score > -2:\n",
    "        interpretation = \"üìâ Well below average\"\n",
    "    else:\n",
    "        interpretation = \"‚ö†Ô∏è Significantly low\"\n",
    "    \n",
    "    print(f\"{name:<15} | ${salary:<7,} | {z_score:<8.2f} | {interpretation}\")\n",
    "\n",
    "print(\"\\nüîç Key Insights:\")\n",
    "print(\"   ‚Ä¢ Manager Alex: 1.67 SD above mean - doing well!\")\n",
    "print(\"   ‚Ä¢ Developer Sam: Only 0.58 SD above mean - room for growth\")\n",
    "print(\"   ‚Ä¢ Intern Jordan: 2.5 SD below mean - typical for internship\")\n",
    "print(\"   ‚Ä¢ Senior Dev Taylor: 2.5 SD above mean - top performer salary!\")\n",
    "\n",
    "# Bonus visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_salary = np.linspace(30000, 110000, 1000)\n",
    "y_norm = stats.norm.pdf((x_salary - company_mean_salary) / company_std_salary) / company_std_salary\n",
    "\n",
    "plt.plot(x_salary, y_norm, linewidth=3, color=colors[0], alpha=0.7)\n",
    "plt.axvline(company_mean_salary, color=colors[1], linestyle='--', linewidth=2, \n",
    "           label=f'Company Average: ${company_mean_salary:,}')\n",
    "\n",
    "# Plot each employee\n",
    "for i, (name, salary) in enumerate(employees):\n",
    "    z = (salary - company_mean_salary) / company_std_salary\n",
    "    y_pos = stats.norm.pdf(z) / company_std_salary\n",
    "    plt.scatter(salary, y_pos, s=200, color=colors[i+2], zorder=5, alpha=0.8)\n",
    "    plt.annotate(name.split()[1], (salary, y_pos), xytext=(5, 10), \n",
    "                textcoords='offset points', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.title('üí∞ Employee Salaries vs Company Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Salary ($)', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. T-Tests: Comparing Groups Like a Scientist\n",
    "**T-tests answer the question**: \"Are these two groups really different, or could the difference just be random chance?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test explanation in simple terms\n",
    "ttest_explanation = {\n",
    "    \"ü§î The Question\": \"Is the difference between groups real or just random?\",\n",
    "    \"‚öñÔ∏è One-Sample T-Test\": \"Compare a group average to a known value\",\n",
    "    \"üë• Two-Sample T-Test\": \"Compare averages between two different groups\",\n",
    "    \"üîó Paired T-Test\": \"Compare before/after measurements on same people\",\n",
    "    \"üìä The Magic\": \"T-tests work even with small samples (unlike z-tests)\",\n",
    "    \"üí° Real Use\": \"Does this medicine work? Are men taller than women? Did training help?\"\n",
    "}\n",
    "\n",
    "print(\"üß™ T-Tests: The Scientific Comparison Tool\")\n",
    "for key, value in ttest_explanation.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "    \n",
    "print(\"\\nüéØ Let's see t-tests solve real problems with gorgeous visuals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One-Sample T-Test: Is Our Group Special?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: A fitness trainer claims her program increases average weight loss\n",
    "# National average weight loss for similar programs: 5 pounds\n",
    "# Her program results for 25 participants:\n",
    "\n",
    "np.random.seed(123)\n",
    "national_average = 5.0\n",
    "program_results = np.random.normal(6.8, 2.1, 25)  # Her program seems better!\n",
    "\n",
    "# Calculate sample statistics\n",
    "sample_mean = np.mean(program_results)\n",
    "sample_std = np.std(program_results, ddof=1)\n",
    "n = len(program_results)\n",
    "\n",
    "print(f\"üèãÔ∏è Fitness Program Evaluation:\")\n",
    "print(f\"   National average weight loss: {national_average} pounds\")\n",
    "print(f\"   Our program average: {sample_mean:.2f} pounds\")\n",
    "print(f\"   Sample size: {n} participants\")\n",
    "print(f\"   Standard deviation: {sample_std:.2f} pounds\")\n",
    "print(f\"\\n‚ùì Question: Is our program significantly better than the national average?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-sample t-test\n",
    "t_statistic, p_value = stats.ttest_1samp(program_results, national_average)\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "df = n - 1\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "margin_error = t_critical * (sample_std / np.sqrt(n))\n",
    "ci_lower = sample_mean - margin_error\n",
    "ci_upper = sample_mean + margin_error\n",
    "\n",
    "print(f\"üìä One-Sample T-Test Results:\")\n",
    "print(f\"   T-statistic: {t_statistic:.3f}\")\n",
    "print(f\"   P-value: {p_value:.4f}\")\n",
    "print(f\"   95% Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}] pounds\")\n",
    "print(f\"\\nüéØ Interpretation:\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"   ‚úÖ YES! Our program IS significantly better (p < 0.05)\")\n",
    "    print(f\"   üéâ The difference is statistically significant!\")\n",
    "else:\n",
    "    print(f\"   ‚ùå No significant difference found (p ‚â• 0.05)\")\n",
    "    print(f\"   ü§∑ Could just be random chance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stunning visualization of the one-sample t-test\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Sample data vs national average\n",
    "ax1.hist(program_results, bins=12, alpha=0.7, color=colors[0], \n",
    "         edgecolor='white', linewidth=2, label='Our Program Results')\n",
    "ax1.axvline(sample_mean, color=colors[1], linestyle='-', linewidth=3, \n",
    "           label=f'Our Average: {sample_mean:.1f} lbs')\n",
    "ax1.axvline(national_average, color=colors[2], linestyle='--', linewidth=3, \n",
    "           label=f'National Average: {national_average} lbs')\n",
    "\n",
    "# Add confidence interval\n",
    "ax1.axvspan(ci_lower, ci_upper, alpha=0.2, color=colors[3], \n",
    "           label=f'95% CI: [{ci_lower:.1f}, {ci_upper:.1f}]')\n",
    "\n",
    "ax1.set_title('üèãÔ∏è Our Program vs National Average', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Weight Loss (pounds)', fontsize=12)\n",
    "ax1.set_ylabel('Number of Participants', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: T-distribution with our t-statistic\n",
    "x_t = np.linspace(-4, 4, 1000)\n",
    "y_t = stats.t.pdf(x_t, df)\n",
    "\n",
    "ax2.plot(x_t, y_t, linewidth=3, color=colors[4], label=f't-distribution (df={df})')\n",
    "ax2.axvline(t_statistic, color=colors[1], linestyle='-', linewidth=3, \n",
    "           label=f'Our t-statistic: {t_statistic:.2f}')\n",
    "ax2.axvline(-t_statistic, color=colors[1], linestyle='-', linewidth=3, alpha=0.5)\n",
    "\n",
    "# Shade p-value region\n",
    "if p_value < 0.05:\n",
    "    x_shade_right = x_t[x_t >= t_statistic]\n",
    "    y_shade_right = stats.t.pdf(x_shade_right, df)\n",
    "    ax2.fill_between(x_shade_right, y_shade_right, alpha=0.3, color=colors[2], \n",
    "                    label=f'p-value region')\n",
    "    \n",
    "    x_shade_left = x_t[x_t <= -t_statistic]\n",
    "    y_shade_left = stats.t.pdf(x_shade_left, df)\n",
    "    ax2.fill_between(x_shade_left, y_shade_left, alpha=0.3, color=colors[2])\n",
    "\n",
    "ax2.set_title(f'üìà T-Test Results\\np-value = {p_value:.4f}', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('T-statistic', fontsize=12)\n",
    "ax2.set_ylabel('Probability Density', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "significance_emoji = \"üéâ\" if p_value < 0.05 else \"ü§î\"\n",
    "print(f\"{significance_emoji} The visual story tells us everything we need to know!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Two-Sample T-Test: Battle of the Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Does a new teaching method improve test scores?\n",
    "# Traditional method vs New method\n",
    "\n",
    "np.random.seed(456)\n",
    "traditional_scores = np.random.normal(78, 8, 30)  # Traditional teaching\n",
    "new_method_scores = np.random.normal(83, 9, 32)   # New teaching method\n",
    "\n",
    "# Calculate statistics for both groups\n",
    "trad_mean, trad_std = np.mean(traditional_scores), np.std(traditional_scores, ddof=1)\n",
    "new_mean, new_std = np.mean(new_method_scores), np.std(new_method_scores, ddof=1)\n",
    "\n",
    "print(f\"üìö Teaching Method Comparison:\")\n",
    "print(f\"   Traditional Method: {len(traditional_scores)} students, avg = {trad_mean:.1f} ¬± {trad_std:.1f}\")\n",
    "print(f\"   New Method: {len(new_method_scores)} students, avg = {new_mean:.1f} ¬± {new_std:.1f}\")\n",
    "print(f\"   Difference in averages: {new_mean - trad_mean:.1f} points\")\n",
    "print(f\"\\n‚ùì Question: Is the new method significantly better?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two-sample t-test\n",
    "t_stat_2samp, p_val_2samp = stats.ttest_ind(new_method_scores, traditional_scores)\n",
    "\n",
    "# Calculate effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(traditional_scores)-1)*trad_std**2 + \n",
    "                     (len(new_method_scores)-1)*new_std**2) / \n",
    "                    (len(traditional_scores) + len(new_method_scores) - 2))\n",
    "cohens_d = (new_mean - trad_mean) / pooled_std\n",
    "\n",
    "print(f\"üìä Two-Sample T-Test Results:\")\n",
    "print(f\"   T-statistic: {t_stat_2samp:.3f}\")\n",
    "print(f\"   P-value: {p_val_2samp:.4f}\")\n",
    "print(f\"   Cohen's d (effect size): {cohens_d:.3f}\")\n",
    "\n",
    "# Effect size interpretation\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_interpretation = \"Small effect\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_interpretation = \"Medium effect\"\n",
    "else:\n",
    "    effect_interpretation = \"Large effect\"\n",
    "\n",
    "print(f\"\\nüéØ Interpretation:\")\n",
    "if p_val_2samp < 0.05:\n",
    "    print(f\"   ‚úÖ YES! New method is significantly better (p < 0.05)\")\n",
    "    print(f\"   üìà Effect size: {effect_interpretation} (d = {cohens_d:.2f})\")\n",
    "else:\n",
    "    print(f\"   ‚ùå No significant difference (p ‚â• 0.05)\")\n",
    "    print(f\"   üìä Effect size: {effect_interpretation} (d = {cohens_d:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spectacular visualization of two-sample t-test\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Top left: Histograms of both groups\n",
    "ax1.hist(traditional_scores, bins=15, alpha=0.7, color=colors[0], \n",
    "         label=f'Traditional (n={len(traditional_scores)})', edgecolor='white')\n",
    "ax1.hist(new_method_scores, bins=15, alpha=0.7, color=colors[1], \n",
    "         label=f'New Method (n={len(new_method_scores)})', edgecolor='white')\n",
    "ax1.axvline(trad_mean, color=colors[0], linestyle='--', linewidth=2)\n",
    "ax1.axvline(new_mean, color=colors[1], linestyle='--', linewidth=2)\n",
    "ax1.set_title('üìä Score Distributions by Teaching Method', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Test Score')\n",
    "ax1.set_ylabel('Number of Students')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Top right: Box plots\n",
    "box_data = [traditional_scores, new_method_scores]\n",
    "bp = ax2.boxplot(box_data, labels=['Traditional', 'New Method'], \n",
    "                patch_artist=True, notch=True)\n",
    "bp['boxes'][0].set_facecolor(colors[0])\n",
    "bp['boxes'][1].set_facecolor(colors[1])\n",
    "ax2.set_title('üì¶ Box Plot Comparison', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Test Score')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom left: Individual data points\n",
    "x1 = np.random.normal(1, 0.04, len(traditional_scores))\n",
    "x2 = np.random.normal(2, 0.04, len(new_method_scores))\n",
    "ax3.scatter(x1, traditional_scores, alpha=0.6, color=colors[0], s=50, label='Traditional')\n",
    "ax3.scatter(x2, new_method_scores, alpha=0.6, color=colors[1], s=50, label='New Method')\n",
    "ax3.hlines(trad_mean, 0.7, 1.3, colors=colors[0], linewidth=4, label=f'Trad Mean: {trad_mean:.1f}')\n",
    "ax3.hlines(new_mean, 1.7, 2.3, colors=colors[1], linewidth=4, label=f'New Mean: {new_mean:.1f}')\n",
    "ax3.set_title('üéØ Individual Student Scores', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks([1, 2])\n",
    "ax3.set_xticklabels(['Traditional', 'New Method'])\n",
    "ax3.set_ylabel('Test Score')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom right: T-distribution with test statistic\n",
    "df_total = len(traditional_scores) + len(new_method_scores) - 2\n",
    "x_t = np.linspace(-4, 4, 1000)\n",
    "y_t = stats.t.pdf(x_t, df_total)\n",
    "ax4.plot(x_t, y_t, linewidth=3, color=colors[2], label=f't-distribution (df={df_total})')\n",
    "ax4.axvline(t_stat_2samp, color=colors[3], linestyle='-', linewidth=3, \n",
    "           label=f't = {t_stat_2samp:.2f}')\n",
    "\n",
    "# Shade p-value region if significant\n",
    "if p_val_2samp < 0.05:\n",
    "    x_shade = x_t[x_t >= t_stat_2samp]\n",
    "    y_shade = stats.t.pdf(x_shade, df_total)\n",
    "    ax4.fill_between(x_shade, y_shade, alpha=0.3, color=colors[4], \n",
    "                    label=f'p = {p_val_2samp:.3f}')\n",
    "\n",
    "ax4.set_title('üìà Statistical Test Results', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('T-statistic')\n",
    "ax4.set_ylabel('Probability Density')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üé® Four different views, one clear conclusion: The visual evidence is overwhelming!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 ‚Äî Medical Treatment Comparison (medium)**  \n",
    "Compare recovery times between two treatments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical scenario: Compare recovery times between two treatments\n",
    "np.random.seed(789)\n",
    "\n",
    "# Treatment A: Standard care (recovery days)\n",
    "treatment_a = np.random.normal(12.5, 3.2, 28)\n",
    "\n",
    "# Treatment B: New therapy (hopefully faster recovery)\n",
    "treatment_b = np.random.normal(10.1, 2.8, 25)\n",
    "\n",
    "print(f\"üè• Medical Treatment Comparison:\")\n",
    "print(f\"   Treatment A (Standard): {len(treatment_a)} patients\")\n",
    "print(f\"   Treatment B (New): {len(treatment_b)} patients\")\n",
    "print(f\"   Question: Does Treatment B lead to faster recovery?\")\n",
    "print(f\"\\nYour tasks:\")\n",
    "print(f\"   1. Calculate descriptive statistics for both groups\")\n",
    "print(f\"   2. Perform a two-sample t-test\")\n",
    "print(f\"   3. Calculate and interpret effect size\")\n",
    "print(f\"   4. Make a medical recommendation\")\n",
    "\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Task 1: Descriptive statistics\n",
    "a_mean, a_std = np.mean(treatment_a), np.std(treatment_a, ddof=1)\n",
    "b_mean, b_std = np.mean(treatment_b), np.std(treatment_b, ddof=1)\n",
    "\n",
    "print(f\"üìä Descriptive Statistics:\")\n",
    "print(f\"   Treatment A: Mean = {a_mean:.2f} days, SD = {a_std:.2f}\")\n",
    "print(f\"   Treatment B: Mean = {b_mean:.2f} days, SD = {b_std:.2f}\")\n",
    "print(f\"   Difference: {a_mean - b_mean:.2f} days faster with B\")\n",
    "\n",
    "# Task 2: Two-sample t-test\n",
    "t_stat, p_val = stats.ttest_ind(treatment_a, treatment_b)\n",
    "\n",
    "print(f\"\\nüî¨ Two-Sample T-Test:\")\n",
    "print(f\"   T-statistic: {t_stat:.3f}\")\n",
    "print(f\"   P-value: {p_val:.4f}\")\n",
    "\n",
    "# Task 3: Effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(treatment_a)-1)*a_std**2 + \n",
    "                     (len(treatment_b)-1)*b_std**2) / \n",
    "                    (len(treatment_a) + len(treatment_b) - 2))\n",
    "cohens_d = (a_mean - b_mean) / pooled_std\n",
    "\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_size = \"Small\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_size = \"Medium\" \n",
    "else:\n",
    "    effect_size = \"Large\"\n",
    "\n",
    "print(f\"\\nüìè Effect Size Analysis:\")\n",
    "print(f\"   Cohen's d: {cohens_d:.3f}\")\n",
    "print(f\"   Effect size: {effect_size}\")\n",
    "\n",
    "# Task 4: Medical recommendation\n",
    "print(f\"\\nüè• Medical Recommendation:\")\n",
    "if p_val < 0.05:\n",
    "    print(f\"   ‚úÖ SIGNIFICANT IMPROVEMENT with Treatment B!\")\n",
    "    print(f\"   üìà Patients recover {a_mean - b_mean:.1f} days faster on average\")\n",
    "    print(f\"   üíä Recommend adopting Treatment B\")\n",
    "    if cohens_d > 0.8:\n",
    "        print(f\"   üåü The improvement is not just significant but also clinically meaningful!\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è No statistically significant difference found\")\n",
    "    print(f\"   ü§î More research needed before changing protocols\")\n",
    "\n",
    "# Bonus: Beautiful medical visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(treatment_a, bins=12, alpha=0.7, color=colors[5], \n",
    "         label=f'Treatment A\\nMean: {a_mean:.1f} days', edgecolor='white')\n",
    "plt.hist(treatment_b, bins=12, alpha=0.7, color=colors[6], \n",
    "         label=f'Treatment B\\nMean: {b_mean:.1f} days', edgecolor='white')\n",
    "plt.axvline(a_mean, color=colors[5], linestyle='--', linewidth=2)\n",
    "plt.axvline(b_mean, color=colors[6], linestyle='--', linewidth=2)\n",
    "plt.title('üè• Recovery Time Distributions', fontweight='bold')\n",
    "plt.xlabel('Recovery Time (days)')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "box_data = [treatment_a, treatment_b]\n",
    "bp = plt.boxplot(box_data, labels=['Treatment A\\n(Standard)', 'Treatment B\\n(New)'], \n",
    "                patch_artist=True, notch=True)\n",
    "bp['boxes'][0].set_facecolor(colors[5])\n",
    "bp['boxes'][1].set_facecolor(colors[6])\n",
    "plt.title('üì¶ Treatment Comparison\\n(Lower is Better)', fontweight='bold')\n",
    "plt.ylabel('Recovery Time (days)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ Clinical Significance: Treatment B shows both statistical and practical improvement!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confidence Intervals: Embracing Uncertainty with Style\n",
    "**Confidence intervals tell you**: \"We're 95% confident the true value lies somewhere in this range.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence interval explanation\n",
    "ci_explanation = {\n",
    "    \"üéØ What it is\": \"A range of plausible values for the true population parameter\",\n",
    "    \"üìä 95% CI meaning\": \"If we repeated this study 100 times, 95 CIs would contain the true value\",\n",
    "    \"üìè Width tells us\": \"Narrow CI = precise estimate, Wide CI = uncertain estimate\",\n",
    "    \"üîç How to improve\": \"Larger sample size = narrower confidence interval\",\n",
    "    \"üí° Business use\": \"Customer satisfaction is 7.2 ¬± 0.3 points (95% CI: 6.9 to 7.5)\"\n",
    "}\n",
    "\n",
    "print(\"üéØ Confidence Intervals: Quantifying Our Uncertainty\")\n",
    "for key, value in ci_explanation.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "    \n",
    "print(\"\\n‚ú® Let's see confidence intervals in action with stunning visuals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Building Confidence Intervals Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Estimating average customer satisfaction score\n",
    "np.random.seed(999)\n",
    "true_satisfaction = 7.3  # Unknown to us in real life\n",
    "customer_ratings = np.random.normal(true_satisfaction, 1.5, 45)\n",
    "\n",
    "# Calculate sample statistics\n",
    "sample_mean = np.mean(customer_ratings)\n",
    "sample_std = np.std(customer_ratings, ddof=1)\n",
    "n = len(customer_ratings)\n",
    "standard_error = sample_std / np.sqrt(n)\n",
    "\n",
    "print(f\"‚≠ê Customer Satisfaction Survey:\")\n",
    "print(f\"   Sample size: {n} customers\")\n",
    "print(f\"   Sample mean: {sample_mean:.3f}\")\n",
    "print(f\"   Sample std: {sample_std:.3f}\")\n",
    "print(f\"   Standard error: {standard_error:.3f}\")\n",
    "print(f\"   (True satisfaction: {true_satisfaction} - but we don't know this!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence intervals for different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "df = n - 1\n",
    "\n",
    "print(f\"üéØ Confidence Intervals for Customer Satisfaction:\")\n",
    "print(f\"{'Confidence':<12} | {'Lower':<8} | {'Upper':<8} | {'Width':<8} | {'Contains True?':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "ci_data = []\n",
    "for conf_level in confidence_levels:\n",
    "    alpha = 1 - conf_level\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "    margin_error = t_critical * standard_error\n",
    "    \n",
    "    ci_lower = sample_mean - margin_error\n",
    "    ci_upper = sample_mean + margin_error\n",
    "    width = ci_upper - ci_lower\n",
    "    \n",
    "    contains_true = ci_lower <= true_satisfaction <= ci_upper\n",
    "    contains_emoji = \"‚úÖ Yes\" if contains_true else \"‚ùå No\"\n",
    "    \n",
    "    ci_data.append((conf_level, ci_lower, ci_upper, width, contains_true))\n",
    "    \n",
    "    print(f\"   {conf_level:.0%}      | {ci_lower:8.3f} | {ci_upper:8.3f} | {width:8.3f} | {contains_emoji}\")\n",
    "\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "print(f\"   ‚Ä¢ Higher confidence = wider intervals (trade-off between precision and confidence)\")\n",
    "print(f\"   ‚Ä¢ All intervals should contain the true value (if our assumptions are correct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create magnificent confidence interval visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Top plot: Sample data with confidence intervals\n",
    "ax1.hist(customer_ratings, bins=15, alpha=0.6, color=colors[0], \n",
    "         edgecolor='white', linewidth=2, label='Customer Ratings')\n",
    "ax1.axvline(sample_mean, color=colors[1], linestyle='-', linewidth=4, \n",
    "           label=f'Sample Mean: {sample_mean:.2f}')\n",
    "ax1.axvline(true_satisfaction, color=colors[2], linestyle=':', linewidth=4, \n",
    "           alpha=0.8, label=f'True Satisfaction: {true_satisfaction}')\n",
    "\n",
    "# Add confidence intervals as colored bands\n",
    "colors_ci = [colors[3], colors[4], colors[5]]\n",
    "alphas = [0.2, 0.25, 0.3]\n",
    "\n",
    "for i, (conf_level, ci_lower, ci_upper, width, contains_true) in enumerate(ci_data):\n",
    "    ax1.axvspan(ci_lower, ci_upper, alpha=alphas[i], color=colors_ci[i], \n",
    "               label=f'{conf_level:.0%} CI: [{ci_lower:.2f}, {ci_upper:.2f}]')\n",
    "\n",
    "ax1.set_title('‚≠ê Customer Satisfaction with Confidence Intervals', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Satisfaction Rating (1-10)')\n",
    "ax1.set_ylabel('Number of Customers')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom plot: Confidence intervals as error bars\n",
    "conf_percentages = [int(cl*100) for cl in confidence_levels]\n",
    "means = [sample_mean] * len(confidence_levels)\n",
    "errors = [(ci_data[i][2] - ci_data[i][1])/2 for i in range(len(ci_data))]\n",
    "\n",
    "bars = ax2.errorbar(conf_percentages, means, yerr=errors, fmt='o', \n",
    "                   capsize=10, capthick=3, markersize=12, linewidth=3,\n",
    "                   color=colors[6], ecolor=colors[7])\n",
    "\n",
    "ax2.axhline(true_satisfaction, color=colors[2], linestyle=':', linewidth=3, \n",
    "           alpha=0.8, label=f'True Value: {true_satisfaction}')\n",
    "ax2.axhline(sample_mean, color=colors[1], linestyle='-', linewidth=2, \n",
    "           alpha=0.6, label=f'Sample Mean: {sample_mean:.2f}')\n",
    "\n",
    "ax2.set_title('üéØ Confidence Interval Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Confidence Level (%)')\n",
    "ax2.set_ylabel('Satisfaction Rating')\n",
    "ax2.set_xticks(conf_percentages)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üé® Beautiful! You can see how confidence intervals expand as we demand more certainty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Power of Sample Size on Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how sample size affects confidence interval width\n",
    "sample_sizes = [10, 25, 50, 100, 200, 500]\n",
    "true_mean = 50\n",
    "true_std = 15\n",
    "confidence_level = 0.95\n",
    "\n",
    "print(f\"üìè How Sample Size Affects Confidence Interval Precision:\")\n",
    "print(f\"   True population: Mean = {true_mean}, Std = {true_std}\")\n",
    "print(f\"   Confidence level: {confidence_level:.0%}\")\n",
    "print(f\"\\n{'Sample Size':<12} | {'CI Width':<10} | {'Margin of Error':<15} | {'Precision':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "sample_size_data = []\n",
    "np.random.seed(1001)\n",
    "\n",
    "for n in sample_sizes:\n",
    "    # Generate sample\n",
    "    sample = np.random.normal(true_mean, true_std, n)\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    \n",
    "    # Calculate CI\n",
    "    se = sample_std / np.sqrt(n)\n",
    "    t_crit = stats.t.ppf(1 - (1-confidence_level)/2, n-1)\n",
    "    margin_error = t_crit * se\n",
    "    ci_width = 2 * margin_error\n",
    "    \n",
    "    # Precision is inverse of width\n",
    "    precision = 1 / ci_width\n",
    "    \n",
    "    sample_size_data.append((n, sample_mean, ci_width, margin_error))\n",
    "    \n",
    "    precision_desc = \"Low\" if ci_width > 10 else \"Medium\" if ci_width > 5 else \"High\"\n",
    "    \n",
    "    print(f\"    {n:<8}    | {ci_width:<10.2f} | {margin_error:<15.2f} | {precision_desc}\")\n",
    "\n",
    "print(f\"\\nüìà Key Insight: Doubling sample size reduces CI width by ~30% (not 50%!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stunning sample size effect visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Confidence intervals by sample size\n",
    "y_positions = range(len(sample_sizes))\n",
    "means = [data[1] for data in sample_size_data]\n",
    "margins = [data[3] for data in sample_size_data]\n",
    "\n",
    "# Create horizontal error bars\n",
    "for i, (n, sample_mean, ci_width, margin_error) in enumerate(sample_size_data):\n",
    "    color = colors[i % len(colors)]\n",
    "    ax1.errorbar(sample_mean, i, xerr=margin_error, fmt='o', \n",
    "                capsize=8, capthick=2, markersize=10, \n",
    "                color=color, ecolor=color, alpha=0.8,\n",
    "                label=f'n={n}')\n",
    "\n",
    "ax1.axvline(true_mean, color='red', linestyle='--', linewidth=3, \n",
    "           alpha=0.7, label=f'True Mean: {true_mean}')\n",
    "ax1.set_yticks(y_positions)\n",
    "ax1.set_yticklabels([f'n={n}' for n in sample_sizes])\n",
    "ax1.set_title('üéØ Confidence Intervals vs Sample Size\\n(Smaller intervals = better precision)', \n",
    "             fontweight='bold')\n",
    "ax1.set_xlabel('Value')\n",
    "ax1.set_ylabel('Sample Size')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: CI width vs sample size\n",
    "widths = [data[2] for data in sample_size_data]\n",
    "ax2.plot(sample_sizes, widths, 'o-', linewidth=3, markersize=10, \n",
    "         color=colors[0], alpha=0.8)\n",
    "ax2.fill_between(sample_sizes, widths, alpha=0.3, color=colors[0])\n",
    "\n",
    "# Add theoretical curve\n",
    "theoretical_widths = [2 * stats.t.ppf(0.975, n-1) * true_std / np.sqrt(n) for n in sample_sizes]\n",
    "ax2.plot(sample_sizes, theoretical_widths, '--', linewidth=2, \n",
    "         color=colors[1], alpha=0.8, label='Theoretical')\n",
    "\n",
    "ax2.set_title('üìè Confidence Interval Width vs Sample Size\\n(Diminishing returns!)', \n",
    "             fontweight='bold')\n",
    "ax2.set_xlabel('Sample Size')\n",
    "ax2.set_ylabel('95% CI Width')\n",
    "ax2.set_xscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üí∞ Business insight: Going from n=100 to n=500 costs 5x more but only improves precision by ~2.2x!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 ‚Äî Marketing Campaign Analysis (hard)**  \n",
    "Build confidence intervals for campaign performance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marketing campaign scenario\n",
    "# You're analyzing click-through rates and conversion rates for an ad campaign\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "# Campaign data\n",
    "n_impressions = 50000\n",
    "n_clicks = 2847  # 5.7% CTR\n",
    "n_conversions = 127  # 4.5% conversion rate from clicks\n",
    "\n",
    "# Additional metrics: time on site for converters (minutes)\n",
    "time_on_site = np.random.gamma(2.5, 2.8, n_conversions)  # Gamma distribution for time data\n",
    "\n",
    "print(f\"üìä Digital Marketing Campaign Analysis:\")\n",
    "print(f\"   Total impressions: {n_impressions:,}\")\n",
    "print(f\"   Total clicks: {n_clicks:,}\")\n",
    "print(f\"   Total conversions: {n_conversions}\")\n",
    "print(f\"   Average time on site (converters): {np.mean(time_on_site):.1f} minutes\")\n",
    "print(f\"\\nYour tasks:\")\n",
    "print(f\"   1. Calculate 95% CI for click-through rate (CTR)\")\n",
    "print(f\"   2. Calculate 95% CI for conversion rate (from clicks to purchases)\")\n",
    "print(f\"   3. Calculate 95% CI for average time on site\")\n",
    "print(f\"   4. Create a comprehensive visualization\")\n",
    "print(f\"   5. Provide business recommendations with uncertainty quantified\")\n",
    "\n",
    "# Your comprehensive analysis here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Task 1: Click-through rate confidence interval\n",
    "ctr = n_clicks / n_impressions\n",
    "ctr_se = np.sqrt(ctr * (1 - ctr) / n_impressions)\n",
    "ctr_margin = 1.96 * ctr_se  # Using normal approximation for large sample\n",
    "ctr_ci_lower = ctr - ctr_margin\n",
    "ctr_ci_upper = ctr + ctr_margin\n",
    "\n",
    "print(f\"üìà Task 1 - Click-Through Rate Analysis:\")\n",
    "print(f\"   CTR: {ctr:.4f} ({ctr:.2%})\")\n",
    "print(f\"   Standard Error: {ctr_se:.6f}\")\n",
    "print(f\"   95% CI: [{ctr_ci_lower:.4f}, {ctr_ci_upper:.4f}] or [{ctr_ci_lower:.2%}, {ctr_ci_upper:.2%}]\")\n",
    "\n",
    "# Task 2: Conversion rate confidence interval\n",
    "conv_rate = n_conversions / n_clicks\n",
    "conv_se = np.sqrt(conv_rate * (1 - conv_rate) / n_clicks)\n",
    "conv_margin = 1.96 * conv_se\n",
    "conv_ci_lower = conv_rate - conv_margin\n",
    "conv_ci_upper = conv_rate + conv_margin\n",
    "\n",
    "print(f\"\\nüí∞ Task 2 - Conversion Rate Analysis:\")\n",
    "print(f\"   Conversion Rate: {conv_rate:.4f} ({conv_rate:.2%})\")\n",
    "print(f\"   Standard Error: {conv_se:.6f}\")\n",
    "print(f\"   95% CI: [{conv_ci_lower:.4f}, {conv_ci_upper:.4f}] or [{conv_ci_lower:.2%}, {conv_ci_upper:.2%}]\")\n",
    "\n",
    "# Task 3: Time on site confidence interval\n",
    "time_mean = np.mean(time_on_site)\n",
    "time_std = np.std(time_on_site, ddof=1)\n",
    "time_se = time_std / np.sqrt(n_conversions)\n",
    "time_df = n_conversions - 1\n",
    "time_t_crit = stats.t.ppf(0.975, time_df)\n",
    "time_margin = time_t_crit * time_se\n",
    "time_ci_lower = time_mean - time_margin\n",
    "time_ci_upper = time_mean + time_margin\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Task 3 - Time on Site Analysis:\")\n",
    "print(f\"   Average Time: {time_mean:.2f} minutes\")\n",
    "print(f\"   Standard Deviation: {time_std:.2f} minutes\")\n",
    "print(f\"   Standard Error: {time_se:.4f}\")\n",
    "print(f\"   95% CI: [{time_ci_lower:.2f}, {time_ci_upper:.2f}] minutes\")\n",
    "\n",
    "# Task 4: Comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: CTR with confidence interval\n",
    "ax1.bar(['Click-Through Rate'], [ctr], color=colors[0], alpha=0.7, \n",
    "        yerr=[[ctr_margin], [ctr_margin]], capsize=10, capthick=3, \n",
    "        error_kw={'color': colors[1], 'linewidth': 2})\n",
    "ax1.set_title('üìà Click-Through Rate\\nwith 95% Confidence Interval', fontweight='bold')\n",
    "ax1.set_ylabel('CTR (%)')\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.text(0, ctr + ctr_margin + 0.001, f'{ctr:.2%} ¬± {ctr_margin:.3%}', \n",
    "         ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 2: Conversion rate with confidence interval\n",
    "ax2.bar(['Conversion Rate'], [conv_rate], color=colors[2], alpha=0.7,\n",
    "        yerr=[[conv_margin], [conv_margin]], capsize=10, capthick=3,\n",
    "        error_kw={'color': colors[3], 'linewidth': 2})\n",
    "ax2.set_title('üí∞ Conversion Rate\\nwith 95% Confidence Interval', fontweight='bold')\n",
    "ax2.set_ylabel('Conversion Rate (%)')\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.text(0, conv_rate + conv_margin + 0.005, f'{conv_rate:.2%} ¬± {conv_margin:.3%}', \n",
    "         ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 3: Time on site distribution\n",
    "ax3.hist(time_on_site, bins=20, alpha=0.7, color=colors[4], edgecolor='white')\n",
    "ax3.axvline(time_mean, color=colors[5], linestyle='-', linewidth=3, \n",
    "           label=f'Mean: {time_mean:.1f} min')\n",
    "ax3.axvline(time_ci_lower, color=colors[6], linestyle='--', linewidth=2, \n",
    "           alpha=0.8, label=f'95% CI')\n",
    "ax3.axvline(time_ci_upper, color=colors[6], linestyle='--', linewidth=2, alpha=0.8)\n",
    "ax3.fill_betweenx([0, ax3.get_ylim()[1]], time_ci_lower, time_ci_upper, \n",
    "                 alpha=0.2, color=colors[6])\n",
    "ax3.set_title('‚è±Ô∏è Time on Site Distribution\\n(Converting Users Only)', fontweight='bold')\n",
    "ax3.set_xlabel('Time on Site (minutes)')\n",
    "ax3.set_ylabel('Number of Users')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Campaign funnel with error bars\n",
    "funnel_stages = ['Impressions', 'Clicks', 'Conversions']\n",
    "funnel_values = [n_impressions, n_clicks, n_conversions]\n",
    "funnel_rates = [1.0, ctr, ctr * conv_rate]\n",
    "funnel_errors = [0, ctr_margin, ctr_margin * conv_rate + ctr * conv_margin]  # Error propagation\n",
    "\n",
    "bars = ax4.bar(funnel_stages, funnel_rates, color=[colors[7], colors[8], colors[9]], \n",
    "               alpha=0.7, yerr=[0, ctr_margin, funnel_errors[2]], \n",
    "               capsize=8, capthick=2)\n",
    "ax4.set_title('üéØ Campaign Funnel\\nwith Uncertainty', fontweight='bold')\n",
    "ax4.set_ylabel('Rate')\n",
    "ax4.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "\n",
    "# Add value labels\n",
    "for i, (stage, value, rate, error) in enumerate(zip(funnel_stages, funnel_values, funnel_rates, funnel_errors)):\n",
    "    ax4.text(i, rate + error + 0.005, f'{value:,}\\n({rate:.2%})', \n",
    "            ha='center', fontweight='bold')\n",
    "\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Task 5: Business recommendations\n",
    "print(f\"\\nüíº Task 5 - Business Recommendations with Quantified Uncertainty:\")\n",
    "print(f\"\\nüéØ Click-Through Rate Performance:\")\n",
    "print(f\"   ‚Ä¢ Current CTR: {ctr:.2%} (95% CI: {ctr_ci_lower:.2%} to {ctr_ci_upper:.2%})\")\n",
    "print(f\"   ‚Ä¢ Benchmark comparison: Industry average ~3-5%\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ EXCELLENT: Our CTR significantly exceeds industry standards\")\n",
    "print(f\"   ‚Ä¢ üí∞ Revenue impact: With 95% confidence, true CTR is above {ctr_ci_lower:.2%}\")\n",
    "\n",
    "print(f\"\\nüí∞ Conversion Rate Analysis:\")\n",
    "print(f\"   ‚Ä¢ Current conversion: {conv_rate:.2%} (95% CI: {conv_ci_lower:.2%} to {conv_ci_upper:.2%})\")\n",
    "print(f\"   ‚Ä¢ This means 1 in {1/conv_rate:.0f} clicks converts to sale\")\n",
    "print(f\"   ‚Ä¢ ‚ö†Ô∏è OPPORTUNITY: Conversion rate has significant room for improvement\")\n",
    "print(f\"   ‚Ä¢ üîß Recommendation: A/B test landing page, checkout process\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è User Engagement:\")\n",
    "print(f\"   ‚Ä¢ Average session time: {time_mean:.1f} min (95% CI: {time_ci_lower:.1f} to {time_ci_upper:.1f} min)\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ POSITIVE: Converting users are highly engaged\")\n",
    "print(f\"   ‚Ä¢ üìà Strategy: Focus on getting more users to this engagement level\")\n",
    "\n",
    "print(f\"\\nüöÄ Strategic Recommendations:\")\n",
    "print(f\"   1. üìä Scale up campaign: CTR performance is exceptional\")\n",
    "print(f\"   2. üéØ Focus on conversion optimization: Biggest improvement opportunity\")\n",
    "print(f\"   3. üì± Replicate engagement tactics: Time on site indicates quality traffic\")\n",
    "print(f\"   4. üìà Monthly budget impact: With current performance, expect:\")\n",
    "print(f\"      ‚Ä¢ Conservative estimate: {ctr_ci_lower * conv_ci_lower * 100:.3f}% overall conversion\")\n",
    "print(f\"      ‚Ä¢ Optimistic estimate: {ctr_ci_upper * conv_ci_upper * 100:.3f}% overall conversion\")\n",
    "\n",
    "print(f\"\\nüé® The power of confidence intervals: We're not just guessing - we're quantifying our uncertainty!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Putting It All Together: The Statistical Inference Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Z-scores visualization\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "y = stats.norm.pdf(x)\n",
    "ax1.plot(x, y, linewidth=3, color=colors[0], label='Standard Normal')\n",
    "ax1.fill_between(x, y, alpha=0.3, color=colors[0])\n",
    "\n",
    "# Mark key z-scores\n",
    "key_z = [-2, -1, 0, 1, 2]\n",
    "for z in key_z:\n",
    "    ax1.axvline(z, color='black', linestyle='--', alpha=0.5)\n",
    "    ax1.text(z, 0.45, f'z={z}', ha='center', fontweight='bold')\n",
    "\n",
    "ax1.set_title('üß≠ Z-Scores: Your Statistical GPS', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Z-Score (Standard Deviations)')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# T-test visualization\n",
    "x_t = np.linspace(-4, 4, 1000)\n",
    "dfs = [5, 15, 30]\n",
    "for i, df in enumerate(dfs):\n",
    "    y_t = stats.t.pdf(x_t, df)\n",
    "    ax2.plot(x_t, y_t, linewidth=2, color=colors[i+1], \n",
    "            label=f't-dist (df={df})', alpha=0.8)\n",
    "\n",
    "# Add normal for comparison\n",
    "y_norm = stats.norm.pdf(x_t)\n",
    "ax2.plot(x_t, y_norm, '--', linewidth=2, color='black', \n",
    "        alpha=0.6, label='Normal (df=‚àû)')\n",
    "\n",
    "ax2.set_title('üß™ T-Distributions: When Sample Size Matters', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('T-Statistic')\n",
    "ax2.set_ylabel('Probability Density')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Confidence intervals - effect of sample size\n",
    "sample_sizes_demo = [10, 30, 100, 300]\n",
    "true_mean_demo = 100\n",
    "true_std_demo = 20\n",
    "\n",
    "y_pos = 0\n",
    "for n in sample_sizes_demo:\n",
    "    se = true_std_demo / np.sqrt(n)\n",
    "    margin = 1.96 * se  # 95% CI\n",
    "    \n",
    "    ax3.errorbar(true_mean_demo, y_pos, xerr=margin, fmt='o', \n",
    "                capsize=6, capthick=2, markersize=8, \n",
    "                color=colors[y_pos], label=f'n={n}')\n",
    "    y_pos += 1\n",
    "\n",
    "ax3.axvline(true_mean_demo, color='red', linestyle='--', linewidth=2, \n",
    "           alpha=0.7, label='True Mean')\n",
    "ax3.set_yticks(range(len(sample_sizes_demo)))\n",
    "ax3.set_yticklabels([f'n={n}' for n in sample_sizes_demo])\n",
    "ax3.set_title('üéØ Confidence Intervals: Precision vs Sample Size', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Value')\n",
    "ax3.set_ylabel('Sample Size')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Summary decision tree\n",
    "ax4.text(0.5, 0.9, 'üéØ Statistical Inference Decision Tree', \n",
    "         transform=ax4.transAxes, ha='center', fontsize=16, fontweight='bold')\n",
    "\n",
    "decision_tree = [\n",
    "    \"ü§î What's your question?\",\n",
    "    \"\",\n",
    "    \"üìç Where does my data point stand?\",\n",
    "    \"   ‚Üí Use Z-SCORES\",\n",
    "    \"\",\n",
    "    \"‚öñÔ∏è Are two groups different?\",\n",
    "    \"   ‚Üí Use T-TESTS\",\n",
    "    \"\",\n",
    "    \"üéØ What's the range of plausible values?\",\n",
    "    \"   ‚Üí Use CONFIDENCE INTERVALS\",\n",
    "    \"\",\n",
    "    \"üí° Pro tip: Always visualize your data first!\"\n",
    "]\n",
    "\n",
    "for i, line in enumerate(decision_tree):\n",
    "    y_pos = 0.8 - i * 0.07\n",
    "    ax4.text(0.05, y_pos, line, transform=ax4.transAxes, \n",
    "            fontsize=11, fontweight='bold' if line.startswith('ü§î') or line.startswith('üí°') else 'normal')\n",
    "\n",
    "ax4.set_xlim(0, 1)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéâ Congratulations! You now have a complete statistical inference toolkit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up & Mastery Check\n",
    "‚úÖ You understand z-scores as your statistical GPS system  \n",
    "‚úÖ You can use t-tests to compare groups scientifically  \n",
    "‚úÖ You know how to build and interpret confidence intervals  \n",
    "‚úÖ You've seen these concepts come alive through beautiful visualizations  \n",
    "‚úÖ You can apply these tools to solve real business problems  \n",
    "\n",
    "**Quick Reference Card:**\n",
    "- üß≠ **Z-Scores**: (value - mean) / std ‚Üí tells you how unusual a data point is\n",
    "- üß™ **T-Tests**: Compare group means, work with small samples too\n",
    "- üéØ **Confidence Intervals**: Range of plausible values for true parameter\n",
    "- üìè **Sample Size**: Bigger samples ‚Üí narrower CIs ‚Üí more precision\n",
    "- üé® **Visualize**: Always plot your data and results!\n",
    "\n",
    "**Real-World Applications You've Mastered:**\n",
    "- Employee performance evaluation with z-scores\n",
    "- Medical treatment comparison with t-tests\n",
    "- Marketing campaign analysis with confidence intervals\n",
    "- Quality control with statistical inference\n",
    "- Survey research with uncertainty quantification\n",
    "\n",
    "**Next Steps in Your Journey:**\n",
    "These foundational concepts power everything else in statistics:\n",
    "- **A/B Testing**: Uses t-tests and confidence intervals\n",
    "- **Machine Learning**: Uses these concepts for model validation\n",
    "- **Advanced Statistics**: ANOVA, regression, and more\n",
    "- **Data Science**: Everything you've learned applies to real data science work\n",
    "\n",
    "üöÄ **You're now equipped with the core tools of statistical thinking!** Every data scientist, researcher, and analyst uses these concepts daily. The beautiful thing is that once you understand the logic and can create the visualizations, you can explain complex statistical concepts to anyone.\n",
    "\n",
    "**Remember**: Statistics isn't about memorizing formulas - it's about understanding uncertainty, making comparisons, and quantifying confidence in your conclusions. You now have these superpowers! üéØ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}