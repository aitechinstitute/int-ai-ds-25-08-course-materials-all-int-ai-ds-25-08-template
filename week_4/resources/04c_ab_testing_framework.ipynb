{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8287c6",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** · *Intermediate AI & Data Science*\n",
    "### Week 04 · Notebook 03 – A/B Testing Framework\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Build a complete A/B testing framework for data-driven decisions.\n",
    "\n",
    "> Format: short theory → quick practice → build understanding → mini-challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35e8bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Design and implement A/B tests end-to-end\n",
    "- Build reusable testing framework\n",
    "- Handle real-world complications\n",
    "- Create actionable reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0238f",
   "metadata": {},
   "source": [
    "## 1. A/B Test Design: From Question to Experiment\n",
    "The complete workflow for running experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f18528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B Test Planning Template\n",
    "test_plan = {\n",
    "    'test_name': 'Homepage CTA Button Color',\n",
    "    'hypothesis': 'Green button will increase CTR by 10%',\n",
    "    'primary_metric': 'click_through_rate',\n",
    "    'secondary_metrics': ['bounce_rate', 'time_on_site'],\n",
    "    'baseline_ctr': 0.05,  # 5%\n",
    "    'minimum_detectable_effect': 0.005,  # 0.5% absolute\n",
    "    'significance_level': 0.05,\n",
    "    'power': 0.8,\n",
    "    'test_duration_days': 14\n",
    "}\n",
    "\n",
    "print(\"A/B TEST PLAN\")\n",
    "print(\"=\"*50)\n",
    "for key, value in test_plan.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate required sample size\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from statsmodels.stats.power import zt_ind_solve_power\n",
    "\n",
    "p1 = test_plan['baseline_ctr']\n",
    "p2 = p1 + test_plan['minimum_detectable_effect']\n",
    "\n",
    "effect_size = proportion_effectsize(p1, p2)\n",
    "n_required = zt_ind_solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=test_plan['significance_level'],\n",
    "    power=test_plan['power'],\n",
    "    ratio=1\n",
    ")\n",
    "\n",
    "print(f\"\\nRequired sample size per variant: {n_required:.0f}\")\n",
    "print(f\"Total visitors needed: {2*n_required:.0f}\")\n",
    "print(f\"Daily traffic required: {2*n_required/test_plan['test_duration_days']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f40a1",
   "metadata": {},
   "source": [
    "**Exercise 1 – Test Planning (easy)**  \n",
    "Plan an A/B test for email subject lines with 20% open rate baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Create test_plan dictionary for email campaign\n",
    "# Baseline open rate: 20%\n",
    "# Want to detect: 2% absolute improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265e60a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "email_test_plan = {\n",
    "    'test_name': 'Email Subject Line Personalization',\n",
    "    'hypothesis': 'Personalized subject increases opens by 10%',\n",
    "    'primary_metric': 'open_rate',\n",
    "    'secondary_metrics': ['click_rate', 'unsubscribe_rate'],\n",
    "    'baseline_rate': 0.20,  # 20%\n",
    "    'minimum_detectable_effect': 0.02,  # 2% absolute\n",
    "    'significance_level': 0.05,\n",
    "    'power': 0.8\n",
    "}\n",
    "\n",
    "# Calculate sample size\n",
    "p1 = email_test_plan['baseline_rate']\n",
    "p2 = p1 + email_test_plan['minimum_detectable_effect']\n",
    "\n",
    "effect = proportion_effectsize(p1, p2)\n",
    "n = zt_ind_solve_power(effect, alpha=0.05, power=0.8, ratio=1)\n",
    "\n",
    "print(f\"Emails needed per variant: {n:.0f}\")\n",
    "print(f\"Total emails: {2*n:.0f}\")\n",
    "print(f\"\\nIf you send 1000 emails/day:\")\n",
    "print(f\"Test duration: {2*n/1000:.1f} days\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c78e3",
   "metadata": {},
   "source": [
    "## 2. Simulating A/B Test Data\n",
    "Creating realistic test data for our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ab_test_data(n_users=10000, effect_size=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    Generate realistic A/B test data\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create user data\n",
    "    data = []\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        # Random assignment to control/treatment\n",
    "        variant = np.random.choice(['control', 'treatment'])\n",
    "        \n",
    "        # Base conversion probability\n",
    "        if variant == 'control':\n",
    "            p_convert = 0.05\n",
    "        else:\n",
    "            p_convert = 0.05 * (1 + effect_size)  # 10% lift\n",
    "        \n",
    "        # Generate user behavior\n",
    "        converted = np.random.random() < p_convert\n",
    "        \n",
    "        # Add some realistic variation\n",
    "        timestamp = start_date + timedelta(\n",
    "            days=np.random.randint(0, 14),\n",
    "            hours=np.random.randint(0, 24),\n",
    "            minutes=np.random.randint(0, 60)\n",
    "        )\n",
    "        \n",
    "        # Time on site (correlated with conversion)\n",
    "        if converted:\n",
    "            time_on_site = np.random.gamma(5, 2) * 60  # seconds\n",
    "        else:\n",
    "            time_on_site = np.random.gamma(3, 2) * 60\n",
    "        \n",
    "        data.append({\n",
    "            'user_id': f'user_{i:05d}',\n",
    "            'timestamp': timestamp,\n",
    "            'variant': variant,\n",
    "            'converted': converted,\n",
    "            'time_on_site': time_on_site,\n",
    "            'device': np.random.choice(['mobile', 'desktop', 'tablet'], \n",
    "                                     p=[0.5, 0.4, 0.1])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate test data\n",
    "ab_data = generate_ab_test_data(n_users=10000, effect_size=0.1)\n",
    "print(ab_data.head())\n",
    "print(f\"\\nData shape: {ab_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data validation\n",
    "print(\"Data Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total users: {len(ab_data)}\")\n",
    "print(f\"\\nVariant split:\")\n",
    "print(ab_data['variant'].value_counts())\n",
    "print(f\"\\nConversion rates:\")\n",
    "print(ab_data.groupby('variant')['converted'].agg(['sum', 'mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cc6d3",
   "metadata": {},
   "source": [
    "**Exercise 2 – Data Validation (medium)**  \n",
    "Check for sample ratio mismatch and data quality issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127850d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Check if the 50/50 split is statistically valid\n",
    "# Check for missing data\n",
    "# Check for duplicate users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f25302",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Sample Ratio Mismatch (SRM) check\n",
    "control_count = (ab_data['variant'] == 'control').sum()\n",
    "treatment_count = (ab_data['variant'] == 'treatment').sum()\n",
    "total = len(ab_data)\n",
    "\n",
    "# Chi-square test for 50/50 split\n",
    "expected = total / 2\n",
    "chi2 = ((control_count - expected)**2 + (treatment_count - expected)**2) / expected\n",
    "p_value = 1 - stats.chi2.cdf(chi2, df=1)\n",
    "\n",
    "print(\"Sample Ratio Check:\")\n",
    "print(f\"Control: {control_count} ({control_count/total:.1%})\")\n",
    "print(f\"Treatment: {treatment_count} ({treatment_count/total:.1%})\")\n",
    "print(f\"Chi-square p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.01:\n",
    "    print(\"⚠️ WARNING: Sample ratio mismatch detected!\")\n",
    "else:\n",
    "    print(\"✅ Sample ratio looks good\")\n",
    "\n",
    "# Data quality checks\n",
    "print(\"\\nData Quality:\")\n",
    "print(f\"Missing values: {ab_data.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate users: {ab_data['user_id'].duplicated().sum()}\")\n",
    "print(f\"Date range: {ab_data['timestamp'].min()} to {ab_data['timestamp'].max()}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1848",
   "metadata": {},
   "source": [
    "## 3. Building the A/B Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABTestAnalyzer:\n",
    "    \"\"\"\n",
    "    Complete A/B Testing Framework\n",
    "    \"\"\"\n",
    "    def __init__(self, data, variant_col='variant', \n",
    "                 control_name='control', treatment_name='treatment'):\n",
    "        self.data = data\n",
    "        self.variant_col = variant_col\n",
    "        self.control_name = control_name\n",
    "        self.treatment_name = treatment_name\n",
    "        \n",
    "    def calculate_conversion_rate(self, metric='converted'):\n",
    "        \"\"\"Calculate conversion rates by variant\"\"\"\n",
    "        results = self.data.groupby(self.variant_col)[metric].agg([\n",
    "            'sum', 'count', 'mean'\n",
    "        ])\n",
    "        results.columns = ['conversions', 'users', 'conversion_rate']\n",
    "        return results\n",
    "    \n",
    "    def run_significance_test(self, metric='converted', alpha=0.05):\n",
    "        \"\"\"Run statistical significance test\"\"\"\n",
    "        control = self.data[self.data[self.variant_col] == self.control_name][metric]\n",
    "        treatment = self.data[self.data[self.variant_col] == self.treatment_name][metric]\n",
    "        \n",
    "        # Two-proportion z-test\n",
    "        n_control = len(control)\n",
    "        n_treatment = len(treatment)\n",
    "        p_control = control.mean()\n",
    "        p_treatment = treatment.mean()\n",
    "        \n",
    "        # Pooled proportion\n",
    "        p_pooled = (control.sum() + treatment.sum()) / (n_control + n_treatment)\n",
    "        \n",
    "        # Standard error\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_control + 1/n_treatment))\n",
    "        \n",
    "        # Z-score\n",
    "        z_score = (p_treatment - p_control) / se\n",
    "        \n",
    "        # P-value (two-tailed)\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "        \n",
    "        # Confidence interval\n",
    "        ci_se = np.sqrt(p_control*(1-p_control)/n_control + \n",
    "                       p_treatment*(1-p_treatment)/n_treatment)\n",
    "        ci_margin = 1.96 * ci_se\n",
    "        \n",
    "        lift = (p_treatment - p_control) / p_control * 100\n",
    "        \n",
    "        return {\n",
    "            'control_rate': p_control,\n",
    "            'treatment_rate': p_treatment,\n",
    "            'absolute_difference': p_treatment - p_control,\n",
    "            'relative_lift': lift,\n",
    "            'z_score': z_score,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < alpha,\n",
    "            'ci_lower': (p_treatment - p_control) - ci_margin,\n",
    "            'ci_upper': (p_treatment - p_control) + ci_margin\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, metric='converted'):\n",
    "        \"\"\"Visualize A/B test results\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Conversion rates\n",
    "        rates = self.calculate_conversion_rate(metric)\n",
    "        axes[0].bar(rates.index, rates['conversion_rate'], \n",
    "                   color=['blue', 'green'])\n",
    "        axes[0].set_ylabel('Conversion Rate')\n",
    "        axes[0].set_title('Conversion Rates by Variant')\n",
    "        axes[0].set_ylim(0, max(rates['conversion_rate']) * 1.2)\n",
    "        \n",
    "        # Add values on bars\n",
    "        for i, (idx, row) in enumerate(rates.iterrows()):\n",
    "            axes[0].text(i, row['conversion_rate'], \n",
    "                        f\"{row['conversion_rate']:.3f}\", \n",
    "                        ha='center', va='bottom')\n",
    "        \n",
    "        # Cumulative conversion over time\n",
    "        daily = self.data.groupby(\n",
    "            [pd.Grouper(key='timestamp', freq='D'), self.variant_col]\n",
    "        )[metric].mean().unstack(fill_value=0)\n",
    "        \n",
    "        daily.cumsum().plot(ax=axes[1])\n",
    "        axes[1].set_xlabel('Date')\n",
    "        axes[1].set_ylabel('Cumulative Conversion Rate')\n",
    "        axes[1].set_title('Conversion Rate Over Time')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # Confidence intervals\n",
    "        test_results = self.run_significance_test(metric)\n",
    "        diff = test_results['absolute_difference']\n",
    "        ci_lower = test_results['ci_lower']\n",
    "        ci_upper = test_results['ci_upper']\n",
    "        \n",
    "        axes[2].errorbar(1, diff, \n",
    "                        yerr=[[diff-ci_lower], [ci_upper-diff]], \n",
    "                        fmt='o', markersize=10, capsize=10)\n",
    "        axes[2].axhline(y=0, color='gray', linestyle='--')\n",
    "        axes[2].set_xlim(0, 2)\n",
    "        axes[2].set_ylabel('Difference in Conversion Rate')\n",
    "        axes[2].set_title('95% Confidence Interval')\n",
    "        axes[2].set_xticks([])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Use the framework\n",
    "analyzer = ABTestAnalyzer(ab_data)\n",
    "results = analyzer.run_significance_test()\n",
    "\n",
    "print(\"A/B TEST RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for key, value in results.items():\n",
    "    if isinstance(value, float):\n",
    "        if 'rate' in key or 'difference' in key:\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82fed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "analyzer.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c85c5e",
   "metadata": {},
   "source": [
    "## 4. Advanced Analysis: Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a3661-2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_analysis(data, segment_col='device'):\n",
    "    \"\"\"\n",
    "    Analyze A/B test results by segment\n",
    "    \"\"\"\n",
    "    segments = data[segment_col].unique()\n",
    "    results = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        segment_data = data[data[segment_col] == segment]\n",
    "        \n",
    "        control = segment_data[segment_data['variant'] == 'control']['converted']\n",
    "        treatment = segment_data[segment_data['variant'] == 'treatment']['converted']\n",
    "        \n",
    "        if len(control) > 0 and len(treatment) > 0:\n",
    "            _, p_value = stats.chi2_contingency([\n",
    "                [control.sum(), len(control) - control.sum()],\n",
    "                [treatment.sum(), len(treatment) - treatment.sum()]\n",
    "            ])[:2]\n",
    "            \n",
    "            results.append({\n",
    "                'segment': segment,\n",
    "                'control_rate': control.mean(),\n",
    "                'treatment_rate': treatment.mean(),\n",
    "                'lift': (treatment.mean() - control.mean()) / control.mean() * 100,\n",
    "                'p_value': p_value,\n",
    "                'sample_size': len(segment_data)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('lift', ascending=False)\n",
    "\n",
    "# Run segment analysis\n",
    "segment_results = segment_analysis(ab_data, 'device')\n",
    "print(\"Segment Analysis - By Device:\")\n",
    "print(segment_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b637638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segment results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "segments = segment_results['segment']\n",
    "x = np.arange(len(segments))\n",
    "width = 0.35\n",
    "\n",
    "control_rates = segment_results['control_rate']\n",
    "treatment_rates = segment_results['treatment_rate']\n",
    "\n",
    "ax.bar(x - width/2, control_rates, width, label='Control', color='blue', alpha=0.7)\n",
    "ax.bar(x + width/2, treatment_rates, width, label='Treatment', color='green', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Device Type')\n",
    "ax.set_ylabel('Conversion Rate')\n",
    "ax.set_title('A/B Test Results by Device Segment')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(segments)\n",
    "ax.legend()\n",
    "\n",
    "# Add significance stars\n",
    "for i, row in segment_results.iterrows():\n",
    "    if row['p_value'] < 0.05:\n",
    "        ax.text(i, max(row['control_rate'], row['treatment_rate']) + 0.002, \n",
    "               '*', ha='center', fontsize=20, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f39466",
   "metadata": {},
   "source": [
    "**Exercise 3 – Time-based Analysis (medium)**  \n",
    "Check if the treatment effect changes over time (novelty effect).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Analyze conversion rates by week\n",
    "# Check if treatment effect diminishes over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54870cb",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Add week number\n",
    "ab_data['week'] = ((ab_data['timestamp'] - ab_data['timestamp'].min()).dt.days // 7) + 1\n",
    "\n",
    "# Calculate weekly conversion rates\n",
    "weekly_results = []\n",
    "for week in ab_data['week'].unique():\n",
    "    week_data = ab_data[ab_data['week'] == week]\n",
    "    \n",
    "    control = week_data[week_data['variant'] == 'control']['converted']\n",
    "    treatment = week_data[week_data['variant'] == 'treatment']['converted']\n",
    "    \n",
    "    if len(control) > 30 and len(treatment) > 30:  # Minimum sample\n",
    "        weekly_results.append({\n",
    "            'week': week,\n",
    "            'control_rate': control.mean(),\n",
    "            'treatment_rate': treatment.mean(),\n",
    "            'lift': (treatment.mean() - control.mean()) / control.mean() * 100\n",
    "        })\n",
    "\n",
    "weekly_df = pd.DataFrame(weekly_results)\n",
    "\n",
    "# Plot novelty effect\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(weekly_df['week'], weekly_df['control_rate'], \n",
    "         'o-', label='Control', color='blue')\n",
    "plt.plot(weekly_df['week'], weekly_df['treatment_rate'], \n",
    "         'o-', label='Treatment', color='green')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Conversion Rate')\n",
    "plt.title('Checking for Novelty Effect')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line for lift\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(weekly_df['week'], weekly_df['lift'], \n",
    "         's--', color='red', alpha=0.5, label='Lift %')\n",
    "ax2.set_ylabel('Lift (%)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check if lift is decreasing\n",
    "if len(weekly_df) > 1:\n",
    "    correlation = weekly_df['week'].corr(weekly_df['lift'])\n",
    "    print(f\"Week-Lift Correlation: {correlation:.3f}\")\n",
    "    if correlation < -0.5:\n",
    "        print(\"⚠️ Warning: Novelty effect detected (lift decreasing over time)\")\n",
    "    else:\n",
    "        print(\"✅ No strong novelty effect detected\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93813ac",
   "metadata": {},
   "source": [
    "## 5. Reporting Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ab_test_report(analyzer, data, test_name=\"A/B Test\"):\n",
    "    \"\"\"\n",
    "    Generate comprehensive A/B test report\n",
    "    \"\"\"\n",
    "    results = analyzer.run_significance_test()\n",
    "    rates = analyzer.calculate_conversion_rate()\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    {'='*60}\n",
    "    A/B TEST REPORT: {test_name}\n",
    "    {'='*60}\n",
    "    \n",
    "    EXECUTIVE SUMMARY\n",
    "    -----------------\n",
    "    Test Duration: {(data['timestamp'].max() - data['timestamp'].min()).days} days\n",
    "    Total Users: {len(data):,}\n",
    "    \n",
    "    RESULTS\n",
    "    -------\n",
    "    Control Conversion Rate: {results['control_rate']:.2%}\n",
    "    Treatment Conversion Rate: {results['treatment_rate']:.2%}\n",
    "    Relative Lift: {results['relative_lift']:+.1f}%\n",
    "    \n",
    "    Statistical Significance: {'✅ YES' if results['significant'] else '❌ NO'}\n",
    "    P-value: {results['p_value']:.4f}\n",
    "    95% CI for difference: [{results['ci_lower']:.4f}, {results['ci_upper']:.4f}]\n",
    "    \n",
    "    RECOMMENDATION\n",
    "    --------------\n",
    "    \"\"\"\n",
    "    \n",
    "    if results['significant']:\n",
    "        if results['relative_lift'] > 0:\n",
    "            report += \"\"\"✅ SHIP IT! The treatment shows a statistically significant improvement.\n",
    "    Implement the treatment variant to all users.\"\"\"\n",
    "        else:\n",
    "            report += \"\"\"⚠️ DO NOT SHIP! The treatment shows a statistically significant decrease.\n",
    "    Keep the control variant.\"\"\"\n",
    "    else:\n",
    "        report += \"\"\"🔄 INCONCLUSIVE. No statistically significant difference detected.\n",
    "    Consider:\n",
    "    - Running the test longer for more data\n",
    "    - Testing a more impactful change\n",
    "    - Checking segment-level results\"\"\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "    \n",
    "    BUSINESS IMPACT\n",
    "    ---------------\n",
    "    If implemented for 100,000 users:\n",
    "    - Additional conversions: {int(100000 * results['absolute_difference']):,}\n",
    "    - At $50 per conversion: ${int(100000 * results['absolute_difference'] * 50):,} additional revenue\n",
    "    \n",
    "    {'='*60}\n",
    "    \"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate report\n",
    "report = generate_ab_test_report(analyzer, ab_data, \"Homepage CTA Color Test\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98963a1",
   "metadata": {},
   "source": [
    "**Exercise 4 – Complete A/B Test (hard)**  \n",
    "Run a complete A/B test analysis with your own hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# 1. Generate data for a pricing test (old: $9.99, new: $7.99)\n",
    "# 2. Run significance test\n",
    "# 3. Check segments\n",
    "# 4. Generate report with revenue impact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecfa82",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Pricing test scenario\n",
    "def generate_pricing_test_data(n_users=5000):\n",
    "    np.random.seed(42)\n",
    "    data = []\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        variant = np.random.choice(['control_$9.99', 'treatment_$7.99'])\n",
    "        \n",
    "        # Lower price = higher conversion\n",
    "        if variant == 'control_$9.99':\n",
    "            p_convert = 0.08\n",
    "            revenue_per_user = 9.99\n",
    "        else:\n",
    "            p_convert = 0.12  # 50% lift in conversion\n",
    "            revenue_per_user = 7.99\n",
    "        \n",
    "        converted = np.random.random() < p_convert\n",
    "        revenue = revenue_per_user if converted else 0\n",
    "        \n",
    "        data.append({\n",
    "            'user_id': f'user_{i:05d}',\n",
    "            'variant': variant,\n",
    "            'converted': converted,\n",
    "            'revenue': revenue,\n",
    "            'user_segment': np.random.choice(['new', 'returning'], p=[0.3, 0.7])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate and analyze\n",
    "pricing_data = generate_pricing_test_data()\n",
    "\n",
    "# Conversion analysis\n",
    "print(\"PRICING TEST RESULTS\")\n",
    "print(\"=\"*50)\n",
    "conversion_by_variant = pricing_data.groupby('variant').agg({\n",
    "    'converted': ['sum', 'mean'],\n",
    "    'revenue': 'mean'\n",
    "})\n",
    "print(conversion_by_variant)\n",
    "\n",
    "# Revenue comparison\n",
    "control_revenue = pricing_data[pricing_data['variant'] == 'control_$9.99']['revenue'].mean()\n",
    "treatment_revenue = pricing_data[pricing_data['variant'] == 'treatment_$7.99']['revenue'].mean()\n",
    "\n",
    "print(f\"\\nAverage Revenue per User:\")\n",
    "print(f\"Control ($9.99): ${control_revenue:.2f}\")\n",
    "print(f\"Treatment ($7.99): ${treatment_revenue:.2f}\")\n",
    "print(f\"Revenue Lift: {(treatment_revenue - control_revenue) / control_revenue * 100:+.1f}%\")\n",
    "\n",
    "# Statistical test on revenue\n",
    "from scipy import stats\n",
    "control_rev = pricing_data[pricing_data['variant'] == 'control_$9.99']['revenue']\n",
    "treatment_rev = pricing_data[pricing_data['variant'] == 'treatment_$7.99']['revenue']\n",
    "t_stat, p_value = stats.ttest_ind(control_rev, treatment_rev)\n",
    "\n",
    "print(f\"\\nRevenue Significance Test:\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Segment analysis\n",
    "print(\"\\nSegment Analysis:\")\n",
    "for segment in ['new', 'returning']:\n",
    "    seg_data = pricing_data[pricing_data['user_segment'] == segment]\n",
    "    seg_control = seg_data[seg_data['variant'] == 'control_$9.99']['converted'].mean()\n",
    "    seg_treatment = seg_data[seg_data['variant'] == 'treatment_$7.99']['converted'].mean()\n",
    "    print(f\"{segment.capitalize()} users: {seg_control:.1%} → {seg_treatment:.1%} \"\n",
    "          f\"(+{(seg_treatment-seg_control)/seg_control*100:.0f}%)\")\n",
    "\n",
    "# Business recommendation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RECOMMENDATION:\")\n",
    "if treatment_revenue > control_revenue and p_value < 0.05:\n",
    "    print(\"✅ Lower price to $7.99 - higher revenue despite lower price point!\")\n",
    "    print(f\"Projected annual impact: ${(treatment_revenue - control_revenue) * 365 * 1000:.0f}\")\n",
    "elif treatment_revenue < control_revenue:\n",
    "    print(\"❌ Keep $9.99 price - lower price reduces total revenue\")\n",
    "else:\n",
    "    print(\"🔄 Inconclusive - need more data\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88bba8",
   "metadata": {},
   "source": [
    "## 6. Mini-Challenges\n",
    "- **M1 (easy):** Calculate minimum detectable effect for your traffic\n",
    "- **M2 (medium):** Implement sequential testing (early stopping)\n",
    "- **M3 (hard):** Build Bayesian A/B testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f834bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e9d0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - Minimum Detectable Effect\n",
    "from statsmodels.stats.power import zt_ind_solve_power\n",
    "\n",
    "daily_traffic = 1000\n",
    "test_days = 14\n",
    "n_per_group = (daily_traffic * test_days) / 2\n",
    "\n",
    "# What effect can we detect?\n",
    "mde = zt_ind_solve_power(effect_size=None, \n",
    "                         nobs1=n_per_group,\n",
    "                         alpha=0.05, \n",
    "                         power=0.8)\n",
    "print(f\"With {n_per_group:.0f} users per group:\")\n",
    "print(f\"Minimum detectable effect size: {mde:.3f}\")\n",
    "\n",
    "# M2 - Sequential Testing (simplified)\n",
    "def sequential_test(data, alpha=0.05, check_points=5):\n",
    "    n = len(data)\n",
    "    check_every = n // check_points\n",
    "    \n",
    "    for i in range(1, check_points + 1):\n",
    "        subset = data.iloc[:i*check_every]\n",
    "        control = subset[subset['variant'] == 'control']['converted']\n",
    "        treatment = subset[subset['variant'] == 'treatment']['converted']\n",
    "        \n",
    "        if len(control) > 30 and len(treatment) > 30:\n",
    "            _, p_value = stats.chi2_contingency([\n",
    "                [control.sum(), len(control) - control.sum()],\n",
    "                [treatment.sum(), len(treatment) - treatment.sum()]\n",
    "            ])[:2]\n",
    "            \n",
    "            # Bonferroni correction for multiple checks\n",
    "            adjusted_alpha = alpha / check_points\n",
    "            \n",
    "            print(f\"Check {i}: n={len(subset)}, p={p_value:.4f}\")\n",
    "            if p_value < adjusted_alpha:\n",
    "                print(f\"✅ Stop early! Significant at check {i}\")\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "sequential_test(ab_data)\n",
    "\n",
    "# M3 - Bayesian A/B Testing\n",
    "from scipy.stats import beta\n",
    "\n",
    "def bayesian_ab_test(data, prior_alpha=1, prior_beta=1):\n",
    "    control = data[data['variant'] == 'control']['converted']\n",
    "    treatment = data[data['variant'] == 'treatment']['converted']\n",
    "    \n",
    "    # Update priors with data\n",
    "    control_alpha = prior_alpha + control.sum()\n",
    "    control_beta = prior_beta + len(control) - control.sum()\n",
    "    \n",
    "    treatment_alpha = prior_alpha + treatment.sum()\n",
    "    treatment_beta = prior_beta + len(treatment) - treatment.sum()\n",
    "    \n",
    "    # Sample from posteriors\n",
    "    n_samples = 10000\n",
    "    control_samples = beta.rvs(control_alpha, control_beta, size=n_samples)\n",
    "    treatment_samples = beta.rvs(treatment_alpha, treatment_beta, size=n_samples)\n",
    "    \n",
    "    # Probability treatment is better\n",
    "    prob_treatment_better = (treatment_samples > control_samples).mean()\n",
    "    \n",
    "    print(f\"Bayesian A/B Test Results:\")\n",
    "    print(f\"P(Treatment > Control): {prob_treatment_better:.1%}\")\n",
    "    print(f\"Expected Control Rate: {control_samples.mean():.3f}\")\n",
    "    print(f\"Expected Treatment Rate: {treatment_samples.mean():.3f}\")\n",
    "    \n",
    "    if prob_treatment_better > 0.95:\n",
    "        print(\"✅ Strong evidence treatment is better\")\n",
    "    elif prob_treatment_better < 0.05:\n",
    "        print(\"❌ Strong evidence control is better\")\n",
    "    else:\n",
    "        print(\"🔄 Need more data\")\n",
    "\n",
    "bayesian_ab_test(ab_data)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba28e65",
   "metadata": {},
   "source": [
    "## Wrap-Up & Next Steps\n",
    "✅ You can design and plan A/B tests properly  \n",
    "✅ You built a complete testing framework  \n",
    "✅ You can analyze results and check for biases  \n",
    "✅ You can create actionable reports for stakeholders  \n",
    "\n",
    "**Week 4 Complete!** You now have the statistical foundation and practical framework for data-driven decision making through A/B testing.\n",
    "\n",
    "**Next Week:** Causal Inference - Going beyond correlation to understand true cause and effect!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
