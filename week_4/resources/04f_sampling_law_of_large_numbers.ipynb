{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8287c6",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 04 ¬∑ Notebook 06 ‚Äì Sampling Theory & Law of Large Numbers\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master the foundations of statistical inference through sampling.\n",
    "\n",
    "> Format: short theory ‚Üí quick practice ‚Üí build understanding ‚Üí mini-challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35e8bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Understand population vs sample concepts\n",
    "- Master different sampling techniques\n",
    "- Prove the Law of Large Numbers empirically\n",
    "- Apply Central Limit Theorem in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0238f",
   "metadata": {},
   "source": [
    "## 1. Population vs Sample: The Foundation\n",
    "Understanding why we sample and what it means for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f18528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"population\" - imagine all users of a social media platform\n",
    "POPULATION_SIZE = 1000000  # 1 million users\n",
    "\n",
    "# True population parameters (usually unknown in real life!)\n",
    "TRUE_MEAN_AGE = 28\n",
    "TRUE_STD_AGE = 8\n",
    "TRUE_PREMIUM_RATE = 0.15  # 15% are premium users\n",
    "\n",
    "# Generate population\n",
    "print(\"Creating population of 1 million users...\")\n",
    "population_ages = np.random.normal(TRUE_MEAN_AGE, TRUE_STD_AGE, POPULATION_SIZE)\n",
    "population_ages = np.clip(population_ages, 13, 80)  # Realistic age bounds\n",
    "population_premium = np.random.binomial(1, TRUE_PREMIUM_RATE, POPULATION_SIZE)\n",
    "\n",
    "print(f\"Population created!\")\n",
    "print(f\"True population mean age: {population_ages.mean():.2f}\")\n",
    "print(f\"True population std age: {population_ages.std():.2f}\")\n",
    "print(f\"True premium rate: {population_premium.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take samples of different sizes\n",
    "sample_sizes = [10, 50, 100, 500, 1000, 5000]\n",
    "samples = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    # Take a random sample\n",
    "    sample_indices = np.random.choice(POPULATION_SIZE, n, replace=False)\n",
    "    sample_ages = population_ages[sample_indices]\n",
    "    samples[n] = sample_ages\n",
    "    \n",
    "    # Calculate sample statistics\n",
    "    sample_mean = sample_ages.mean()\n",
    "    sample_std = sample_ages.std(ddof=1)  # Using sample std (n-1)\n",
    "    \n",
    "    # Visualize\n",
    "    axes[idx].hist(sample_ages, bins=30, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[idx].axvline(sample_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean: {sample_mean:.2f}')\n",
    "    axes[idx].axvline(TRUE_MEAN_AGE, color='green', linestyle='--', linewidth=2, label=f'True mean: {TRUE_MEAN_AGE}')\n",
    "    axes[idx].set_title(f'Sample Size: {n}\\nError: {abs(sample_mean - TRUE_MEAN_AGE):.2f} years')\n",
    "    axes[idx].set_xlabel('Age')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    axes[idx].set_xlim(10, 50)\n",
    "\n",
    "plt.suptitle('How Sample Size Affects Estimation Accuracy', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Insight: Larger samples give estimates closer to true population values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f40a1",
   "metadata": {},
   "source": [
    "**Exercise 1 ‚Äì Sample Bias Detection (easy)**  \n",
    "Compare random vs biased sampling and see the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Take two samples of size 1000:\n",
    "# 1. Random sample\n",
    "# 2. Biased sample (only ages < 25)\n",
    "# Compare their means to the true population mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265e60a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Random sample\n",
    "random_sample = np.random.choice(population_ages, 1000, replace=False)\n",
    "random_mean = random_sample.mean()\n",
    "\n",
    "# Biased sample (younger users only)\n",
    "young_indices = np.where(population_ages < 25)[0]\n",
    "biased_sample = population_ages[np.random.choice(young_indices, 1000, replace=False)]\n",
    "biased_mean = biased_sample.mean()\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Random sample\n",
    "ax1.hist(random_sample, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "ax1.axvline(random_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean: {random_mean:.2f}')\n",
    "ax1.axvline(TRUE_MEAN_AGE, color='blue', linestyle='--', linewidth=2, label=f'True mean: {TRUE_MEAN_AGE}')\n",
    "ax1.set_title(f'Random Sample\\nBias: {random_mean - TRUE_MEAN_AGE:.2f} years')\n",
    "ax1.set_xlabel('Age')\n",
    "ax1.legend()\n",
    "\n",
    "# Biased sample\n",
    "ax2.hist(biased_sample, bins=30, alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.axvline(biased_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean: {biased_mean:.2f}')\n",
    "ax2.axvline(TRUE_MEAN_AGE, color='blue', linestyle='--', linewidth=2, label=f'True mean: {TRUE_MEAN_AGE}')\n",
    "ax2.set_title(f'Biased Sample (Age < 25 only)\\nBias: {biased_mean - TRUE_MEAN_AGE:.2f} years')\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle('Random vs Biased Sampling', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Biased sampling leads to incorrect estimates!\")\n",
    "print(f\"Random sample error: {abs(random_mean - TRUE_MEAN_AGE):.2f} years\")\n",
    "print(f\"Biased sample error: {abs(biased_mean - TRUE_MEAN_AGE):.2f} years\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c78e3",
   "metadata": {},
   "source": [
    "## 2. The Law of Large Numbers in Action\n",
    "Watch the magic happen as sample size increases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Law of Large Numbers - Coin Flips\n",
    "def law_of_large_numbers_demo(true_probability=0.5, max_flips=10000):\n",
    "    \"\"\"Show how sample proportion converges to true probability\"\"\"\n",
    "    \n",
    "    # Simulate coin flips\n",
    "    flips = np.random.binomial(1, true_probability, max_flips)\n",
    "    \n",
    "    # Calculate running average\n",
    "    running_average = np.cumsum(flips) / np.arange(1, max_flips + 1)\n",
    "    \n",
    "    # Plot convergence\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Main plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(running_average, alpha=0.7, linewidth=1)\n",
    "    plt.axhline(y=true_probability, color='red', linestyle='--', linewidth=2, label=f'True probability: {true_probability}')\n",
    "    plt.fill_between(range(max_flips), \n",
    "                     running_average - 2*np.sqrt(true_probability*(1-true_probability)/np.arange(1, max_flips+1)),\n",
    "                     running_average + 2*np.sqrt(true_probability*(1-true_probability)/np.arange(1, max_flips+1)),\n",
    "                     alpha=0.2, color='gray', label='95% CI')\n",
    "    plt.xlabel('Number of Flips')\n",
    "    plt.ylabel('Proportion of Heads')\n",
    "    plt.title('Law of Large Numbers: Coin Flips')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Zoom in on convergence\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(running_average[-1000:], alpha=0.7, linewidth=1)\n",
    "    plt.axhline(y=true_probability, color='red', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('Last 1000 Flips')\n",
    "    plt.ylabel('Proportion of Heads')\n",
    "    plt.title('Zoomed View: Convergence')\n",
    "    plt.ylim(true_probability - 0.05, true_probability + 0.05)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print convergence statistics\n",
    "    print(f\"After {max_flips:,} flips:\")\n",
    "    print(f\"Sample proportion: {running_average[-1]:.4f}\")\n",
    "    print(f\"True probability: {true_probability:.4f}\")\n",
    "    print(f\"Error: {abs(running_average[-1] - true_probability):.4f}\")\n",
    "\n",
    "# Run the demo\n",
    "law_of_large_numbers_demo(true_probability=0.5, max_flips=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLN with different probabilities\n",
    "probabilities = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "n_trials = 5000\n",
    "\n",
    "fig, axes = plt.subplots(1, len(probabilities), figsize=(20, 4))\n",
    "\n",
    "for idx, p in enumerate(probabilities):\n",
    "    # Simulate\n",
    "    outcomes = np.random.binomial(1, p, n_trials)\n",
    "    running_avg = np.cumsum(outcomes) / np.arange(1, n_trials + 1)\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].plot(running_avg, alpha=0.7, linewidth=1, color='blue')\n",
    "    axes[idx].axhline(y=p, color='red', linestyle='--', linewidth=2)\n",
    "    axes[idx].set_title(f'p = {p}')\n",
    "    axes[idx].set_xlabel('Trials')\n",
    "    axes[idx].set_ylabel('Sample Proportion')\n",
    "    axes[idx].set_ylim(0, 1)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add final value\n",
    "    axes[idx].text(n_trials*0.7, 0.1, f'Final: {running_avg[-1]:.3f}', \n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Law of Large Numbers Works for Any Probability!', fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cc6d3",
   "metadata": {},
   "source": [
    "**Exercise 2 ‚Äì Casino Simulation (medium)**  \n",
    "Simulate a casino game and show the house always wins in the long run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127850d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Simulate roulette: 18 red, 18 black, 2 green (0, 00)\n",
    "# Bet on red: win $1 if red, lose $1 otherwise\n",
    "# Show cumulative profit/loss over 10000 spins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f25302",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Roulette simulation\n",
    "n_spins = 10000\n",
    "\n",
    "# Probabilities\n",
    "p_red = 18/38  # American roulette\n",
    "p_not_red = 20/38\n",
    "\n",
    "# Expected value per bet\n",
    "expected_value = p_red * 1 + p_not_red * (-1)\n",
    "print(f\"Expected value per $1 bet: ${expected_value:.4f}\")\n",
    "print(f\"House edge: {-expected_value*100:.2f}%\\n\")\n",
    "\n",
    "# Simulate spins\n",
    "outcomes = np.random.choice([1, -1], size=n_spins, p=[p_red, p_not_red])\n",
    "cumulative_profit = np.cumsum(outcomes)\n",
    "\n",
    "# Expected profit line\n",
    "expected_profit = expected_value * np.arange(1, n_spins + 1)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Cumulative profit\n",
    "ax1.plot(cumulative_profit, alpha=0.7, label='Actual profit/loss')\n",
    "ax1.plot(expected_profit, 'r--', linewidth=2, label='Expected (LLN)')\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax1.fill_between(range(n_spins), 0, cumulative_profit, \n",
    "                 where=(cumulative_profit >= 0), alpha=0.3, color='green', label='Profit')\n",
    "ax1.fill_between(range(n_spins), 0, cumulative_profit, \n",
    "                 where=(cumulative_profit < 0), alpha=0.3, color='red', label='Loss')\n",
    "ax1.set_xlabel('Number of Spins')\n",
    "ax1.set_ylabel('Cumulative Profit ($)')\n",
    "ax1.set_title('Casino Always Wins in the Long Run')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average profit per spin\n",
    "avg_profit = cumulative_profit / np.arange(1, n_spins + 1)\n",
    "ax2.plot(avg_profit, alpha=0.7)\n",
    "ax2.axhline(y=expected_value, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Expected: ${expected_value:.4f}')\n",
    "ax2.set_xlabel('Number of Spins')\n",
    "ax2.set_ylabel('Average Profit per Spin ($)')\n",
    "ax2.set_title('Convergence to Expected Value')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAfter {n_spins:,} spins:\")\n",
    "print(f\"Total profit/loss: ${cumulative_profit[-1]:,.2f}\")\n",
    "print(f\"Average per spin: ${avg_profit[-1]:.4f}\")\n",
    "print(f\"\\nüé∞ The house edge guarantees casino profits over time!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1848",
   "metadata": {},
   "source": [
    "## 3. Sampling Methods & Their Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a diverse population for sampling demonstration\n",
    "np.random.seed(42)\n",
    "n_population = 100000\n",
    "\n",
    "# Create population with different segments\n",
    "population_df = pd.DataFrame({\n",
    "    'user_id': range(n_population),\n",
    "    'age': np.concatenate([\n",
    "        np.random.normal(22, 3, n_population//4),   # Young segment\n",
    "        np.random.normal(35, 5, n_population//4),   # Middle segment\n",
    "        np.random.normal(50, 7, n_population//4),   # Older segment\n",
    "        np.random.normal(65, 5, n_population//4)    # Senior segment\n",
    "    ]),\n",
    "    'income': np.concatenate([\n",
    "        np.random.lognormal(10, 0.5, n_population//4),  # Low income\n",
    "        np.random.lognormal(10.8, 0.4, n_population//4), # Medium income\n",
    "        np.random.lognormal(11.2, 0.3, n_population//4), # High income\n",
    "        np.random.lognormal(10.5, 0.6, n_population//4)  # Variable income\n",
    "    ]),\n",
    "    'segment': np.repeat(['Young', 'Middle', 'Older', 'Senior'], n_population//4)\n",
    "})\n",
    "\n",
    "# Add region based on some pattern\n",
    "population_df['region'] = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                                          n_population, p=[0.2, 0.3, 0.25, 0.25])\n",
    "\n",
    "print(\"Population created with segments:\")\n",
    "print(population_df.groupby('segment')['age'].agg(['mean', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82fed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sampling_methods(population_df, sample_size=1000):\n",
    "    \"\"\"Compare different sampling methods\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Simple Random Sampling\n",
    "    simple_random = population_df.sample(n=sample_size, random_state=42)\n",
    "    results['Simple Random'] = simple_random\n",
    "    \n",
    "    # 2. Systematic Sampling (every kth element)\n",
    "    k = len(population_df) // sample_size\n",
    "    systematic = population_df.iloc[::k][:sample_size]\n",
    "    results['Systematic'] = systematic\n",
    "    \n",
    "    # 3. Stratified Sampling (proportional to segments)\n",
    "    stratified = population_df.groupby('segment', group_keys=False).apply(\n",
    "        lambda x: x.sample(int(len(x) * sample_size / len(population_df)), random_state=42)\n",
    "    )\n",
    "    results['Stratified'] = stratified\n",
    "    \n",
    "    # 4. Cluster Sampling (select some regions entirely)\n",
    "    selected_regions = np.random.choice(population_df['region'].unique(), 2, replace=False)\n",
    "    cluster = population_df[population_df['region'].isin(selected_regions)].sample(n=sample_size, random_state=42)\n",
    "    results['Cluster'] = cluster\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare methods\n",
    "sample_size = 1000\n",
    "sampling_results = compare_sampling_methods(population_df, sample_size)\n",
    "\n",
    "# Visualize differences\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (method, sample) in enumerate(sampling_results.items()):\n",
    "    # Age distribution\n",
    "    axes[0, idx].hist(sample['age'], bins=30, alpha=0.7, density=True, edgecolor='black')\n",
    "    axes[0, idx].axvline(sample['age'].mean(), color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, idx].set_title(f'{method}\\nMean Age: {sample[\"age\"].mean():.1f}')\n",
    "    axes[0, idx].set_xlabel('Age')\n",
    "    axes[0, idx].set_ylabel('Density')\n",
    "    \n",
    "    # Segment proportions\n",
    "    segment_props = sample['segment'].value_counts(normalize=True)\n",
    "    axes[1, idx].bar(segment_props.index, segment_props.values, alpha=0.7)\n",
    "    axes[1, idx].set_title(f'Segment Distribution')\n",
    "    axes[1, idx].set_xlabel('Segment')\n",
    "    axes[1, idx].set_ylabel('Proportion')\n",
    "    axes[1, idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Comparison of Sampling Methods', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"\\nSampling Method Comparison:\")\n",
    "print(\"=\"*60)\n",
    "population_mean_age = population_df['age'].mean()\n",
    "population_mean_income = population_df['income'].mean()\n",
    "\n",
    "for method, sample in sampling_results.items():\n",
    "    age_error = abs(sample['age'].mean() - population_mean_age)\n",
    "    income_error = abs(sample['income'].mean() - population_mean_income)\n",
    "    print(f\"{method:15s} | Age Error: {age_error:.2f} | Income Error: ${income_error:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c85c5e",
   "metadata": {},
   "source": [
    "## 4. Central Limit Theorem: The Magic of Sampling Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a3661-2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_clt(distribution_type='exponential', sample_size=30, n_samples=10000):\n",
    "    \"\"\"Show that sample means are normally distributed regardless of population distribution\"\"\"\n",
    "    \n",
    "    # Generate population based on distribution type\n",
    "    if distribution_type == 'exponential':\n",
    "        population_generator = lambda n: np.random.exponential(scale=5, size=n)\n",
    "        title = 'Exponential Population'\n",
    "    elif distribution_type == 'uniform':\n",
    "        population_generator = lambda n: np.random.uniform(0, 10, size=n)\n",
    "        title = 'Uniform Population'\n",
    "    elif distribution_type == 'bimodal':\n",
    "        def bimodal_generator(n):\n",
    "            return np.concatenate([\n",
    "                np.random.normal(3, 1, n//2),\n",
    "                np.random.normal(8, 1, n//2)\n",
    "            ])\n",
    "        population_generator = bimodal_generator\n",
    "        title = 'Bimodal Population'\n",
    "    \n",
    "    # Generate many samples and calculate their means\n",
    "    sample_means = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = population_generator(sample_size)\n",
    "        sample_means.append(sample.mean())\n",
    "    \n",
    "    sample_means = np.array(sample_means)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original distribution\n",
    "    original = population_generator(10000)\n",
    "    axes[0].hist(original, bins=50, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0].set_title(f'{title}\\n(Original Distribution)')\n",
    "    axes[0].set_xlabel('Value')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    \n",
    "    # Sampling distribution of means\n",
    "    axes[1].hist(sample_means, bins=50, density=True, alpha=0.7, color='green', edgecolor='black')\n",
    "    \n",
    "    # Overlay normal distribution\n",
    "    mu = sample_means.mean()\n",
    "    sigma = sample_means.std()\n",
    "    x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
    "    axes[1].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal fit')\n",
    "    axes[1].set_title(f'Distribution of Sample Means\\n(n={sample_size}, {n_samples} samples)')\n",
    "    axes[1].set_xlabel('Sample Mean')\n",
    "    axes[1].set_ylabel('Density')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # Q-Q plot to verify normality\n",
    "    stats.probplot(sample_means, dist=\"norm\", plot=axes[2])\n",
    "    axes[2].set_title('Q-Q Plot\\n(Testing Normality of Sample Means)')\n",
    "    \n",
    "    plt.suptitle(f'Central Limit Theorem: {title} ‚Üí Normal Distribution of Means', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Normality test\n",
    "    _, p_value = stats.shapiro(sample_means[:5000])  # Shapiro test limited to 5000\n",
    "    print(f\"Shapiro-Wilk test for normality of sample means:\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    if p_value > 0.05:\n",
    "        print(\"‚úÖ Sample means are normally distributed (CLT confirmed!)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Sample means may not be perfectly normal (try larger sample size)\")\n",
    "\n",
    "# Demonstrate with different distributions\n",
    "demonstrate_clt('exponential', sample_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b637638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show CLT with different sample sizes\n",
    "sample_sizes_clt = [2, 5, 10, 30, 50, 100]\n",
    "n_simulations = 5000\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Use a heavily skewed distribution (exponential)\n",
    "for idx, n in enumerate(sample_sizes_clt):\n",
    "    # Generate sample means\n",
    "    sample_means = [np.random.exponential(scale=5, size=n).mean() \n",
    "                   for _ in range(n_simulations)]\n",
    "    \n",
    "    # Plot histogram\n",
    "    axes[idx].hist(sample_means, bins=40, density=True, alpha=0.7, \n",
    "                  color='purple', edgecolor='black')\n",
    "    \n",
    "    # Overlay theoretical normal\n",
    "    theoretical_mean = 5  # Mean of exponential with scale=5\n",
    "    theoretical_std = 5 / np.sqrt(n)  # Standard error\n",
    "    x = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "    axes[idx].plot(x, stats.norm.pdf(x, theoretical_mean, theoretical_std), \n",
    "                  'r-', linewidth=2, label='Theoretical Normal')\n",
    "    \n",
    "    axes[idx].set_title(f'n = {n}')\n",
    "    axes[idx].set_xlabel('Sample Mean')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    \n",
    "    # Add skewness value\n",
    "    skew = stats.skew(sample_means)\n",
    "    axes[idx].text(0.7, 0.9, f'Skew: {skew:.3f}', \n",
    "                  transform=axes[idx].transAxes,\n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('CLT: Sample Means Become Normal as n Increases\\n(Even from Exponential Population!)', \n",
    "            fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Key Insight: Even with n=30, sample means are approximately normal!\")\n",
    "print(\"This is why n=30 is often cited as the 'magic number' for CLT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f39466",
   "metadata": {},
   "source": [
    "**Exercise 3 ‚Äì Bootstrap Confidence Intervals (medium)**  \n",
    "Use bootstrap sampling to estimate confidence intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Given a sample of 100 incomes, use bootstrap to:\n",
    "# 1. Estimate the sampling distribution of the mean\n",
    "# 2. Calculate 95% confidence interval\n",
    "# sample_incomes = np.random.lognormal(10, 1, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54870cb",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Original sample\n",
    "np.random.seed(42)\n",
    "sample_incomes = np.random.lognormal(10, 1, 100)\n",
    "original_mean = sample_incomes.mean()\n",
    "\n",
    "# Bootstrap\n",
    "n_bootstrap = 10000\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample = np.random.choice(sample_incomes, size=len(sample_incomes), replace=True)\n",
    "    bootstrap_means.append(bootstrap_sample.mean())\n",
    "\n",
    "bootstrap_means = np.array(bootstrap_means)\n",
    "\n",
    "# Calculate confidence interval\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original sample\n",
    "ax1.hist(sample_incomes, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax1.axvline(original_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Sample mean: ${original_mean:,.0f}')\n",
    "ax1.set_xlabel('Income ($)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Original Sample (n=100)')\n",
    "ax1.legend()\n",
    "\n",
    "# Bootstrap distribution\n",
    "ax2.hist(bootstrap_means, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "ax2.axvline(original_mean, color='red', linestyle='--', linewidth=2, label='Original mean')\n",
    "ax2.axvline(ci_lower, color='orange', linestyle='--', linewidth=2)\n",
    "ax2.axvline(ci_upper, color='orange', linestyle='--', linewidth=2)\n",
    "ax2.fill_betweenx([0, ax2.get_ylim()[1]], ci_lower, ci_upper, \n",
    "                  alpha=0.3, color='orange', label='95% CI')\n",
    "ax2.set_xlabel('Bootstrap Sample Mean ($)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title(f'Bootstrap Distribution ({n_bootstrap} resamples)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle('Bootstrap Confidence Interval Estimation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Bootstrap Results:\")\n",
    "print(f\"Original sample mean: ${original_mean:,.2f}\")\n",
    "print(f\"Bootstrap mean: ${bootstrap_means.mean():,.2f}\")\n",
    "print(f\"Bootstrap std error: ${bootstrap_means.std():,.2f}\")\n",
    "print(f\"\\n95% Confidence Interval: [${ci_lower:,.2f}, ${ci_upper:,.2f}]\")\n",
    "print(f\"\\n‚úÖ We're 95% confident the true population mean is in this interval!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93813ac",
   "metadata": {},
   "source": [
    "## 5. Standard Error and Sample Size Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How sample size affects precision\n",
    "def sample_size_precision_demo():\n",
    "    \"\"\"Show relationship between sample size and standard error\"\"\"\n",
    "    \n",
    "    # True population parameters\n",
    "    true_mean = 100\n",
    "    true_std = 15\n",
    "    \n",
    "    sample_sizes = np.arange(10, 1000, 10)\n",
    "    \n",
    "    # Theoretical standard error\n",
    "    theoretical_se = true_std / np.sqrt(sample_sizes)\n",
    "    \n",
    "    # Empirical standard error (via simulation)\n",
    "    empirical_se = []\n",
    "    for n in sample_sizes:\n",
    "        sample_means = [np.random.normal(true_mean, true_std, n).mean() \n",
    "                       for _ in range(500)]\n",
    "        empirical_se.append(np.std(sample_means))\n",
    "    \n",
    "    # Margin of error for 95% CI\n",
    "    margin_of_error = 1.96 * theoretical_se\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Standard Error vs Sample Size\n",
    "    axes[0].plot(sample_sizes, theoretical_se, 'b-', linewidth=2, label='Theoretical')\n",
    "    axes[0].scatter(sample_sizes[::5], empirical_se[::5], alpha=0.5, s=20, \n",
    "                   color='red', label='Empirical')\n",
    "    axes[0].set_xlabel('Sample Size')\n",
    "    axes[0].set_ylabel('Standard Error')\n",
    "    axes[0].set_title('Standard Error Decreases with ‚àön')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Margin of Error\n",
    "    axes[1].plot(sample_sizes, margin_of_error, 'g-', linewidth=2)\n",
    "    axes[1].axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Target: ¬±1')\n",
    "    axes[1].fill_between(sample_sizes, 0, margin_of_error, \n",
    "                        where=(margin_of_error <= 1), alpha=0.3, color='green')\n",
    "    axes[1].set_xlabel('Sample Size')\n",
    "    axes[1].set_ylabel('Margin of Error (95% CI)')\n",
    "    axes[1].set_title('Precision Improves with Sample Size')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Required sample size for different margins\n",
    "    desired_margins = [5, 3, 2, 1, 0.5]\n",
    "    required_n = [(1.96 * true_std / margin) ** 2 for margin in desired_margins]\n",
    "    \n",
    "    axes[2].bar(range(len(desired_margins)), required_n, alpha=0.7, color='purple')\n",
    "    axes[2].set_xticks(range(len(desired_margins)))\n",
    "    axes[2].set_xticklabels([f'¬±{m}' for m in desired_margins])\n",
    "    axes[2].set_xlabel('Desired Margin of Error')\n",
    "    axes[2].set_ylabel('Required Sample Size')\n",
    "    axes[2].set_title('Sample Size Requirements')\n",
    "    axes[2].set_yscale('log')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for i, n in enumerate(required_n):\n",
    "        axes[2].text(i, n, f'{int(n):,}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle('The Precision-Sample Size Relationship', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key insights\n",
    "    print(\"Key Insights:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"‚Ä¢ To halve the margin of error, you need 4√ó the sample size\")\n",
    "    print(f\"‚Ä¢ Diminishing returns: Going from n=100 to n=400 reduces SE by 50%\")\n",
    "    print(f\"‚Ä¢ But going from n=400 to n=700 only reduces SE by 15%\")\n",
    "\n",
    "sample_size_precision_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98963a1",
   "metadata": {},
   "source": [
    "**Exercise 4 ‚Äì Monte Carlo Integration (hard)**  \n",
    "Use random sampling to estimate œÄ (pi).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Use Monte Carlo method to estimate œÄ:\n",
    "# 1. Generate random points in a square\n",
    "# 2. Check if they fall inside a circle\n",
    "# 3. Use the ratio to estimate œÄ\n",
    "# Show convergence as n increases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecfa82",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "def monte_carlo_pi(n_points=10000, visualize=True):\n",
    "    \"\"\"Estimate œÄ using Monte Carlo sampling\"\"\"\n",
    "    \n",
    "    # Generate random points in [0,1] x [0,1]\n",
    "    x = np.random.uniform(0, 1, n_points)\n",
    "    y = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    # Check if inside quarter circle (radius = 1)\n",
    "    inside_circle = (x**2 + y**2) <= 1\n",
    "    \n",
    "    # Estimate œÄ\n",
    "    # Area of quarter circle = œÄ/4\n",
    "    # Area of square = 1\n",
    "    # Ratio = œÄ/4\n",
    "    pi_estimates = np.cumsum(inside_circle) / np.arange(1, n_points + 1) * 4\n",
    "    \n",
    "    if visualize:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Scatter plot of points\n",
    "        sample_points = min(5000, n_points)\n",
    "        axes[0].scatter(x[:sample_points], y[:sample_points], \n",
    "                       c=inside_circle[:sample_points], \n",
    "                       s=1, alpha=0.5, cmap='RdBu')\n",
    "        \n",
    "        # Draw quarter circle\n",
    "        theta = np.linspace(0, np.pi/2, 100)\n",
    "        axes[0].plot(np.cos(theta), np.sin(theta), 'r-', linewidth=2)\n",
    "        axes[0].set_xlim(0, 1)\n",
    "        axes[0].set_ylim(0, 1)\n",
    "        axes[0].set_aspect('equal')\n",
    "        axes[0].set_title(f'Monte Carlo Sampling\\n(First {sample_points:,} points)')\n",
    "        axes[0].set_xlabel('x')\n",
    "        axes[0].set_ylabel('y')\n",
    "        \n",
    "        # Convergence plot\n",
    "        axes[1].plot(pi_estimates, alpha=0.7, linewidth=1)\n",
    "        axes[1].axhline(y=np.pi, color='red', linestyle='--', linewidth=2, label=f'True œÄ = {np.pi:.6f}')\n",
    "        axes[1].set_xlabel('Number of Points')\n",
    "        axes[1].set_ylabel('Estimate of œÄ')\n",
    "        axes[1].set_title('Convergence to œÄ')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Error plot\n",
    "        errors = np.abs(pi_estimates - np.pi)\n",
    "        axes[2].loglog(range(1, n_points + 1), errors, alpha=0.5, linewidth=1)\n",
    "        axes[2].set_xlabel('Number of Points (log scale)')\n",
    "        axes[2].set_ylabel('|Error| (log scale)')\n",
    "        axes[2].set_title('Error Decreases with ‚àön')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add 1/‚àön reference line\n",
    "        n_range = np.arange(10, n_points, 100)\n",
    "        axes[2].plot(n_range, 1/np.sqrt(n_range), 'r--', alpha=0.7, label='1/‚àön')\n",
    "        axes[2].legend()\n",
    "        \n",
    "        plt.suptitle(f'Monte Carlo Estimation of œÄ', fontsize=14, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return pi_estimates[-1]\n",
    "\n",
    "# Run simulation\n",
    "n_points = 100000\n",
    "pi_estimate = monte_carlo_pi(n_points)\n",
    "\n",
    "print(f\"\\nResults after {n_points:,} points:\")\n",
    "print(f\"Estimated œÄ: {pi_estimate:.6f}\")\n",
    "print(f\"True œÄ:      {np.pi:.6f}\")\n",
    "print(f\"Error:       {abs(pi_estimate - np.pi):.6f}\")\n",
    "print(f\"Error %:     {abs(pi_estimate - np.pi)/np.pi*100:.3f}%\")\n",
    "\n",
    "# Show convergence rate\n",
    "print(\"\\nConvergence Rate:\")\n",
    "for n in [100, 1000, 10000, 100000, 1000000]:\n",
    "    estimate = monte_carlo_pi(n, visualize=False)\n",
    "    error = abs(estimate - np.pi)\n",
    "    print(f\"n = {n:8,}: œÄ ‚âà {estimate:.5f}, error = {error:.5f}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88bba8",
   "metadata": {},
   "source": [
    "## 6. Real-World Application: A/B Test Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f834bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_test_sample_size_calculator(baseline_rate, minimum_detectable_effect, \n",
    "                                  alpha=0.05, power=0.8):\n",
    "    \"\"\"Calculate required sample size for A/B test\"\"\"\n",
    "    \n",
    "    from statsmodels.stats.proportion import proportion_effectsize\n",
    "    from statsmodels.stats.power import zt_ind_solve_power\n",
    "    \n",
    "    # Calculate effect size\n",
    "    effect_size = proportion_effectsize(baseline_rate, \n",
    "                                       baseline_rate + minimum_detectable_effect)\n",
    "    \n",
    "    # Calculate required sample size\n",
    "    n_required = zt_ind_solve_power(effect_size=effect_size,\n",
    "                                    alpha=alpha,\n",
    "                                    power=power,\n",
    "                                    ratio=1)\n",
    "    \n",
    "    return int(np.ceil(n_required))\n",
    "\n",
    "# Interactive sample size exploration\n",
    "baseline_rates = [0.01, 0.05, 0.10, 0.20, 0.30]\n",
    "relative_improvements = [0.05, 0.10, 0.20, 0.30, 0.50]  # Relative changes\n",
    "\n",
    "# Create heatmap of required sample sizes\n",
    "sample_size_matrix = np.zeros((len(baseline_rates), len(relative_improvements)))\n",
    "\n",
    "for i, baseline in enumerate(baseline_rates):\n",
    "    for j, rel_improvement in enumerate(relative_improvements):\n",
    "        abs_improvement = baseline * rel_improvement\n",
    "        n = ab_test_sample_size_calculator(baseline, abs_improvement)\n",
    "        sample_size_matrix[i, j] = n\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sample_size_matrix, annot=True, fmt='.0f', cmap='YlOrRd',\n",
    "            xticklabels=[f'+{int(r*100)}%' for r in relative_improvements],\n",
    "            yticklabels=[f'{int(b*100)}%' for b in baseline_rates])\n",
    "plt.xlabel('Relative Improvement to Detect')\n",
    "plt.ylabel('Baseline Conversion Rate')\n",
    "plt.title('Required Sample Size per Group for A/B Test\\n(Œ±=0.05, Power=0.8)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"=\"*50)\n",
    "print(\"‚Ä¢ Detecting small improvements requires huge samples\")\n",
    "print(\"‚Ä¢ Lower baseline rates need larger samples\")\n",
    "print(\"‚Ä¢ Doubling the effect size quarters the required sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e9d0",
   "metadata": {},
   "source": [
    "## 7. Mini-Challenges\n",
    "- **M1 (easy):** Simulate dice rolls and show convergence to expected value\n",
    "- **M2 (medium):** Implement reservoir sampling for streaming data\n",
    "- **M3 (hard):** Create a function to detect Simpson's Paradox in grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f834bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e9d01",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - Dice rolls convergence\n",
    "n_rolls = 10000\n",
    "dice_rolls = np.random.randint(1, 7, n_rolls)\n",
    "running_average = np.cumsum(dice_rolls) / np.arange(1, n_rolls + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(running_average, alpha=0.7)\n",
    "plt.axhline(y=3.5, color='red', linestyle='--', linewidth=2, label='Expected: 3.5')\n",
    "plt.xlabel('Number of Rolls')\n",
    "plt.ylabel('Average Value')\n",
    "plt.title('Law of Large Numbers: Fair Dice')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "print(f\"After {n_rolls:,} rolls: {running_average[-1]:.4f}\")\n",
    "\n",
    "# M2 - Reservoir sampling\n",
    "def reservoir_sampling(stream, k):\n",
    "    \"\"\"Select k items uniformly from stream of unknown length\"\"\"\n",
    "    reservoir = []\n",
    "    \n",
    "    for i, item in enumerate(stream):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = np.random.randint(0, i + 1)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    \n",
    "    return reservoir\n",
    "\n",
    "# Test reservoir sampling\n",
    "stream = range(1000000)  # Large stream\n",
    "sample = reservoir_sampling(stream, 100)\n",
    "print(f\"Reservoir sample mean: {np.mean(sample):.1f}\")\n",
    "print(f\"True mean: {(1000000-1)/2:.1f}\")\n",
    "\n",
    "# M3 - Simpson's Paradox detector\n",
    "def detect_simpsons_paradox(df, group_col, x_col, y_col):\n",
    "    \"\"\"Detect if correlation reverses when grouped\"\"\"\n",
    "    \n",
    "    # Overall correlation\n",
    "    overall_corr = df[x_col].corr(df[y_col])\n",
    "    \n",
    "    # Group correlations\n",
    "    group_corrs = []\n",
    "    for group in df[group_col].unique():\n",
    "        group_data = df[df[group_col] == group]\n",
    "        if len(group_data) > 2:\n",
    "            corr = group_data[x_col].corr(group_data[y_col])\n",
    "            group_corrs.append(corr)\n",
    "    \n",
    "    # Check for paradox\n",
    "    if overall_corr > 0:\n",
    "        paradox = all(c < 0 for c in group_corrs)\n",
    "    else:\n",
    "        paradox = all(c > 0 for c in group_corrs)\n",
    "    \n",
    "    print(f\"Overall correlation: {overall_corr:.3f}\")\n",
    "    print(f\"Group correlations: {[f'{c:.3f}' for c in group_corrs]}\")\n",
    "    \n",
    "    if paradox:\n",
    "        print(\"‚ö†Ô∏è Simpson's Paradox detected!\")\n",
    "    else:\n",
    "        print(\"‚úÖ No paradox detected\")\n",
    "    \n",
    "    return paradox\n",
    "\n",
    "# Create example with Simpson's Paradox\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'group': np.repeat(['A', 'B', 'C'], 100),\n",
    "    'x': np.concatenate([np.random.normal(10, 2, 100),\n",
    "                        np.random.normal(20, 2, 100),\n",
    "                        np.random.normal(30, 2, 100)]),\n",
    "    'y': np.concatenate([np.random.normal(30, 2, 100) - np.random.normal(10, 2, 100)*0.5,\n",
    "                        np.random.normal(20, 2, 100) - np.random.normal(20, 2, 100)*0.5,\n",
    "                        np.random.normal(10, 2, 100) - np.random.normal(30, 2, 100)*0.5])\n",
    "})\n",
    "\n",
    "detect_simpsons_paradox(data, 'group', 'x', 'y')\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba28e65",
   "metadata": {},
   "source": [
    "## Wrap-Up & Next Steps\n",
    "‚úÖ You understand the relationship between populations and samples  \n",
    "‚úÖ You've proven the Law of Large Numbers empirically  \n",
    "‚úÖ You've seen the Central Limit Theorem in action  \n",
    "‚úÖ You know how sample size affects precision  \n",
    "‚úÖ You can apply sampling theory to real problems  \n",
    "\n",
    "**Key Takeaways:**\n",
    "- Larger samples ‚Üí Better estimates (LLN)\n",
    "- Sample means ‚Üí Normal distribution (CLT)  \n",
    "- Random sampling ‚Üí Unbiased inference\n",
    "- Sample size ‚àù 1/error¬≤ (quadratic relationship)\n",
    "\n",
    "**Week 4 Complete!** You now have a deep understanding of statistical foundations, distributions, EDA techniques, and the mathematical basis for why statistics works!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
