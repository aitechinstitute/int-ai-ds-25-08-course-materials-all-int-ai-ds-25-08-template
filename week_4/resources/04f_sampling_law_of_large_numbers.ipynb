{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8287c6",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** · *Intermediate AI & Data Science*\n",
    "### Week 04 · Notebook 06 – Sampling Theory & Law of Large Numbers\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master the foundations of statistical inference through sampling.\n",
    "\n",
    "> Format: short theory → quick practice → build understanding → mini-challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35e8bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "- Understand population vs sample concepts\n",
    "- Master different sampling techniques\n",
    "- Prove the Law of Large Numbers empirically\n",
    "- Apply Central Limit Theorem in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0238f",
   "metadata": {},
   "source": [
    "## 1. Population vs Sample: The Foundation\n",
    "Understanding why we sample and what it means for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f18528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"population\" - imagine all users of a social media platform\n",
    "POPULATION_SIZE = 1000000  # 1 million users\n",
    "\n",
    "# True population parameters (usually unknown in real life!)\n",
    "TRUE_MEAN_AGE = 28\n",
    "TRUE_STD_AGE = 8\n",
    "TRUE_PREMIUM_RATE = 0.15  # 15% are premium users\n",
    "\n",
    "# Generate population\n",
    "print(\"Creating population of 1 million users...\")\n",
    "population_ages = np.random.normal(TRUE_MEAN_AGE, TRUE_STD_AGE, POPULATION_SIZE)\n",
    "population_ages = np.clip(population_ages, 13, 80)  # Realistic age bounds\n",
    "population_premium = np.random.binomial(1, TRUE_PREMIUM_RATE, POPULATION_SIZE)\n",
    "\n",
    "print(f\"Population created!\")\n",
    "print(f\"True population mean age: {population_ages.mean():.2f}\")\n",
    "print(f\"True population std age: {population_ages.std():.2f}\")\n",
    "print(f\"True premium rate: {population_premium.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take samples of different sizes\n",
    "sample_sizes = [10, 50, 100, 500, 1000, 5000]\n",
    "samples = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    # Take a random sample\n",
    "    sample_indices = np.random.choice(POPULATION_SIZE, n, replace=False)\n",
    "    sample_ages = population_ages[sample_indices]\n",
    "    samples[n] = sample_ages\n",
    "    \n",
    "    # Calculate sample statistics\n",
    "    sample_mean = sample_ages.mean()\n",
    "    sample_std = sample_ages.std(ddof=1)  # Using sample std (n-1)\n",
    "    \n",
    "    # Visualize\n",
    "    axes[idx].hist(sample_ages, bins=30, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[idx].axvline(sample_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean: {sample_mean:.2f}')\n",
    "    axes[idx].axvline(TRUE_MEAN_AGE, color='green', linestyle='--', linewidth=2, label=f'True mean: {TRUE_MEAN_AGE}')\n",
    "    axes[idx].set_title(f'Sample Size: {n}\\nError: {abs(sample_mean - TRUE_MEAN_AGE):.2f} years')\n",
    "    axes[idx].set_xlabel('Age')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    axes[idx].set_xlim(10, 50)\n",
    "\n",
    "plt.suptitle('How Sample Size Affects Estimation Accuracy', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Key Insight: Larger samples give estimates closer to true population values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f40a1",
   "metadata": {},
   "source": [
    "**Exercise 1 – Sample Bias Detection (easy)**  \n",
    "Compare random vs biased sampling and see the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Take two samples of size 1000:\n",
    "# 1. Random sample\n",
    "# 2. Biased sample (only ages < 25)\n",
    "# Compare their means to the true population mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265e60a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Random sample\n",
    "random_sample = np.random.choice(population_ages, 1000, replace=False)\n",
    "random_mean = random_sample.mean()\n",
    "\n",
    "# Biased sample (younger users only)\n",
    "young_indices = np.where(population_ages < 25)[0]\n",
    "biased_sample = population_ages[np.random.choice(young_indices, 1000, replace=False)]\n",
    "biased_mean = biased_sample.mean()\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Random sample\n",
    "ax1.hist(random_sample, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "ax1.axvline(random_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean: {random_mean:.2f}')\n",
    "ax1.axvline(TRUE_MEAN_AGE, color='blue', linestyle='--', linewidth=2, label=f'True mean: {TRUE_MEAN_AGE}')\n",
    "ax1.set_title(f'Random Sample\\nBias: {random_mean - TRUE_MEAN_AGE:.2f} years')\n",
    "ax1.set_xlabel('Age')\n",
    "ax1.legend()\n",
    "\n",
    "# Biased sample\n",
    "ax2.hist(biased_sample, bins=30, alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.axvline(biased_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean: {biased_mean:.2f}')\n",
    "ax2.axvline(TRUE_MEAN_AGE, color='blue', linestyle='--', linewidth=2, label=f'True mean: {TRUE_MEAN_AGE}')\n",
    "ax2.set_title(f'Biased Sample (Age < 25 only)\\nBias: {biased_mean - TRUE_MEAN_AGE:.2f} years')\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle('Random vs Biased Sampling', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n⚠️ Biased sampling leads to incorrect estimates!\")\n",
    "print(f\"Random sample error: {abs(random_mean - TRUE_MEAN_AGE):.2f} years\")\n",
    "print(f\"Biased sample error: {abs(biased_mean - TRUE_MEAN_AGE):.2f} years\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c78e3",
   "metadata": {},
   "source": [
    "## 2. The Law of Large Numbers in Action\n",
    "Watch the magic happen as sample size increases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Law of Large Numbers - Coin Flips\n",
    "def law_of_large_numbers_demo(true_probability=0.5, max_flips=10000):\n",
    "    \"\"\"Show how sample proportion converges to true probability\"\"\"\n",
    "    \n",
    "    # Simulate coin flips\n",
    "    flips = np.random.binomial(1, true_probability, max_flips)\n",
    "    \n",
    "    # Calculate running average\n",
    "    running_average = np.cumsum(flips) / np.arange(1, max_flips + 1)\n",
    "    \n",
    "    # Plot convergence\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Main plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(running_average, alpha=0.7, linewidth=1)\n",
    "    plt.axhline(y=true_probability, color='red', linestyle='--', linewidth=2, label=f'True probability: {true_probability}')\n",
    "    plt.fill_between(range(max_flips), \n",
    "                     running_average - 2*np.sqrt(true_probability*(1-true_probability)/np.arange(1, max_flips+1)),\n",
    "                     running_average + 2*np.sqrt(true_probability*(1-true_probability)/np.arange(1, max_flips+1)),\n",
    "                     alpha=0.2, color='gray', label='95% CI')\n",
    "    plt.xlabel('Number of Flips')\n",
    "    plt.ylabel('Proportion of Heads')\n",
    "    plt.title('Law of Large Numbers: Coin Flips')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Zoom in on convergence\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(running_average[-1000:], alpha=0.7, linewidth=1)\n",
    "    plt.axhline(y=true_probability, color='red', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('Last 1000 Flips')\n",
    "    plt.ylabel('Proportion of Heads')\n",
    "    plt.title('Zoomed View: Convergence')\n",
    "    plt.ylim(true_probability - 0.05, true_probability + 0.05)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print convergence statistics\n",
    "    print(f\"After {max_flips:,} flips:\")\n",
    "    print(f\"Sample proportion: {running_average[-1]:.4f}\")\n",
    "    print(f\"True probability: {true_probability:.4f}\")\n",
    "    print(f\"Error: {abs(running_average[-1] - true_probability):.4f}\")\n",
    "\n",
    "# Run the demo\n",
    "law_of_large_numbers_demo(true_probability=0.5, max_flips=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLN with different probabilities\n",
    "probabilities = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "n_trials = 5000\n",
    "\n",
    "fig, axes = plt.subplots(1, len(probabilities), figsize=(20, 4))\n",
    "\n",
    "for idx, p in enumerate(probabilities):\n",
    "    # Simulate\n",
    "    outcomes = np.random.binomial(1, p, n_trials)\n",
    "    running_avg = np.cumsum(outcomes) / np.arange(1, n_trials + 1)\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].plot(running_avg, alpha=0.7, linewidth=1, color='blue')\n",
    "    axes[idx].axhline(y=p, color='red', linestyle='--', linewidth=2)\n",
    "    axes[idx].set_title(f'p = {p}')\n",
    "    axes[idx].set_xlabel('Trials')\n",
    "    axes[idx].set_ylabel('Sample Proportion')\n",
    "    axes[idx].set_ylim(0, 1)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add final value\n",
    "    axes[idx].text(n_trials*0.7, 0.1, f'Final: {running_avg[-1]:.3f}', \n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Law of Large Numbers Works for Any Probability!', fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cc6d3",
   "metadata": {},
   "source": [
    "**Exercise 2 – Casino Simulation (medium)**  \n",
    "Simulate a casino game and show the house always wins in the long run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127850d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Simulate roulette: 18 red, 18 black, 2 green (0, 00)\n",
    "# Bet on red: win $1 if red, lose $1 otherwise\n",
    "# Show cumulative profit/loss over 10000 spins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f25302",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Roulette simulation\n",
    "n_spins = 10000\n",
    "\n",
    "# Probabilities\n",
    "p_red = 18/38  # American roulette\n",
    "p_not_red = 20/38\n",
    "\n",
    "# Expected value per bet\n",
    "expected_value = p_red * 1 + p_not_red * (-1)\n",
    "print(f\"Expected value per $1 bet: ${expected_value:.4f}\")\n",
    "print(f\"House edge: {-expected_value*100:.2f}%\\n\")\n",
    "\n",
    "# Simulate spins\n",
    "outcomes = np.random.choice([1, -1], size=n_spins, p=[p_red, p_not_red])\n",
    "cumulative_profit = np.cumsum(outcomes)\n",
    "\n",
    "# Expected profit line\n",
    "expected_profit = expected_value * np.arange(1, n_spins + 1)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Cumulative profit\n",
    "ax1.plot(cumulative_profit, alpha=0.7, label='Actual profit/loss')\n",
    "ax1.plot(expected_profit, 'r--', linewidth=2, label='Expected (LLN)')\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax1.fill_between(range(n_spins), 0, cumulative_profit, \n",
    "                 where=(cumulative_profit >= 0), alpha=0.3, color='green', label='Profit')\n",
    "ax1.fill_between(range(n_spins), 0, cumulative_profit, \n",
    "                 where=(cumulative_profit < 0), alpha=0.3, color='red', label='Loss')\n",
    "ax1.set_xlabel('Number of Spins')\n",
    "ax1.set_ylabel('Cumulative Profit ($)')\n",
    "ax1.set_title('Casino Always Wins in the Long Run')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average profit per spin\n",
    "avg_profit = cumulative_profit / np.arange(1, n_spins + 1)\n",
    "ax2.plot(avg_profit, alpha=0.7)\n",
    "ax2.axhline(y=expected_value, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Expected: ${expected_value:.4f}')\n",
    "ax2.set_xlabel('Number of Spins')\n",
    "ax2.set_ylabel('Average Profit per Spin ($)')\n",
    "ax2.set_title('Convergence to Expected Value')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAfter {n_spins:,} spins:\")\n",
    "print(f\"Total profit/loss: ${cumulative_profit[-1]:,.2f}\")\n",
    "print(f\"Average per spin: ${avg_profit[-1]:.4f}\")\n",
    "print(f\"\\n🎰 The house edge guarantees casino profits over time!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1848",
   "metadata": {},
   "source": [
    "## 3. Sampling Methods & Their Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a diverse population for sampling demonstration\n",
    "np.random.seed(42)\n",
    "n_population = 100000\n",
    "\n",
    "# Create population with different segments\n",
    "population_df = pd.DataFrame({\n",
    "    'user_id': range(n_population),\n",
    "    'age': np.concatenate([\n",
    "        np.random.normal(22, 3, n_population//4),   # Young segment\n",
    "        np.random.normal(35, 5, n_population//4),   # Middle segment\n",
    "        np.random.normal(50, 7, n_population//4),   # Older segment\n",
    "        np.random.normal(65, 5, n_population//4)    # Senior segment\n",
    "    ]),\n",
    "    'income': np.concatenate([\n",
    "        np.random.lognormal(10, 0.5, n_population//4),  # Low income\n",
    "        np.random.lognormal(10.8, 0.4, n_population//4), # Medium income\n",
    "        np.random.lognormal(11.2, 0.3, n_population//4), # High income\n",
    "        np.random.lognormal(10.5, 0.6, n_population//4)  # Variable income\n",
    "    ]),\n",
    "    'segment': np.repeat(['Young', 'Middle', 'Older', 'Senior'], n_population//4)\n",
    "})\n",
    "\n",
    "# Add region based on some pattern\n",
    "population_df['region'] = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                                          n_population, p=[0.2, 0.3, 0.25, 0.25])\n",
    "\n",
    "print(\"Population created with segments:\")\n",
    "print(population_df.groupby('segment')['age'].agg(['mean', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82fed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sampling_methods(population_df, sample_size=1000):\n",
    "    \"\"\"Compare different sampling methods\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Simple Random Sampling\n",
    "    simple_random = population_df.sample(n=sample_size, random_state=42)\n",
    "    results['Simple Random'] = simple_random\n",
    "    \n",
    "    # 2. Systematic Sampling (every kth element)\n",
    "    k = len(population_df) // sample_size\n",
    "    systematic = population_df.iloc[::k][:sample_size]\n",
    "    results['Systematic'] = systematic\n",
    "    \n",
    "    # 3. Stratified Sampling (proportional to segments)\n",
    "    stratified = population_df.groupby('segment', group_keys=False).apply(\n",
    "        lambda x: x.sample(int(len(x) * sample_size / len(population_df)), random_state=42)\n",
    "    )\n",
    "    results['Stratified'] = stratified\n",
    "    \n",
    "    # 4. Cluster Sampling (select some regions entirely)\n",
    "    selected_regions = np.random.choice(population_df['region'].unique(), 2, replace=False)\n",
    "    cluster = population_df[population_df['region'].isin(selected_regions)].sample(n=sample_size, random_state=42)\n",
    "    results['Cluster'] = cluster\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare methods\n",
    "sample_size = 1000\n",
    "sampling_results = compare_sampling_methods(population_df, sample_size)\n",
    "\n",
    "# Visualize differences\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (method, sample) in enumerate(sampling_results.items()):\n",
    "    # Age distribution\n",
    "    axes[0, idx].hist(sample['age'], bins=30, alpha=0.7, density=True, edgecolor='black')\n",
    "    axes[0, idx].axvline(sample['age'].mean(), color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, idx].set_title(f'{method}\\nMean Age: {sample[\"age\"].mean():.1f}')\n",
    "    axes[0, idx].set_xlabel('Age')\n",
    "    axes[0, idx].set_ylabel('Density')\n",
    "    \n",
    "    # Segment proportions\n",
    "    segment_props = sample['segment'].value_counts(normalize=True)\n",
    "    axes[1, idx].bar(segment_props.index, segment_props.values, alpha=0.7)\n",
    "    axes[1, idx].set_title(f'Segment Distribution')\n",
    "    axes[1, idx].set_xlabel('Segment')\n",
    "    axes[1, idx].set_ylabel('Proportion')\n",
    "    axes[1, idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Comparison of Sampling Methods', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"\\nSampling Method Comparison:\")\n",
    "print(\"=\"*60)\n",
    "population_mean_age = population_df['age'].mean()\n",
    "population_mean_income = population_df['income'].mean()\n",
    "\n",
    "for method, sample in sampling_results.items():\n",
    "    age_error = abs(sample['age'].mean() - population_mean_age)\n",
    "    income_error = abs(sample['income'].mean() - population_mean_income)\n",
    "    print(f\"{method:15s} | Age Error: {age_error:.2f} | Income Error: ${income_error:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c85c5e",
   "metadata": {},
   "source": [
    "## 4. Central Limit Theorem: The Magic of Sampling Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a3661-2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_clt(distribution_type='exponential', sample_size=30, n_samples=10000):\n",
    "    \"\"\"Show that sample means are normally distributed regardless of population distribution\"\"\"\n",
    "    \n",
    "    # Generate population based on distribution type\n",
    "    if distribution_type == 'exponential':\n",
    "        population_generator = lambda n: np.random.exponential(scale=5, size=n)\n",
    "        title = 'Exponential Population'\n",
    "    elif distribution_type == 'uniform':\n",
    "        population_generator = lambda n: np.random.uniform(0, 10, size=n)\n",
    "        title = 'Uniform Population'\n",
    "    elif distribution_type == 'bimodal':\n",
    "        def bimodal_generator(n):\n",
    "            return np.concatenate([\n",
    "                np.random.normal(3, 1, n//2),\n",
    "                np.random.normal(8, 1, n//2)\n",
    "            ])\n",
    "        population_generator = bimodal_generator\n",
    "        title = 'Bimodal Population'\n",
    "    \n",
    "    # Generate many samples and calculate their means\n",
    "    sample_means = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = population_generator(sample_size)\n",
    "        sample_means.append(sample.mean())\n",
    "    \n",
    "    sample_means = np.array(sample_means)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original distribution\n",
    "    original = population_generator(10000)\n",
    "    axes[0].hist(original, bins=50, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0].set_title(f'{title}\\n(Original Distribution)')\n",
    "    axes[0].set_xlabel('Value')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    \n",
    "    # Sampling distribution of means\n",
    "    axes[1].hist(sample_means, bins=50, density=True, alpha=0.7, color='green', edgecolor='black')\n",
    "    \n",
    "    # Overlay normal distribution\n",
    "    mu = sample_means.mean()\n",
    "    sigma = sample_means.std()\n",
    "    x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
    "    axes[1].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal fit')\n",
    "    axes[1].set_title(f'Distribution of Sample Means\\n(n={sample_size}, {n_samples} samples)')\n",
    "    axes[1].set_xlabel('Sample Mean')\n",
    "    axes[1].set_ylabel('Density')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # Q-Q plot to verify normality\n",
    "    stats.probplot(sample_means, dist=\"norm\", plot=axes[2])\n",
    "    axes[2].set_title('Q-Q Plot\\n(Testing Normality of Sample Means)')\n",
    "    \n",
    "    plt.suptitle(f'Central Limit Theorem: {title} → Normal Distribution of Means', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Normality test\n",
    "    _, p_value = stats.shapiro(sample_means[:5000])  # Shapiro test limited to 5000\n",
    "    print(f\"Shapiro-Wilk test for normality of sample means:\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    if p_value > 0.05:\n",
    "        print(\"✅ Sample means are normally distributed (CLT confirmed!)\")\n",
    "    else:\n",
    "        print(\"⚠️ Sample means may not be perfectly normal (try larger sample size)\")\n",
    "\n",
    "# Demonstrate with different distributions\n",
    "demonstrate_clt('exponential', sample_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b637638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show CLT with different sample sizes\n",
    "sample_sizes_clt = [2, 5, 10, 30, 50, 100]\n",
    "n_simulations = 5000\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Use a heavily skewed distribution (exponential)\n",
    "for idx, n in enumerate(sample_sizes_clt):\n",
    "    # Generate sample means\n",
    "    sample_means = [np.random.exponential(scale=5, size=n).mean() \n",
    "                   for _ in range(n_simulations)]\n",
    "    \n",
    "    # Plot histogram\n",
    "    axes[idx].hist(sample_means, bins=40, density=True, alpha=0.7, \n",
    "                  color='purple', edgecolor='black')\n",
    "    \n",
    "    # Overlay theoretical normal\n",
    "    theoretical_mean = 5  # Mean of exponential with scale=5\n",
    "    theoretical_std = 5 / np.sqrt(n)  # Standard error\n",
    "    x = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "    axes[idx].plot(x, stats.norm.pdf(x, theoretical_mean, theoretical_std), \n",
    "                  'r-', linewidth=2, label='Theoretical Normal')\n",
    "    \n",
    "    axes[idx].set_title(f'n = {n}')\n",
    "    axes[idx].set_xlabel('Sample Mean')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    \n",
    "    # Add skewness value\n",
    "    skew = stats.skew(sample_means)\n",
    "    axes[idx].text(0.7, 0.9, f'Skew: {skew:.3f}', \n",
    "                  transform=axes[idx].transAxes,\n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('CLT: Sample Means Become Normal as n Increases\\n(Even from Exponential Population!)', \n",
    "            fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Key Insight: Even with n=30, sample means are approximately normal!\")\n",
    "print(\"This is why n=30 is often cited as the 'magic number' for CLT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f39466",
   "metadata": {},
   "source": [
    "**Exercise 3 – Bootstrap Confidence Intervals (medium)**  \n",
    "Use bootstrap sampling to estimate confidence intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Given a sample of 100 incomes, use bootstrap to:\n",
    "# 1. Estimate the sampling distribution of the mean\n",
    "# 2. Calculate 95% confidence interval\n",
    "# sample_incomes = np.random.lognormal(10, 1, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54870cb",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Original sample\n",
    "np.random.seed(42)\n",
    "sample_incomes = np.random.lognormal(10, 1, 100)\n",
    "original_mean = sample_incomes.mean()\n",
    "\n",
    "# Bootstrap\n",
    "n_bootstrap = 10000\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample = np.random.choice(sample_incomes, size=len(sample_incomes), replace=True)\n",
    "    bootstrap_means.append(bootstrap_sample.mean())\n",
    "\n",
    "bootstrap_means = np.array(bootstrap_means)\n",
    "\n",
    "# Calculate confidence interval\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original sample\n",
    "ax1.hist(sample_incomes, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax1.axvline(original_mean, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Sample mean: ${original_mean:,.0f}')\n",
    "ax1.set_xlabel('Income ($)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Original Sample (n=100)')\n",
    "ax1.legend()\n",
    "\n",
    "# Bootstrap distribution\n",
    "ax2.hist(bootstrap_means, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "ax2.axvline(original_mean, color='red', linestyle='--', linewidth=2, label='Original mean')\n",
    "ax2.axvline(ci_lower, color='orange', linestyle='--', linewidth=2)\n",
    "ax2.axvline(ci_upper, color='orange', linestyle='--', linewidth=2)\n",
    "ax2.fill_betweenx([0, ax2.get_ylim()[1]], ci_lower, ci_upper, \n",
    "                  alpha=0.3, color='orange', label='95% CI')\n",
    "ax2.set_xlabel('Bootstrap Sample Mean ($)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title(f'Bootstrap Distribution ({n_bootstrap} resamples)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle('Bootstrap Confidence Interval Estimation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Bootstrap Results:\")\n",
    "print(f\"Original sample mean: ${original_mean:,.2f}\")\n",
    "print(f\"Bootstrap mean: ${bootstrap_means.mean():,.2f}\")\n",
    "print(f\"Bootstrap std error: ${bootstrap_means.std():,.2f}\")\n",
    "print(f\"\\n95% Confidence Interval: [${ci_lower:,.2f}, ${ci_upper:,.2f}]\")\n",
    "print(f\"\\n✅ We're 95% confident the true population mean is in this interval!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93813ac",
   "metadata": {},
   "source": [
    "## 5. Standard Error and Sample Size Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How sample size affects precision\n",
    "def sample_size_precision_demo():\n",
    "    \"\"\"Show relationship between sample size and standard error\"\"\"\n",
    "    \n",
    "    # True population parameters\n",
    "    true_mean = 100\n",
    "    true_std = 15\n",
    "    \n",
    "    sample_sizes = np.arange(10, 1000, 10)\n",
    "    \n",
    "    # Theoretical standard error\n",
    "    theoretical_se = true_std / np.sqrt(sample_sizes)\n",
    "    \n",
    "    # Empirical standard error (via simulation)\n",
    "    empirical_se = []\n",
    "    for n in sample_sizes:\n",
    "        sample_means = [np.random.normal(true_mean, true_std, n).mean() \n",
    "                       for _ in range(500)]\n",
    "        empirical_se.append(np.std(sample_means))\n",
    "    \n",
    "    # Margin of error for 95% CI\n",
    "    margin_of_error = 1.96 * theoretical_se\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Standard Error vs Sample Size\n",
    "    axes[0].plot(sample_sizes, theoretical_se, 'b-', linewidth=2, label='Theoretical')\n",
    "    axes[0].scatter(sample_sizes[::5], empirical_se[::5], alpha=0.5, s=20, \n",
    "                   color='red', label='Empirical')\n",
    "    axes[0].set_xlabel('Sample Size')\n",
    "    axes[0].set_ylabel('Standard Error')\n",
    "    axes[0].set_title('Standard Error Decreases with √n')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Margin of Error\n",
    "    axes[1].plot(sample_sizes, margin_of_error, 'g-', linewidth=2)\n",
    "    axes[1].axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Target: ±1')\n",
    "    axes[1].fill_between(sample_sizes, 0, margin_of_error, \n",
    "                        where=(margin_of_error <= 1), alpha=0.3, color='green')\n",
    "    axes[1].set_xlabel('Sample Size')\n",
    "    axes[1].set_ylabel('Margin of Error (95% CI)')\n",
    "    axes[1].set_title('Precision Improves with Sample Size')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Required sample size for different margins\n",
    "    desired_margins = [5, 3, 2, 1, 0.5]\n",
    "    required_n = [(1.96 * true_std / margin) ** 2 for margin in desired_margins]\n",
    "    \n",
    "    axes[2].bar(range(len(desired_margins)), required_n, alpha=0.7, color='purple')\n",
    "    axes[2].set_xticks(range(len(desired_margins)))\n",
    "    axes[2].set_xticklabels([f'±{m}' for m in desired_margins])\n",
    "    axes[2].set_xlabel('Desired Margin of Error')\n",
    "    axes[2].set_ylabel('Required Sample Size')\n",
    "    axes[2].set_title('Sample Size Requirements')\n",
    "    axes[2].set_yscale('log')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for i, n in enumerate(required_n):\n",
    "        axes[2].text(i, n, f'{int(n):,}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle('The Precision-Sample Size Relationship', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key insights\n",
    "    print(\"Key Insights:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"• To halve the margin of error, you need 4× the sample size\")\n",
    "    print(f\"• Diminishing returns: Going from n=100 to n=400 reduces SE by 50%\")\n",
    "    print(f\"• But going from n=400 to n=700 only reduces SE by 15%\")\n",
    "\n",
    "sample_size_precision_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98963a1",
   "metadata": {},
   "source": [
    "**Exercise 4 – Monte Carlo Integration (hard)**  \n",
    "Use random sampling to estimate π (pi).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n",
    "# Use Monte Carlo method to estimate π:\n",
    "# 1. Generate random points in a square\n",
    "# 2. Check if they fall inside a circle\n",
    "# 3. Use the ratio to estimate π\n",
    "# Show convergence as n increases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecfa82",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "def monte_carlo_pi(n_points=10000, visualize=True):\n",
    "    \"\"\"Estimate π using Monte Carlo sampling\"\"\"\n",
    "    \n",
    "    # Generate random points in [0,1] x [0,1]\n",
    "    x = np.random.uniform(0, 1, n_points)\n",
    "    y = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    # Check if inside quarter circle (radius = 1)\n",
    "    inside_circle = (x**2 + y**2) <= 1\n",
    "    \n",
    "    # Estimate π\n",
    "    # Area of quarter circle = π/4\n",
    "    # Area of square = 1\n",
    "    # Ratio = π/4\n",
    "    pi_estimates = np.cumsum(inside_circle) / np.arange(1, n_points + 1) * 4\n",
    "    \n",
    "    if visualize:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Scatter plot of points\n",
    "        sample_points = min(5000, n_points)\n",
    "        axes[0].scatter(x[:sample_points], y[:sample_points], \n",
    "                       c=inside_circle[:sample_points], \n",
    "                       s=1, alpha=0.5, cmap='RdBu')\n",
    "        \n",
    "        # Draw quarter circle\n",
    "        theta = np.linspace(0, np.pi/2, 100)\n",
    "        axes[0].plot(np.cos(theta), np.sin(theta), 'r-', linewidth=2)\n",
    "        axes[0].set_xlim(0, 1)\n",
    "        axes[0].set_ylim(0, 1)\n",
    "        axes[0].set_aspect('equal')\n",
    "        axes[0].set_title(f'Monte Carlo Sampling\\n(First {sample_points:,} points)')\n",
    "        axes[0].set_xlabel('x')\n",
    "        axes[0].set_ylabel('y')\n",
    "        \n",
    "        # Convergence plot\n",
    "        axes[1].plot(pi_estimates, alpha=0.7, linewidth=1)\n",
    "        axes[1].axhline(y=np.pi, color='red', linestyle='--', linewidth=2, label=f'True π = {np.pi:.6f}')\n",
    "        axes[1].set_xlabel('Number of Points')\n",
    "        axes[1].set_ylabel('Estimate of π')\n",
    "        axes[1].set_title('Convergence to π')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Error plot\n",
    "        errors = np.abs(pi_estimates - np.pi)\n",
    "        axes[2].loglog(range(1, n_points + 1), errors, alpha=0.5, linewidth=1)\n",
    "        axes[2].set_xlabel('Number of Points (log scale)')\n",
    "        axes[2].set_ylabel('|Error| (log scale)')\n",
    "        axes[2].set_title('Error Decreases with √n')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add 1/√n reference line\n",
    "        n_range = np.arange(10, n_points, 100)\n",
    "        axes[2].plot(n_range, 1/np.sqrt(n_range), 'r--', alpha=0.7, label='1/√n')\n",
    "        axes[2].legend()\n",
    "        \n",
    "        plt.suptitle(f'Monte Carlo Estimation of π', fontsize=14, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return pi_estimates[-1]\n",
    "\n",
    "# Run simulation\n",
    "n_points = 100000\n",
    "pi_estimate = monte_carlo_pi(n_points)\n",
    "\n",
    "print(f\"\\nResults after {n_points:,} points:\")\n",
    "print(f\"Estimated π: {pi_estimate:.6f}\")\n",
    "print(f\"True π:      {np.pi:.6f}\")\n",
    "print(f\"Error:       {abs(pi_estimate - np.pi):.6f}\")\n",
    "print(f\"Error %:     {abs(pi_estimate - np.pi)/np.pi*100:.3f}%\")\n",
    "\n",
    "# Show convergence rate\n",
    "print(\"\\nConvergence Rate:\")\n",
    "for n in [100, 1000, 10000, 100000, 1000000]:\n",
    "    estimate = monte_carlo_pi(n, visualize=False)\n",
    "    error = abs(estimate - np.pi)\n",
    "    print(f\"n = {n:8,}: π ≈ {estimate:.5f}, error = {error:.5f}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88bba8",
   "metadata": {},
   "source": [
    "## 6. Real-World Application: A/B Test Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f834bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_test_sample_size_calculator(baseline_rate, minimum_detectable_effect, \n",
    "                                  alpha=0.05, power=0.8):\n",
    "    \"\"\"Calculate required sample size for A/B test\"\"\"\n",
    "    \n",
    "    from statsmodels.stats.proportion import proportion_effectsize\n",
    "    from statsmodels.stats.power import zt_ind_solve_power\n",
    "    \n",
    "    # Calculate effect size\n",
    "    effect_size = proportion_effectsize(baseline_rate, \n",
    "                                       baseline_rate + minimum_detectable_effect)\n",
    "    \n",
    "    # Calculate required sample size\n",
    "    n_required = zt_ind_solve_power(effect_size=effect_size,\n",
    "                                    alpha=alpha,\n",
    "                                    power=power,\n",
    "                                    ratio=1)\n",
    "    \n",
    "    return int(np.ceil(n_required))\n",
    "\n",
    "# Interactive sample size exploration\n",
    "baseline_rates = [0.01, 0.05, 0.10, 0.20, 0.30]\n",
    "relative_improvements = [0.05, 0.10, 0.20, 0.30, 0.50]  # Relative changes\n",
    "\n",
    "# Create heatmap of required sample sizes\n",
    "sample_size_matrix = np.zeros((len(baseline_rates), len(relative_improvements)))\n",
    "\n",
    "for i, baseline in enumerate(baseline_rates):\n",
    "    for j, rel_improvement in enumerate(relative_improvements):\n",
    "        abs_improvement = baseline * rel_improvement\n",
    "        n = ab_test_sample_size_calculator(baseline, abs_improvement)\n",
    "        sample_size_matrix[i, j] = n\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sample_size_matrix, annot=True, fmt='.0f', cmap='YlOrRd',\n",
    "            xticklabels=[f'+{int(r*100)}%' for r in relative_improvements],\n",
    "            yticklabels=[f'{int(b*100)}%' for b in baseline_rates])\n",
    "plt.xlabel('Relative Improvement to Detect')\n",
    "plt.ylabel('Baseline Conversion Rate')\n",
    "plt.title('Required Sample Size per Group for A/B Test\\n(α=0.05, Power=0.8)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"=\"*50)\n",
    "print(\"• Detecting small improvements requires huge samples\")\n",
    "print(\"• Lower baseline rates need larger samples\")\n",
    "print(\"• Doubling the effect size quarters the required sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e9d0",
   "metadata": {},
   "source": [
    "## 7. Mini-Challenges\n",
    "- **M1 (easy):** Simulate dice rolls and show convergence to expected value\n",
    "- **M2 (medium):** Implement reservoir sampling for streaming data\n",
    "- **M3 (hard):** Create a function to detect Simpson's Paradox in grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f834bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e9d01",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - Dice rolls convergence\n",
    "n_rolls = 10000\n",
    "dice_rolls = np.random.randint(1, 7, n_rolls)\n",
    "running_average = np.cumsum(dice_rolls) / np.arange(1, n_rolls + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(running_average, alpha=0.7)\n",
    "plt.axhline(y=3.5, color='red', linestyle='--', linewidth=2, label='Expected: 3.5')\n",
    "plt.xlabel('Number of Rolls')\n",
    "plt.ylabel('Average Value')\n",
    "plt.title('Law of Large Numbers: Fair Dice')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "print(f\"After {n_rolls:,} rolls: {running_average[-1]:.4f}\")\n",
    "\n",
    "# M2 - Reservoir sampling\n",
    "def reservoir_sampling(stream, k):\n",
    "    \"\"\"Select k items uniformly from stream of unknown length\"\"\"\n",
    "    reservoir = []\n",
    "    \n",
    "    for i, item in enumerate(stream):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = np.random.randint(0, i + 1)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    \n",
    "    return reservoir\n",
    "\n",
    "# Test reservoir sampling\n",
    "stream = range(1000000)  # Large stream\n",
    "sample = reservoir_sampling(stream, 100)\n",
    "print(f\"Reservoir sample mean: {np.mean(sample):.1f}\")\n",
    "print(f\"True mean: {(1000000-1)/2:.1f}\")\n",
    "\n",
    "# M3 - Simpson's Paradox detector\n",
    "def detect_simpsons_paradox(df, group_col, x_col, y_col):\n",
    "    \"\"\"Detect if correlation reverses when grouped\"\"\"\n",
    "    \n",
    "    # Overall correlation\n",
    "    overall_corr = df[x_col].corr(df[y_col])\n",
    "    \n",
    "    # Group correlations\n",
    "    group_corrs = []\n",
    "    for group in df[group_col].unique():\n",
    "        group_data = df[df[group_col] == group]\n",
    "        if len(group_data) > 2:\n",
    "            corr = group_data[x_col].corr(group_data[y_col])\n",
    "            group_corrs.append(corr)\n",
    "    \n",
    "    # Check for paradox\n",
    "    if overall_corr > 0:\n",
    "        paradox = all(c < 0 for c in group_corrs)\n",
    "    else:\n",
    "        paradox = all(c > 0 for c in group_corrs)\n",
    "    \n",
    "    print(f\"Overall correlation: {overall_corr:.3f}\")\n",
    "    print(f\"Group correlations: {[f'{c:.3f}' for c in group_corrs]}\")\n",
    "    \n",
    "    if paradox:\n",
    "        print(\"⚠️ Simpson's Paradox detected!\")\n",
    "    else:\n",
    "        print(\"✅ No paradox detected\")\n",
    "    \n",
    "    return paradox\n",
    "\n",
    "# Create example with Simpson's Paradox\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'group': np.repeat(['A', 'B', 'C'], 100),\n",
    "    'x': np.concatenate([np.random.normal(10, 2, 100),\n",
    "                        np.random.normal(20, 2, 100),\n",
    "                        np.random.normal(30, 2, 100)]),\n",
    "    'y': np.concatenate([np.random.normal(30, 2, 100) - np.random.normal(10, 2, 100)*0.5,\n",
    "                        np.random.normal(20, 2, 100) - np.random.normal(20, 2, 100)*0.5,\n",
    "                        np.random.normal(10, 2, 100) - np.random.normal(30, 2, 100)*0.5])\n",
    "})\n",
    "\n",
    "detect_simpsons_paradox(data, 'group', 'x', 'y')\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba28e65",
   "metadata": {},
   "source": [
    "## Wrap-Up & Next Steps\n",
    "✅ You understand the relationship between populations and samples  \n",
    "✅ You've proven the Law of Large Numbers empirically  \n",
    "✅ You've seen the Central Limit Theorem in action  \n",
    "✅ You know how sample size affects precision  \n",
    "✅ You can apply sampling theory to real problems  \n",
    "\n",
    "**Key Takeaways:**\n",
    "- Larger samples → Better estimates (LLN)\n",
    "- Sample means → Normal distribution (CLT)  \n",
    "- Random sampling → Unbiased inference\n",
    "- Sample size ∝ 1/error² (quadratic relationship)\n",
    "\n",
    "**Week 4 Complete!** You now have a deep understanding of statistical foundations, distributions, EDA techniques, and the mathematical basis for why statistics works!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
