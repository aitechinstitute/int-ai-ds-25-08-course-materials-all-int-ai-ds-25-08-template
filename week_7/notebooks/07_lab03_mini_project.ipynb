{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 7 - Lab 03: Mini-Project Challenge\n",
    "**Instructor:** Amir Charkhi | **Type:** Integrated Practice\n",
    "\n",
    "> Apply everything you learned in Week 7!\n",
    "\n",
    "## üéØ Challenge Objectives\n",
    "\n",
    "Build a complete ML pipeline from scratch:\n",
    "- Load and explore data\n",
    "- Engineer features\n",
    "- Compare multiple models\n",
    "- Select and evaluate the best one\n",
    "- Save your model\n",
    "\n",
    "**Time**: 40-50 minutes  \n",
    "**Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (Challenge)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Your Mission\n",
    "\n",
    "**Scenario**: You're a data scientist at a hospital. You need to predict whether a patient has heart disease based on medical measurements.\n",
    "\n",
    "**Business Impact**: Early detection can save lives!\n",
    "\n",
    "**Success Criteria**:\n",
    "- High **recall** (can't miss patients with disease!)\n",
    "- Good **precision** (don't want too many false alarms)\n",
    "- Model ready to save for deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this first!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"üè• Heart Disease Prediction Challenge\")\n",
    "print(\"‚úÖ Setup complete! Let's save some lives!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 1: Load and Explore Data\n",
    "\n",
    "**Estimated time**: 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic heart disease dataset\n",
    "np.random.seed(42)\n",
    "n_patients = 500\n",
    "\n",
    "# Generate features\n",
    "data = {\n",
    "    'age': np.random.randint(30, 80, n_patients),\n",
    "    'sex': np.random.choice([0, 1], n_patients),  # 0=Female, 1=Male\n",
    "    'chest_pain': np.random.choice([0, 1, 2, 3], n_patients),\n",
    "    'resting_bp': np.random.randint(90, 200, n_patients),\n",
    "    'cholesterol': np.random.randint(120, 400, n_patients),\n",
    "    'fasting_sugar': np.random.choice([0, 1], n_patients, p=[0.85, 0.15]),\n",
    "    'max_heart_rate': np.random.randint(70, 200, n_patients),\n",
    "    'exercise_angina': np.random.choice([0, 1], n_patients, p=[0.7, 0.3]),\n",
    "    'oldpeak': np.random.uniform(0, 6, n_patients),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create target with realistic patterns\n",
    "risk_score = (\n",
    "    (df['age'] > 55) * 0.2 +\n",
    "    (df['sex'] == 1) * 0.15 +\n",
    "    (df['chest_pain'] > 0) * 0.25 +\n",
    "    (df['cholesterol'] > 240) * 0.2 +\n",
    "    (df['max_heart_rate'] < 120) * 0.15 +\n",
    "    (df['exercise_angina'] == 1) * 0.3 +\n",
    "    (df['oldpeak'] > 2) * 0.2\n",
    ")\n",
    "\n",
    "df['heart_disease'] = (risk_score > np.random.uniform(0.3, 0.7, n_patients)).astype(int)\n",
    "\n",
    "# TODO 1.1: Display basic information\n",
    "# - Shape of dataset\n",
    "# - First few rows\n",
    "# - Class distribution\n",
    "# - Check for missing values\n",
    "\n",
    "print(\"Heart Disease Dataset\")\n",
    "print(\"=\"*50)\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ Task 1.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.2: Create visualizations to understand the data\n",
    "# Requirements:\n",
    "#   1. Plot disease rate by age groups\n",
    "#   2. Compare cholesterol levels for disease vs no disease\n",
    "#   3. Any other interesting pattern\n",
    "\n",
    "# Your code here:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Your visualization\n",
    "\n",
    "\n",
    "# Plot 2: Your visualization\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° What patterns do you notice?\")\n",
    "print(\"‚úÖ Task 1.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÇÔ∏è Step 2: Prepare Data\n",
    "\n",
    "**Estimated time**: 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Feature Engineering (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.1: Create new features if you want\n",
    "# Ideas:\n",
    "#   - Age groups (e.g., is_senior = age > 60)\n",
    "#   - High cholesterol flag (cholesterol > 240)\n",
    "#   - BMI-like features\n",
    "#   - Interaction features\n",
    "\n",
    "# Your code here (optional):\n",
    "\n",
    "\n",
    "print(\"‚úÖ Task 2.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.2: Split the data\n",
    "# Requirements:\n",
    "#   - Separate features (X) and target (y)\n",
    "#   - 80/20 split\n",
    "#   - Stratified\n",
    "#   - random_state=42\n",
    "\n",
    "# Your code here:\n",
    "X = # Select all columns except 'heart_disease'\n",
    "y = # Select 'heart_disease' column\n",
    "\n",
    "X_train, X_test, y_train, y_test = # Your split\n",
    "\n",
    "# Validation\n",
    "print(f\"Training set: {len(X_train)} patients\")\n",
    "print(f\"Test set: {len(X_test)} patients\")\n",
    "print(f\"\\nClass balance in training:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "assert len(X_train) + len(X_test) == len(df), \"‚ùå Split error!\"\n",
    "print(\"\\n‚úÖ Task 2.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Step 3: Build and Compare Models\n",
    "\n",
    "**Estimated time**: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Compare Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.1: Compare at least 3 different models\n",
    "# Use cross-validation on TRAINING data only\n",
    "# Evaluate with multiple metrics: accuracy, precision, recall, F1\n",
    "\n",
    "print(\"üî¨ Model Comparison with Cross-Validation\\n\")\n",
    "\n",
    "# Define your models\n",
    "models = {\n",
    "    # Add at least 3 models here\n",
    "    # Example: 'Logistic Regression': LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Your code here:\n",
    "cv = # Create StratifiedKFold\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Calculate multiple metrics\n",
    "    acc_scores = # accuracy\n",
    "    prec_scores = # precision\n",
    "    rec_scores = # recall\n",
    "    f1_scores = # f1\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': f\"{acc_scores.mean():.3f} ¬± {acc_scores.std():.3f}\",\n",
    "        'Precision': f\"{prec_scores.mean():.3f} ¬± {prec_scores.std():.3f}\",\n",
    "        'Recall': f\"{rec_scores.mean():.3f} ¬± {rec_scores.std():.3f}\",\n",
    "        'F1': f\"{f1_scores.mean():.3f} ¬± {f1_scores.std():.3f}\",\n",
    "        'Recall_mean': rec_scores.mean()  # For sorting\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values('Recall_mean', ascending=False)\n",
    "print(results_df[['Model', 'Accuracy', 'Precision', 'Recall', 'F1']].to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Remember: For disease detection, RECALL is most important!\")\n",
    "print(\"   We can't afford to miss patients with heart disease.\")\n",
    "print(\"\\n‚úÖ Task 3.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.2: Based on CV results, select the best model\n",
    "# Consider: What metric is most important for this problem?\n",
    "\n",
    "# Your decision:\n",
    "best_model_name = # Name of model you chose\n",
    "best_model = # Create instance of that model\n",
    "\n",
    "print(f\"üèÜ Selected Model: {best_model_name}\")\n",
    "print(f\"\\nüìã Reasoning:\")\n",
    "# Write your reasoning here (why this model?)\n",
    "\n",
    "print(\"\\n‚úÖ Task 3.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 4: Final Evaluation\n",
    "\n",
    "**Estimated time**: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Train and Evaluate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.1: Train your chosen model on full training set\n",
    "# Then evaluate on test set (ONCE!)\n",
    "\n",
    "print(\"üéØ Final Model Training & Evaluation\\n\")\n",
    "\n",
    "# Train on full training set\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = # Your predictions\n",
    "\n",
    "# Calculate all metrics\n",
    "accuracy = # Calculate\n",
    "precision = # Calculate\n",
    "recall = # Calculate\n",
    "f1 = # Calculate\n",
    "\n",
    "# Display results\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {accuracy:.3f} ({accuracy:.1%})\")\n",
    "print(f\"Precision: {precision:.3f} ({precision:.1%})\")\n",
    "print(f\"Recall:    {recall:.3f} ({recall:.1%}) ‚≠ê\")\n",
    "print(f\"F1-Score:  {f1:.3f} ({f1:.1%})\")\n",
    "\n",
    "print(\"\\nüí° What this means:\")\n",
    "print(f\"  - We catch {recall:.1%} of patients with heart disease\")\n",
    "print(f\"  - When we predict disease, we're right {precision:.1%} of the time\")\n",
    "\n",
    "if recall > 0.7:\n",
    "    print(\"\\n‚úÖ Good recall! We're catching most disease cases.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Recall could be higher - consider model tuning\")\n",
    "\n",
    "print(\"\\n‚úÖ Task 4.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.2: Create and analyze confusion matrix\n",
    "# Show both raw counts and percentages\n",
    "\n",
    "# Your code here:\n",
    "cm = # Calculate confusion matrix\n",
    "tn, fp, fn, tp = # Extract values\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot confusion matrices (counts and normalized)\n",
    "# Your plotting code\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze\n",
    "print(\"\\nüîç Analysis:\")\n",
    "print(f\"  Correctly identified healthy: {tn}\")\n",
    "print(f\"  Correctly identified disease: {tp}\")\n",
    "print(f\"  False alarms (predicted disease, was healthy): {fp}\")\n",
    "print(f\"  MISSED cases (predicted healthy, had disease): {fn} ‚ö†Ô∏è\")\n",
    "\n",
    "if fn < fp:\n",
    "    print(\"\\n‚úÖ Good! We're prioritizing catching disease cases.\")\n",
    "\n",
    "print(\"\\n‚úÖ Task 4.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Step 5: Save Your Model\n",
    "\n",
    "**Estimated time**: 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Pickle the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.1: Save your model with pickle\n",
    "# Include: model, feature names, performance metrics\n",
    "\n",
    "# Your code here:\n",
    "model_package = {\n",
    "    'model': # Your trained model\n",
    "    'feature_names': # List of feature names\n",
    "    'metrics': {\n",
    "        # Your performance metrics\n",
    "    },\n",
    "    'model_name': best_model_name,\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('heart_disease_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(\"üíæ Model saved as: heart_disease_model.pkl\")\n",
    "print(\"\\n‚úÖ Task 5.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: Test Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.2: Load the model and make a test prediction\n",
    "\n",
    "# Your code here:\n",
    "with open('heart_disease_model.pkl', 'rb') as f:\n",
    "    loaded_model = # Load the model\n",
    "\n",
    "# Test with first 5 test samples\n",
    "test_predictions = # Make predictions\n",
    "\n",
    "print(\"üîç Testing loaded model:\")\n",
    "print(f\"Predictions: {test_predictions}\")\n",
    "print(f\"Actual:      {y_test.iloc[:5].values}\")\n",
    "print(\"\\n‚úÖ Model loads and works correctly!\")\n",
    "print(\"‚úÖ Task 5.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Step 6: Write Your Report\n",
    "\n",
    "**Estimated time**: 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1: Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6.1: Complete this summary report\n",
    "\n",
    "print(\"üè• HEART DISEASE PREDICTION - PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä DATASET:\")\n",
    "print(f\"  Total patients: {len(df)}\")\n",
    "print(f\"  Features used: {len(X.columns)}\")\n",
    "print(f\"  Disease prevalence: {(y==1).mean():.1%}\")\n",
    "\n",
    "print(\"\\nü§ñ MODEL SELECTION:\")\n",
    "print(f\"  Models compared: {len(models)}\")\n",
    "print(f\"  Selected model: {best_model_name}\")\n",
    "print(f\"  Selection criteria: [YOUR REASONING HERE]\")\n",
    "\n",
    "print(\"\\nüìà PERFORMANCE:\")\n",
    "print(f\"  Test Accuracy:  {accuracy:.1%}\")\n",
    "print(f\"  Test Precision: {precision:.1%}\")\n",
    "print(f\"  Test Recall:    {recall:.1%} ‚≠ê\")\n",
    "print(f\"  Test F1-Score:  {f1:.1%}\")\n",
    "\n",
    "print(\"\\nüí° BUSINESS IMPACT:\")\n",
    "print(f\"  ‚úÖ Catches {recall:.0%} of disease cases\")\n",
    "print(f\"  ‚úÖ {precision:.0%} of positive predictions are correct\")\n",
    "print(f\"  ‚ö†Ô∏è Misses {(1-recall)*100:.0f}% of disease cases (false negatives)\")\n",
    "print(f\"  ‚ö†Ô∏è {(1-precision)*100:.0f}% false alarm rate\")\n",
    "\n",
    "print(\"\\nüéØ RECOMMENDATIONS:\")\n",
    "# TODO: Add your recommendations\n",
    "# - Should this model be deployed?\n",
    "# - What could improve performance?\n",
    "# - What are the risks?\n",
    "\n",
    "print(\"\\n‚úÖ Task 6.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Challenge Complete!\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "‚úÖ **Loaded and explored** medical data  \n",
    "‚úÖ **Prepared data** with proper train/test split  \n",
    "‚úÖ **Compared multiple models** using cross-validation  \n",
    "‚úÖ **Selected best model** based on business needs  \n",
    "‚úÖ **Evaluated thoroughly** with multiple metrics  \n",
    "‚úÖ **Saved model** for deployment  \n",
    "‚úÖ **Documented results** professionally  \n",
    "\n",
    "### Skills Demonstrated:\n",
    "\n",
    "1. **End-to-end ML workflow** from data to model\n",
    "2. **Proper evaluation** using train/test split and CV\n",
    "3. **Metric selection** based on business context\n",
    "4. **Model comparison** with stratified CV\n",
    "5. **Production readiness** with model persistence\n",
    "6. **Communication** through clear reporting\n",
    "\n",
    "### Reflection Questions:\n",
    "\n",
    "1. **Why did you choose your final model?**\n",
    "2. **Is recall of {recall:.1%} acceptable for this problem?**\n",
    "3. **What would you do to improve performance?**\n",
    "4. **Would you deploy this model? Why or why not?**\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try different hyperparameters\n",
    "- Add more feature engineering\n",
    "- Experiment with ensemble methods\n",
    "- Build a simple Streamlit app (see Notebook 04)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully completed a real-world ML project following all best practices from Week 7!\n",
    "\n",
    "**You're now ready to tackle real ML challenges! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
