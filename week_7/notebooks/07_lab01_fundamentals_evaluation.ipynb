{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 7 - Lab 01: ML Fundamentals & Evaluation Practice\n",
    "**Instructor:** Amir Charkhi | **Type:** Hands-On Practice\n",
    "\n",
    "> Practice what you learned in Notebooks 01 & 02\n",
    "\n",
    "## üéØ Lab Objectives\n",
    "\n",
    "In this lab, you'll practice:\n",
    "- Loading data and performing train/test split\n",
    "- Training your first models\n",
    "- Calculating and interpreting evaluation metrics\n",
    "- Understanding confusion matrices\n",
    "- Choosing the right metric for the problem\n",
    "\n",
    "**Time**: 30-40 minutes  \n",
    "**Difficulty**: ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (Beginner)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Quick Reference\n",
    "\n",
    "**Classification Metrics:**\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "**Regression Metrics:**\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this cell first!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Setup complete! Let's start practicing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Exercise 1: Train/Test Split Basics\n",
    "\n",
    "Let's practice the most fundamental concept in ML!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "print(f\"Dataset loaded!\")\n",
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Classes: {np.unique(y)}\")\n",
    "\n",
    "# TODO 1.1: Print the class distribution (how many 0s and 1s)\n",
    "# Hint: Use np.bincount(y) or pd.Series(y).value_counts()\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Perform Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.2: Split the data into train and test sets\n",
    "# Requirements:\n",
    "#   - Use 80% for training, 20% for testing\n",
    "#   - Set random_state=42 for reproducibility\n",
    "#   - Use stratify=y to maintain class balance\n",
    "\n",
    "# Your code here:\n",
    "X_train, X_test, y_train, y_test = # Complete this line\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(f\"‚úÖ Training set: {len(X_train)} samples\")\n",
    "print(f\"‚úÖ Test set: {len(X_test)} samples\")\n",
    "print(f\"‚úÖ Train/test split: {len(X_train)/len(X)*100:.0f}% / {len(X_test)/len(X)*100:.0f}%\")\n",
    "\n",
    "assert len(X_train) + len(X_test) == len(X), \"‚ùå Split doesn't add up!\"\n",
    "assert len(X_train) > len(X_test), \"‚ùå Training set should be larger!\"\n",
    "print(\"\\nüéâ Task 1.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Verify Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.3: Calculate and compare class proportions\n",
    "# Calculate the percentage of class 1 (positive class) in:\n",
    "#   - Original dataset (y)\n",
    "#   - Training set (y_train)\n",
    "#   - Test set (y_test)\n",
    "\n",
    "# Your code here:\n",
    "original_class1_pct = # Calculate percentage of 1s in y\n",
    "train_class1_pct = # Calculate percentage of 1s in y_train\n",
    "test_class1_pct = # Calculate percentage of 1s in y_test\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(f\"Class 1 percentage:\")\n",
    "print(f\"  Original: {original_class1_pct:.1%}\")\n",
    "print(f\"  Training: {train_class1_pct:.1%}\")\n",
    "print(f\"  Test:     {test_class1_pct:.1%}\")\n",
    "\n",
    "if abs(train_class1_pct - original_class1_pct) < 0.02:  # Within 2%\n",
    "    print(\"\\n‚úÖ Stratification worked! Proportions are similar.\")\n",
    "    print(\"üéâ Task 1.3 Complete!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Proportions differ - did you use stratify=y?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Exercise 2: Building Your First Model\n",
    "\n",
    "Now let's train a model and make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Train a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.1: Create and train a Logistic Regression model\n",
    "# Steps:\n",
    "#   1. Create a LogisticRegression model (set max_iter=1000)\n",
    "#   2. Fit it on the training data\n",
    "#   3. Make predictions on the test set\n",
    "\n",
    "# Your code here:\n",
    "model = # Create the model\n",
    "# Fit the model\n",
    "y_pred = # Make predictions on X_test\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(f\"‚úÖ Model trained!\")\n",
    "print(f\"‚úÖ Predictions made for {len(y_pred)} test samples\")\n",
    "print(f\"\\nFirst 10 predictions: {y_pred[:10]}\")\n",
    "print(f\"First 10 actual:      {y_test[:10]}\")\n",
    "print(\"\\nüéâ Task 2.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Calculate Basic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.2: Calculate accuracy, precision, recall, and F1-score\n",
    "# Use the functions from sklearn.metrics\n",
    "\n",
    "# Your code here:\n",
    "accuracy = # Calculate accuracy\n",
    "precision = # Calculate precision\n",
    "recall = # Calculate recall\n",
    "f1 = # Calculate F1-score\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(\"Model Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f} ({accuracy:.1%})\")\n",
    "print(f\"  Precision: {precision:.4f} ({precision:.1%})\")\n",
    "print(f\"  Recall:    {recall:.4f} ({recall:.1%})\")\n",
    "print(f\"  F1-Score:  {f1:.4f} ({f1:.1%})\")\n",
    "\n",
    "if accuracy > 0.9:\n",
    "    print(\"\\n‚úÖ Great performance! Above 90% accuracy!\")\n",
    "    print(\"üéâ Task 2.2 Complete!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Accuracy is {accuracy:.1%} - check your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé≠ Exercise 3: Understanding Confusion Matrix\n",
    "\n",
    "The confusion matrix is the foundation of all classification metrics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.1: Calculate the confusion matrix\n",
    "# Then extract True Negatives, False Positives, False Negatives, True Positives\n",
    "\n",
    "# Your code here:\n",
    "cm = # Calculate confusion matrix using y_test and y_pred\n",
    "tn, fp, fn, tp = # Extract the four values (use cm.ravel())\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  True Negatives (TN):  {tn}\")\n",
    "print(f\"  False Positives (FP): {fp}\")\n",
    "print(f\"  False Negatives (FN): {fn}\")\n",
    "print(f\"  True Positives (TP):  {tp}\")\n",
    "\n",
    "assert tn + fp + fn + tp == len(y_test), \"‚ùå Values don't add up!\"\n",
    "print(\"\\nüéâ Task 3.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Calculate Metrics from Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.2: Calculate metrics manually from TP, TN, FP, FN\n",
    "# This helps you understand what each metric really means!\n",
    "\n",
    "# Formulas:\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "\n",
    "# Your code here:\n",
    "manual_accuracy = # Calculate manually\n",
    "manual_precision = # Calculate manually\n",
    "manual_recall = # Calculate manually\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(\"Manual Calculations:\")\n",
    "print(f\"  Accuracy:  {manual_accuracy:.4f}\")\n",
    "print(f\"  Precision: {manual_precision:.4f}\")\n",
    "print(f\"  Recall:    {manual_recall:.4f}\")\n",
    "\n",
    "print(\"\\nCompare with sklearn:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "\n",
    "if abs(manual_accuracy - accuracy) < 0.001:\n",
    "    print(\"\\n‚úÖ Perfect match! You understand the formulas!\")\n",
    "    print(\"üéâ Task 3.2 Complete!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Numbers don't match - check your formulas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Exercise 4: Regression Metrics\n",
    "\n",
    "Now let's practice with regression (predicting numbers)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Train a Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.1: Load diabetes dataset, split, and train a model\n",
    "# This is a regression problem (predicting disease progression)\n",
    "\n",
    "# Load data\n",
    "diabetes = load_diabetes()\n",
    "X_reg = diabetes.data\n",
    "y_reg = diabetes.target\n",
    "\n",
    "print(f\"Regression dataset loaded: {len(X_reg)} samples\")\n",
    "\n",
    "# Your code here:\n",
    "# 1. Split into train/test (80/20, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = # Split here\n",
    "\n",
    "# 2. Create and train a LinearRegression model\n",
    "reg_model = # Create model\n",
    "# Fit model\n",
    "\n",
    "# 3. Make predictions on test set\n",
    "y_pred_reg = # Predict\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(f\"\\n‚úÖ Model trained and predictions made!\")\n",
    "print(f\"Sample predictions: {y_pred_reg[:5]}\")\n",
    "print(f\"Sample actual:      {y_test_reg[:5]}\")\n",
    "print(\"\\nüéâ Task 4.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Calculate Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.2: Calculate MAE, MSE, RMSE, and R¬≤\n",
    "\n",
    "# Your code here:\n",
    "mae = # Mean Absolute Error\n",
    "mse = # Mean Squared Error\n",
    "rmse = # Root Mean Squared Error (use np.sqrt on MSE)\n",
    "r2 = # R¬≤ Score\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(\"Regression Metrics:\")\n",
    "print(f\"  MAE:  {mae:.2f}\")\n",
    "print(f\"  MSE:  {mse:.2f}\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  R¬≤:   {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"  On average, predictions are off by {mae:.1f} units (MAE)\")\n",
    "print(f\"  Model explains {r2*100:.1f}% of variance in disease progression\")\n",
    "\n",
    "if r2 > 0.3:\n",
    "    print(f\"\\n‚úÖ R¬≤ > 0.3 is reasonable for this dataset!\")\n",
    "    print(\"üéâ Task 4.2 Complete!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è R¬≤ is low - check your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Exercise 5: Choosing the Right Metric\n",
    "\n",
    "Understanding WHEN to use which metric is critical!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Metric Selection Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.1: For each scenario, choose the best metric\n",
    "# Options: 'accuracy', 'precision', 'recall', 'f1', 'mae', 'rmse', 'r2'\n",
    "\n",
    "# Scenario 1: Email spam detection - we DON'T want important emails in spam\n",
    "scenario_1_metric = \"\"  # Your answer\n",
    "\n",
    "# Scenario 2: Cancer detection - we CAN'T miss cancer cases (false negatives are deadly)\n",
    "scenario_2_metric = \"\"  # Your answer\n",
    "\n",
    "# Scenario 3: Predicting house prices - large errors are worse than small errors\n",
    "scenario_3_metric = \"\"  # Your answer\n",
    "\n",
    "# Scenario 4: Customer churn prediction - need balance, classes imbalanced\n",
    "scenario_4_metric = \"\"  # Your answer\n",
    "\n",
    "# Validation (Don't modify)\n",
    "answers = {\n",
    "    1: ('precision', \"We don't want false positives (important email marked as spam)\"),\n",
    "    2: ('recall', \"We must catch all cancer cases (minimize false negatives)\"),\n",
    "    3: ('rmse', \"RMSE penalizes large errors more than MAE\"),\n",
    "    4: ('f1', \"F1 balances precision and recall for imbalanced classes\")\n",
    "}\n",
    "\n",
    "score = 0\n",
    "your_answers = [scenario_1_metric, scenario_2_metric, scenario_3_metric, scenario_4_metric]\n",
    "\n",
    "for i, (correct, explanation) in answers.items():\n",
    "    if your_answers[i-1].lower() == correct:\n",
    "        print(f\"‚úÖ Scenario {i}: Correct! {explanation}\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(f\"‚ùå Scenario {i}: Expected '{correct}'. {explanation}\")\n",
    "\n",
    "print(f\"\\nScore: {score}/4\")\n",
    "if score == 4:\n",
    "    print(\"üéâ Perfect! You understand metric selection!\")\n",
    "    print(\"üéâ Task 5.1 Complete!\")\n",
    "elif score >= 2:\n",
    "    print(\"üëç Good! Review the wrong ones.\")\n",
    "else:\n",
    "    print(\"üìö Review Notebook 02 on when to use each metric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Lab Complete!\n",
    "\n",
    "### What You Practiced:\n",
    "\n",
    "‚úÖ **Exercise 1**: Train/test split with stratification  \n",
    "‚úÖ **Exercise 2**: Training models and making predictions  \n",
    "‚úÖ **Exercise 3**: Understanding confusion matrices  \n",
    "‚úÖ **Exercise 4**: Regression metrics (MAE, RMSE, R¬≤)  \n",
    "‚úÖ **Exercise 5**: Choosing the right metric  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Always stratify** for classification problems\n",
    "2. **Test set is sacred** - never touch during training!\n",
    "3. **Different problems need different metrics**\n",
    "4. **Confusion matrix** is the foundation of all classification metrics\n",
    "5. **R¬≤ shows explanatory power**, RMSE shows prediction error\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Move to **Lab 02** for cross-validation practice\n",
    "- Review concepts you struggled with\n",
    "- Try modifying the code to deepen understanding\n",
    "\n",
    "**Great job! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
