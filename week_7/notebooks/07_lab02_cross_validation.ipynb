{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 7 - Lab 02: Cross-Validation & Model Comparison\n",
    "**Instructor:** Amir Charkhi | **Type:** Hands-On Practice\n",
    "\n",
    "> Practice what you learned in Notebook 03\n",
    "\n",
    "## üéØ Lab Objectives\n",
    "\n",
    "In this lab, you'll practice:\n",
    "- Implementing K-fold cross-validation\n",
    "- Using stratified cross-validation\n",
    "- Comparing multiple models fairly\n",
    "- Understanding when to use which CV strategy\n",
    "\n",
    "**Time**: 25-35 minutes  \n",
    "**Difficulty**: ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Quick Reference\n",
    "\n",
    "**Cross-Validation:**\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Simple cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=cv)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this cell first!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, load_iris\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"‚úÖ Setup complete! Let's practice cross-validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Exercise 1: Basic Cross-Validation\n",
    "\n",
    "Let's start with simple K-fold cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Load Data and Simple CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "print(f\"Dataset: {len(X)} wine samples, {len(np.unique(y))} classes\")\n",
    "\n",
    "# TODO 1.1: Perform 5-fold cross-validation\n",
    "# Steps:\n",
    "#   1. Create a LogisticRegression model (max_iter=1000)\n",
    "#   2. Use cross_val_score with cv=5\n",
    "#   3. Calculate mean and std of scores\n",
    "\n",
    "# Your code here:\n",
    "model = # Create model\n",
    "cv_scores = # Perform cross-validation\n",
    "\n",
    "mean_score = # Calculate mean\n",
    "std_score = # Calculate std\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(f\"\\n5-Fold CV Scores: {cv_scores}\")\n",
    "print(f\"Mean: {mean_score:.4f}\")\n",
    "print(f\"Std:  {std_score:.4f}\")\n",
    "print(f\"\\nResult: {mean_score:.4f} ¬± {std_score:.4f}\")\n",
    "\n",
    "if len(cv_scores) == 5:\n",
    "    print(\"\\n‚úÖ Correct! You performed 5-fold CV\")\n",
    "    print(\"üéâ Task 1.1 Complete!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Should have 5 scores - check your cv parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Visualize Fold Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.2: Create a bar plot showing performance across folds\n",
    "# Include a horizontal line showing the mean\n",
    "\n",
    "# Your code here (plotting):\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create bar plot of cv_scores\n",
    "# Add a horizontal line at mean_score\n",
    "# Add labels, title, and grid\n",
    "\n",
    "\n",
    "# Validation\n",
    "print(\"üéâ Task 1.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Exercise 2: Stratified vs Regular K-Fold\n",
    "\n",
    "See the difference stratification makes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Compare Both Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.1: Compare regular K-Fold vs Stratified K-Fold\n",
    "# Use the same model for both\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Your code here:\n",
    "# 1. Regular K-Fold\n",
    "kfold = # Create KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_regular = # cross_val_score with kfold\n",
    "\n",
    "# 2. Stratified K-Fold\n",
    "kfold_stratified = # Create StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_stratified = # cross_val_score with kfold_stratified\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(\"Regular K-Fold:\")\n",
    "print(f\"  Scores: {scores_regular}\")\n",
    "print(f\"  Mean: {scores_regular.mean():.4f} ¬± {scores_regular.std():.4f}\")\n",
    "\n",
    "print(\"\\nStratified K-Fold:\")\n",
    "print(f\"  Scores: {scores_stratified}\")\n",
    "print(f\"  Mean: {scores_stratified.mean():.4f} ¬± {scores_stratified.std():.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Difference in std: {abs(scores_regular.std() - scores_stratified.std()):.4f}\")\n",
    "print(\"   Stratified usually has lower variance (more stable)\")\n",
    "\n",
    "if scores_stratified.std() <= scores_regular.std():\n",
    "    print(\"\\n‚úÖ Stratified CV is more stable!\")\n",
    "    print(\"üéâ Task 2.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Check Class Distribution in Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.2: Examine class distribution in each fold\n",
    "# This shows WHY stratification matters\n",
    "\n",
    "print(\"Original class distribution:\")\n",
    "print(pd.Series(y).value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nClass distribution in Stratified K-Fold:\")\n",
    "\n",
    "# Your code here:\n",
    "# Loop through the folds and print class distribution in each test set\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold_stratified.split(X, y), 1):\n",
    "    y_test_fold = # Get y values for test_idx\n",
    "    # Print fold number and class proportions\n",
    "    \n",
    "\n",
    "print(\"\\nüí° Notice: All folds have similar class proportions!\")\n",
    "print(\"üéâ Task 2.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Exercise 3: Comparing Multiple Models\n",
    "\n",
    "Now let's compare several models using CV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Evaluate Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.1: Compare 4 different models using cross-validation\n",
    "# Models: Logistic Regression, Decision Tree, Random Forest, KNN\n",
    "\n",
    "# Load fresh dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Your code here:\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Perform CV and store results\n",
    "    scores = # cross_val_score\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Mean': # mean of scores\n",
    "        'Std': # std of scores\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by mean score\n",
    "results_df = pd.DataFrame(results).sort_values('Mean', ascending=False)\n",
    "\n",
    "# Validation (Don't modify)\n",
    "print(\"Model Comparison (5-Fold Stratified CV):\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_model = results_df.iloc[0]['Model']\n",
    "best_score = results_df.iloc[0]['Mean']\n",
    "\n",
    "print(f\"\\nüèÜ Winner: {best_model}\")\n",
    "print(f\"   Score: {best_score:.4f}\")\n",
    "print(\"\\nüéâ Task 3.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.2: Create a horizontal bar chart comparing models\n",
    "# Include error bars showing standard deviation\n",
    "\n",
    "# Your code here:\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create horizontal bar plot with error bars\n",
    "# Use results_df data\n",
    "# Add title, labels, and grid\n",
    "\n",
    "\n",
    "print(\"üéâ Task 3.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Exercise 4: Understanding CV Scores\n",
    "\n",
    "Let's dig deeper into what CV tells us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Interpret CV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create two models with different characteristics\n",
    "model_consistent = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_unstable = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores_consistent = cross_val_score(model_consistent, X, y, cv=cv)\n",
    "scores_unstable = cross_val_score(model_unstable, X, y, cv=cv)\n",
    "\n",
    "# TODO 4.1: Analyze and explain the difference\n",
    "# Calculate mean and std for both, then interpret\n",
    "\n",
    "# Your code here:\n",
    "mean_cons = # Mean of scores_consistent\n",
    "std_cons = # Std of scores_consistent\n",
    "\n",
    "mean_unstable = # Mean of scores_unstable\n",
    "std_unstable = # Std of scores_unstable\n",
    "\n",
    "# Print comparison\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Random Forest:  {mean_cons:.4f} ¬± {std_cons:.4f}\")\n",
    "print(f\"Decision Tree:  {mean_unstable:.4f} ¬± {std_unstable:.4f}\")\n",
    "\n",
    "# TODO: Fill in this interpretation\n",
    "# Which model is more stable?\n",
    "# Which has higher variance?\n",
    "# Which would you choose?\n",
    "\n",
    "if std_cons < std_unstable:\n",
    "    print(\"\\n‚úÖ Random Forest is more consistent across folds!\")\n",
    "    print(\"   Lower std = more stable predictions\")\n",
    "    print(\"üéâ Task 4.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: When is High Variance a Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.2: Multiple choice - Select the correct answer\n",
    "# When should you be concerned about high variance in CV scores?\n",
    "\n",
    "# Options:\n",
    "# A: \"When std > 0.05\"\n",
    "# B: \"When std is large relative to mean (e.g., std/mean > 0.1)\"\n",
    "# C: \"Never - high variance is always fine\"\n",
    "# D: \"Only when mean score is low\"\n",
    "\n",
    "your_answer = \"\"  # Put A, B, C, or D\n",
    "\n",
    "# Validation\n",
    "correct_answer = \"B\"\n",
    "explanation = \"\"\"High variance relative to mean suggests the model's performance \n",
    "is inconsistent across different data splits. A std/mean ratio > 0.1 (10% coefficient \n",
    "of variation) is often considered concerning.\"\"\"\n",
    "\n",
    "if your_answer.upper() == correct_answer:\n",
    "    print(\"‚úÖ Correct!\")\n",
    "    print(explanation)\n",
    "    print(\"\\nüéâ Task 4.2 Complete!\")\n",
    "else:\n",
    "    print(f\"‚ùå Incorrect. The answer is {correct_answer}.\")\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Exercise 5: Putting It All Together\n",
    "\n",
    "Final challenge: Complete ML workflow with CV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Complete Evaluation Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.1: Follow the complete best-practice workflow\n",
    "# This combines everything you've learned!\n",
    "\n",
    "# Load data\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "print(\"Complete ML Evaluation Workflow\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Step 1: Split data (hold out test set)\n",
    "# TODO: Split into 80% train, 20% test, stratified, random_state=42\n",
    "X_train, X_test, y_train, y_test = # Your split here\n",
    "\n",
    "print(f\"\\nStep 1: Data Split\")\n",
    "print(f\"  Train: {len(X_train)} samples\")\n",
    "print(f\"  Test:  {len(X_test)} samples (LOCKED)\")\n",
    "\n",
    "# Step 2: Compare models using CV on training data only!\n",
    "print(f\"\\nStep 2: Model Selection (CV on training data)\")\n",
    "\n",
    "models_to_try = {\n",
    "    'Logistic': LogisticRegression(max_iter=200),\n",
    "    'Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Forest': RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "}\n",
    "\n",
    "# TODO: Use StratifiedKFold, evaluate each model\n",
    "cv = # Create StratifiedKFold\n",
    "best_score = 0\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "\n",
    "for name, model in models_to_try.items():\n",
    "    scores = # CV scores\n",
    "    mean = scores.mean()\n",
    "    print(f\"  {name}: {mean:.4f} ¬± {scores.std():.4f}\")\n",
    "    \n",
    "    if mean > best_score:\n",
    "        best_score = mean\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "print(f\"\\n  ‚Üí Selected: {best_model_name}\")\n",
    "\n",
    "# Step 3: Train best model on full training set\n",
    "print(f\"\\nStep 3: Training {best_model_name} on full training set\")\n",
    "# TODO: Fit best_model on X_train, y_train\n",
    "\n",
    "\n",
    "# Step 4: Evaluate ONCE on test set\n",
    "print(f\"\\nStep 4: Final Evaluation on Test Set\")\n",
    "# TODO: Make predictions and calculate accuracy\n",
    "y_pred = # Predict on X_test\n",
    "test_accuracy = # Calculate accuracy\n",
    "\n",
    "print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if test_accuracy > 0.8:\n",
    "    print(\"\\n‚úÖ Excellent workflow! Model performs well.\")\n",
    "    print(\"\\nüí° Key Points:\")\n",
    "    print(\"  - Used CV to SELECT model (on training data)\")\n",
    "    print(\"  - Held out test set until the end\")\n",
    "    print(\"  - Evaluated ONCE on test set\")\n",
    "    print(\"\\nüéâ Task 5.1 Complete!\")\n",
    "    print(\"üéâ Lab 02 Complete!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Test accuracy is {test_accuracy:.1%} - check your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Lab Complete!\n",
    "\n",
    "### What You Practiced:\n",
    "\n",
    "‚úÖ **Exercise 1**: Basic K-fold cross-validation  \n",
    "‚úÖ **Exercise 2**: Stratified vs regular K-fold  \n",
    "‚úÖ **Exercise 3**: Comparing multiple models  \n",
    "‚úÖ **Exercise 4**: Interpreting CV results  \n",
    "‚úÖ **Exercise 5**: Complete evaluation workflow  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Always use StratifiedKFold** for classification\n",
    "2. **CV gives mean ¬± std** - both matter!\n",
    "3. **High variance = unstable** model\n",
    "4. **Use CV for selection**, test set for final evaluation\n",
    "5. **Never touch test set** during model development\n",
    "\n",
    "### The Golden Workflow:\n",
    "\n",
    "```python\n",
    "1. Split: Train (80%) + Test (20%) - LOCK test set\n",
    "2. Use CV on training set to compare models\n",
    "3. Select best model based on CV results\n",
    "4. Train best model on full training set\n",
    "5. Evaluate ONCE on test set - this is your final score\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try **Lab 03** for mini-project practice\n",
    "- Experiment with different K values (3, 5, 10)\n",
    "- Compare models on your own datasets\n",
    "\n",
    "**Excellent work! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
