{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** Â· *Intermediate AI & Data Science*\n",
    "### Week 8 - Lab 03: Model Selection Mini-Project\n",
    "**Instructor:** Amir Charkhi | **Type:** Integrated Challenge\n",
    "\n",
    "> Apply everything you learned about Linear and Tree-Based Models!\n",
    "\n",
    "## ðŸŽ¯ Challenge Objectives\n",
    "\n",
    "Build a complete ML solution:\n",
    "- Comprehensive EDA and feature engineering\n",
    "- Compare linear and tree-based approaches\n",
    "- Perform hyperparameter tuning\n",
    "- Select the best model using rigorous evaluation\n",
    "- Provide business recommendations\n",
    "\n",
    "**Time**: 50-60 minutes  \n",
    "**Difficulty**: â­â­â­â­â­ (Challenge)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Your Mission\n",
    "\n",
    "**Scenario**: You're a data scientist at an insurance company. You need to predict whether a customer will make a claim and estimate the claim amount.\n",
    "\n",
    "**Business Context**:\n",
    "- Classification task: Will the customer claim? (binary)\n",
    "- Regression task: If yes, how much? (continuous)\n",
    "- Need both accuracy and interpretability\n",
    "- Model will inform premium pricing\n",
    "\n",
    "**Success Criteria**:\n",
    "- âœ… Classification accuracy > 75%\n",
    "- âœ… Regression RÂ² > 0.6\n",
    "- âœ… Models properly validated with CV\n",
    "- âœ… Clear recommendation with justification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this first!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(\"ðŸ¥ Insurance Claim Prediction Challenge\")\n",
    "print(\"âœ… Setup complete! Time to build something amazing!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Part 1: Data Loading and Exploration\n",
    "\n",
    "**Estimated time**: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic insurance dataset\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "data = {\n",
    "    'age': np.random.randint(18, 70, n_customers),\n",
    "    'bmi': np.random.normal(28, 6, n_customers),\n",
    "    'children': np.random.poisson(1.2, n_customers),\n",
    "    'smoker': np.random.choice([0, 1], n_customers, p=[0.8, 0.2]),\n",
    "    'region': np.random.choice([0, 1, 2, 3], n_customers),  # 4 regions\n",
    "    'previous_claims': np.random.poisson(0.5, n_customers),\n",
    "    'coverage_level': np.random.choice([1, 2, 3], n_customers, p=[0.2, 0.5, 0.3]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate realistic claim probability\n",
    "claim_prob = (\n",
    "    0.1 +  # Base probability\n",
    "    (df['age'] / 100) * 0.3 +\n",
    "    (df['smoker'] == 1) * 0.35 +\n",
    "    (df['bmi'] > 30) * 0.15 +\n",
    "    (df['previous_claims'] > 0) * 0.25 +\n",
    "    np.random.normal(0, 0.1, n_customers)\n",
    ")\n",
    "claim_prob = np.clip(claim_prob, 0, 1)\n",
    "\n",
    "df['has_claim'] = (np.random.random(n_customers) < claim_prob).astype(int)\n",
    "\n",
    "# Generate claim amounts (only for those who claimed)\n",
    "base_amount = 3000\n",
    "df['claim_amount'] = 0.0\n",
    "claim_mask = df['has_claim'] == 1\n",
    "\n",
    "df.loc[claim_mask, 'claim_amount'] = (\n",
    "    base_amount +\n",
    "    df.loc[claim_mask, 'age'] * 50 +\n",
    "    df.loc[claim_mask, 'bmi'] * 100 +\n",
    "    df.loc[claim_mask, 'smoker'] * 5000 +\n",
    "    df.loc[claim_mask, 'previous_claims'] * 2000 +\n",
    "    np.random.normal(0, 1500, claim_mask.sum())\n",
    ")\n",
    "df.loc[claim_mask, 'claim_amount'] = np.maximum(df.loc[claim_mask, 'claim_amount'], 500)\n",
    "\n",
    "print(\"âœ… Dataset created successfully!\")\n",
    "print(f\"Total customers: {len(df)}\")\n",
    "print(f\"Customers with claims: {df['has_claim'].sum()} ({df['has_claim'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Comprehensive EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.2: Perform comprehensive exploratory data analysis\n",
    "# Requirements:\n",
    "#   1. Display dataset info, shape, and basic statistics\n",
    "#   2. Check for missing values\n",
    "#   3. Show class distribution for has_claim\n",
    "#   4. Display claim_amount statistics (for those with claims)\n",
    "#   5. Create at least 3 visualizations showing key patterns\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your code here:\n",
    "# 1. Basic info\n",
    "\n",
    "\n",
    "# 2. Missing values\n",
    "\n",
    "\n",
    "# 3. Class distribution\n",
    "\n",
    "\n",
    "# 4. Claim amount stats (only for claims)\n",
    "\n",
    "\n",
    "# 5. Visualizations\n",
    "# Suggested plots:\n",
    "#   - Claim rate by age groups\n",
    "#   - Claim amount distribution\n",
    "#   - Claim rate: smokers vs non-smokers\n",
    "#   - Correlation heatmap\n",
    "\n",
    "\n",
    "print(\"\\nâœ… Task 1.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”§ Part 2: Feature Engineering\n",
    "\n",
    "**Estimated time**: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Create Meaningful Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.1: Engineer new features\n",
    "# Suggestions:\n",
    "#   - Age groups (young, middle, senior)\n",
    "#   - BMI categories (underweight, normal, overweight, obese)\n",
    "#   - Risk score combining multiple factors\n",
    "#   - Interaction features (e.g., smoker * age)\n",
    "#   - Has previous claims (binary)\n",
    "\n",
    "# Your code here:\n",
    "df_features = df.copy()\n",
    "\n",
    "# Example: Age groups\n",
    "# df_features['age_group'] = pd.cut(df['age'], bins=[0, 30, 50, 100], labels=['young', 'middle', 'senior'])\n",
    "\n",
    "# Create your features:\n",
    "\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(df_features.columns.tolist())\n",
    "print(f\"\\nTotal features: {df_features.shape[1]}\")\n",
    "print(\"\\nâœ… Task 2.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.2: Prepare datasets for both classification and regression\n",
    "# Requirements:\n",
    "#   1. For CLASSIFICATION: predict has_claim\n",
    "#      - Features: all except has_claim and claim_amount\n",
    "#      - Target: has_claim\n",
    "#      - Split: 80/20, stratified\n",
    "#   \n",
    "#   2. For REGRESSION: predict claim_amount (only for customers WITH claims)\n",
    "#      - Filter: only rows where has_claim == 1\n",
    "#      - Features: all except has_claim and claim_amount\n",
    "#      - Target: claim_amount\n",
    "#      - Split: 80/20\n",
    "\n",
    "# Your code here:\n",
    "# Classification data\n",
    "X_clf = # Select features\n",
    "y_clf = # Target\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = # Split\n",
    "\n",
    "# Regression data (only claims)\n",
    "df_claims = # Filter only customers with claims\n",
    "X_reg = # Select features\n",
    "y_reg = # Target\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = # Split\n",
    "\n",
    "# Validation\n",
    "print(\"Data Preparation Summary:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nCLASSIFICATION (Predict if claim occurs):\")\n",
    "print(f\"  Training samples: {len(X_train_clf)}\")\n",
    "print(f\"  Test samples: {len(X_test_clf)}\")\n",
    "print(f\"  Features: {X_clf.shape[1]}\")\n",
    "print(f\"  Class balance: {y_train_clf.value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "print(f\"\\nREGRESSION (Predict claim amount):\")\n",
    "print(f\"  Training samples: {len(X_train_reg)}\")\n",
    "print(f\"  Test samples: {len(X_test_reg)}\")\n",
    "print(f\"  Features: {X_reg.shape[1]}\")\n",
    "print(f\"  Target range: ${y_train_reg.min():.0f} - ${y_train_reg.max():.0f}\")\n",
    "\n",
    "print(\"\\nâœ… Task 2.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ¤– Part 3: Classification Models\n",
    "\n",
    "**Estimated time**: 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Build and Compare Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.1: Compare multiple classification models\n",
    "# Requirements:\n",
    "#   1. Build at least 4 models:\n",
    "#      - Logistic Regression (baseline)\n",
    "#      - Logistic Regression with polynomial features (degree=2)\n",
    "#      - Decision Tree (tune max_depth)\n",
    "#      - Random Forest\n",
    "#   2. Use 5-fold stratified cross-validation\n",
    "#   3. Evaluate: accuracy, precision, recall, F1\n",
    "#   4. Create comparison table\n",
    "\n",
    "print(\"ðŸ”¬ CLASSIFICATION MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your code here:\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models\n",
    "clf_models = {\n",
    "    # Add your models here\n",
    "}\n",
    "\n",
    "clf_results = []\n",
    "for name, model in clf_models.items():\n",
    "    # Calculate CV scores for multiple metrics\n",
    "    \n",
    "    # Store results\n",
    "    pass\n",
    "\n",
    "# Display results\n",
    "clf_results_df = pd.DataFrame(clf_results)\n",
    "print(\"\\n\" + clf_results_df.to_string(index=False))\n",
    "print(\"\\nâœ… Task 3.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Tune Best Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.2: Use GridSearchCV to tune your best performing model\n",
    "# Choose the model with best F1 score from Task 3.1\n",
    "# Requirements:\n",
    "#   1. Define comprehensive parameter grid\n",
    "#   2. Use GridSearchCV with stratified CV\n",
    "#   3. Find optimal parameters\n",
    "#   4. Evaluate on test set\n",
    "\n",
    "print(\"ðŸ”§ HYPERPARAMETER TUNING - CLASSIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your code here:\n",
    "# Choose your best model and define param_grid\n",
    "\n",
    "\n",
    "# GridSearchCV\n",
    "\n",
    "\n",
    "# Results\n",
    "print(f\"\\nBest parameters: {grid_clf.best_params_}\")\n",
    "print(f\"Best CV F1: {grid_clf.best_score_:.4f}\")\n",
    "\n",
    "# Test set evaluation\n",
    "best_clf_model = grid_clf.best_estimator_\n",
    "y_pred_clf = best_clf_model.predict(X_test_clf)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_clf, y_pred_clf, target_names=['No Claim', 'Claim']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_clf, y_pred_clf)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['No Claim', 'Claim'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Best Classification Model')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Task 3.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ˆ Part 4: Regression Models\n",
    "\n",
    "**Estimated time**: 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Build and Compare Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.1: Compare multiple regression models\n",
    "# Requirements:\n",
    "#   1. Build at least 4 models:\n",
    "#      - Linear Regression (baseline)\n",
    "#      - Ridge Regression\n",
    "#      - Decision Tree Regressor\n",
    "#      - Random Forest Regressor\n",
    "#   2. Use 5-fold cross-validation\n",
    "#   3. Evaluate: RMSE, MAE, RÂ²\n",
    "#   4. Create comparison table\n",
    "\n",
    "print(\"ðŸ“Š REGRESSION MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your code here:\n",
    "# Note: Standardize features for linear models!\n",
    "scaler = StandardScaler()\n",
    "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
    "\n",
    "reg_models = {\n",
    "    # Add your models here\n",
    "    # Use scaled data for linear models, original for trees\n",
    "}\n",
    "\n",
    "reg_results = []\n",
    "for name, (model, X_tr, X_te) in reg_models.items():\n",
    "    # Calculate CV scores\n",
    "    \n",
    "    # Train and predict\n",
    "    \n",
    "    # Calculate metrics\n",
    "    \n",
    "    # Store results\n",
    "    pass\n",
    "\n",
    "# Display results\n",
    "reg_results_df = pd.DataFrame(reg_results)\n",
    "print(\"\\n\" + reg_results_df.to_string(index=False))\n",
    "print(\"\\nâœ… Task 4.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Tune Best Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.2: Use GridSearchCV to tune your best performing model\n",
    "# Choose the model with best RÂ² from Task 4.1\n",
    "# Requirements:\n",
    "#   1. Define comprehensive parameter grid\n",
    "#   2. Use GridSearchCV\n",
    "#   3. Find optimal parameters\n",
    "#   4. Evaluate on test set\n",
    "#   5. Visualize predictions vs actuals\n",
    "\n",
    "print(\"ðŸ”§ HYPERPARAMETER TUNING - REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your code here:\n",
    "# Choose your best model and define param_grid\n",
    "\n",
    "\n",
    "# GridSearchCV\n",
    "\n",
    "\n",
    "# Results\n",
    "print(f\"\\nBest parameters: {grid_reg.best_params_}\")\n",
    "print(f\"Best CV RÂ²: {grid_reg.best_score_:.4f}\")\n",
    "\n",
    "# Test set evaluation\n",
    "best_reg_model = grid_reg.best_estimator_\n",
    "# Make predictions (use appropriate X_test based on model)\n",
    "y_pred_reg = # Your prediction\n",
    "\n",
    "# Calculate final metrics\n",
    "test_mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "test_r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"  MAE:  ${test_mae:.2f}\")\n",
    "print(f\"  RMSE: ${test_rmse:.2f}\")\n",
    "print(f\"  RÂ²:   {test_r2:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Predicted vs Actual\n",
    "axes[0].scatter(y_test_reg, y_pred_reg, alpha=0.6, s=50)\n",
    "axes[0].plot([y_test_reg.min(), y_test_reg.max()], \n",
    "             [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Claim Amount ($)', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted Claim Amount ($)', fontsize=11)\n",
    "axes[0].set_title(f'Predictions vs Actuals\\n(RÂ²={test_r2:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test_reg - y_pred_reg\n",
    "axes[1].scatter(y_pred_reg, residuals, alpha=0.6, s=50)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Claim Amount ($)', fontsize=11)\n",
    "axes[1].set_ylabel('Residuals ($)', fontsize=11)\n",
    "axes[1].set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Task 4.2 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Part 5: Final Analysis and Recommendations\n",
    "\n",
    "**Estimated time**: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.1: Analyze feature importance for both problems\n",
    "# Requirements:\n",
    "#   1. Get feature importance from tree-based models\n",
    "#   2. Or get coefficients from linear models\n",
    "#   3. Visualize top 10 features for each problem\n",
    "#   4. Interpret what drives claims and claim amounts\n",
    "\n",
    "print(\"ðŸ“Š FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your code here:\n",
    "# For classification\n",
    "\n",
    "\n",
    "# For regression\n",
    "\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insights:\")\n",
    "print(\"  Classification: Which factors most predict if someone will claim?\")\n",
    "# Your interpretation\n",
    "\n",
    "print(\"\\n  Regression: Which factors most affect claim amount?\")\n",
    "# Your interpretation\n",
    "\n",
    "print(\"\\nâœ… Task 5.1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: Final Recommendation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.2: Create final recommendation summary\n",
    "# Requirements:\n",
    "#   1. Summarize best models for both tasks\n",
    "#   2. Compare linear vs tree-based approaches\n",
    "#   3. List key business insights\n",
    "#   4. Provide deployment recommendations\n",
    "#   5. Suggest next steps\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL RECOMMENDATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Your comprehensive report here:\n",
    "print(\"\\nðŸ“‹ EXECUTIVE SUMMARY\")\n",
    "print(\"-\" * 70)\n",
    "# Summarize the business problem and your solution\n",
    "\n",
    "print(\"\\nðŸ† SELECTED MODELS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nClassification (Claim Prediction):\")\n",
    "print(f\"  Model: [Your best model]\")\n",
    "print(f\"  Test Accuracy: [Your score]\")\n",
    "print(f\"  Test F1 Score: [Your score]\")\n",
    "print(f\"  Justification: [Why this model?]\")\n",
    "\n",
    "print(\"\\nRegression (Claim Amount Prediction):\")\n",
    "print(f\"  Model: [Your best model]\")\n",
    "print(f\"  Test RÂ²: [Your score]\")\n",
    "print(f\"  Test RMSE: $[Your score]\")\n",
    "print(f\"  Justification: [Why this model?]\")\n",
    "\n",
    "print(\"\\nðŸ” LINEAR VS TREE-BASED COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "# Compare the approaches\n",
    "# Which worked better? Why?\n",
    "# Trade-offs?\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY BUSINESS INSIGHTS\")\n",
    "print(\"-\" * 70)\n",
    "# List 5-7 actionable insights from your analysis\n",
    "# Example: \"1. Smokers are 3x more likely to file claims\"\n",
    "\n",
    "print(\"\\nðŸš€ DEPLOYMENT RECOMMENDATIONS\")\n",
    "print(\"-\" * 70)\n",
    "# How should the company use these models?\n",
    "# What are the risks?\n",
    "# How to monitor performance?\n",
    "\n",
    "print(\"\\nðŸ“ˆ NEXT STEPS\")\n",
    "print(\"-\" * 70)\n",
    "# What could improve the models?\n",
    "# Additional data needed?\n",
    "# Other models to try?\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nâœ… Task 5.2 Complete!\")\n",
    "print(\"ðŸŽ‰ MINI-PROJECT COMPLETE!\")\n",
    "print(\"\\nðŸ† Outstanding work! You've demonstrated mastery of:\")\n",
    "print(\"   â€¢ Linear and tree-based modeling\")\n",
    "print(\"   â€¢ Feature engineering\")\n",
    "print(\"   â€¢ Model selection and tuning\")\n",
    "print(\"   â€¢ Business-focused analysis\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ† Mini-Project Complete!\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "âœ… **Part 1**: Comprehensive data exploration and visualization  \n",
    "âœ… **Part 2**: Feature engineering and data preparation  \n",
    "âœ… **Part 3**: Classification model development and tuning  \n",
    "âœ… **Part 4**: Regression model development and tuning  \n",
    "âœ… **Part 5**: Business insights and recommendations  \n",
    "\n",
    "### Skills Demonstrated:\n",
    "\n",
    "**Technical Skills:**\n",
    "- âœ… End-to-end ML pipeline development\n",
    "- âœ… Linear and tree-based model comparison\n",
    "- âœ… Hyperparameter tuning with GridSearchCV\n",
    "- âœ… Cross-validation for robust evaluation\n",
    "- âœ… Feature engineering and selection\n",
    "- âœ… Model interpretation and diagnostics\n",
    "\n",
    "**Business Skills:**\n",
    "- âœ… Translating business problems to ML tasks\n",
    "- âœ… Extracting actionable insights from models\n",
    "- âœ… Risk assessment and recommendations\n",
    "- âœ… Clear communication of technical results\n",
    "\n",
    "### Model Selection Framework:\n",
    "\n",
    "**When to choose Linear Models:**\n",
    "- âœ… Need interpretable coefficients\n",
    "- âœ… Linear relationships in data\n",
    "- âœ… Fast prediction required\n",
    "- âœ… Limited data available\n",
    "- âœ… Regulatory requirements for explainability\n",
    "\n",
    "**When to choose Tree-Based Models:**\n",
    "- âœ… Non-linear relationships\n",
    "- âœ… Feature interactions important\n",
    "- âœ… Mixed data types (categorical + numerical)\n",
    "- âœ… Robust to outliers needed\n",
    "- âœ… Feature importance ranking wanted\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "This type of two-stage prediction (will it happen? how much?) is common in:\n",
    "- ðŸ¥ Healthcare: Disease occurrence + treatment cost\n",
    "- ðŸ’° Finance: Default risk + recovery amount\n",
    "- ðŸª Retail: Will customer churn + lifetime value\n",
    "- ðŸš— Insurance: Accident probability + claim amount\n",
    "\n",
    "### Best Practices You Applied:\n",
    "\n",
    "1. **Data Split Before EDA** - No data leakage!\n",
    "2. **Stratified CV** - Proper evaluation for imbalanced classes\n",
    "3. **Multiple Metrics** - Single metric can be misleading\n",
    "4. **Hyperparameter Tuning** - Extract maximum performance\n",
    "5. **Feature Importance** - Understand what drives predictions\n",
    "6. **Residual Analysis** - Diagnose model weaknesses\n",
    "7. **Business Context** - Technical excellence + business value\n",
    "\n",
    "### Certificate of Completion:\n",
    "\n",
    "```\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                                                           â•‘\n",
    "â•‘              ðŸ† AI TECH INSTITUTE ðŸ†                      â•‘\n",
    "â•‘                                                           â•‘\n",
    "â•‘         Week 8 - Model Selection Mini-Project            â•‘\n",
    "â•‘                                                           â•‘\n",
    "â•‘  This certifies that you have successfully completed     â•‘\n",
    "â•‘  a comprehensive machine learning project demonstrating  â•‘\n",
    "â•‘  proficiency in linear models, tree-based models, and    â•‘\n",
    "â•‘  end-to-end ML pipeline development.                     â•‘\n",
    "â•‘                                                           â•‘\n",
    "â•‘  Skills Mastered:                                        â•‘\n",
    "â•‘  â€¢ Linear & Polynomial Regression                        â•‘\n",
    "â•‘  â€¢ Ridge & Lasso Regularization                          â•‘\n",
    "â•‘  â€¢ Decision Trees & Random Forests                       â•‘\n",
    "â•‘  â€¢ Hyperparameter Tuning                                 â•‘\n",
    "â•‘  â€¢ Model Selection & Evaluation                          â•‘\n",
    "â•‘  â€¢ Business Communication                                â•‘\n",
    "â•‘                                                           â•‘\n",
    "â•‘              Keep learning, keep growing! ðŸš€             â•‘\n",
    "â•‘                                                           â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "ðŸŽ¯ **Immediate Next Steps:**\n",
    "- Review your code and refactor for clarity\n",
    "- Try the project with different datasets\n",
    "- Experiment with ensemble methods (voting, stacking)\n",
    "- Add more advanced feature engineering\n",
    "\n",
    "ðŸš€ **Advanced Topics to Explore:**\n",
    "- Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
    "- Feature selection algorithms\n",
    "- Model calibration\n",
    "- Production deployment (Flask, FastAPI)\n",
    "- Model monitoring and maintenance\n",
    "\n",
    "ðŸ“š **Further Learning:**\n",
    "- Study ensemble methods in depth\n",
    "- Learn about AutoML frameworks\n",
    "- Explore neural networks for tabular data\n",
    "- Practice on Kaggle competitions\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing Week 8! You're now equipped with powerful modeling techniques that form the foundation of most production ML systems! ðŸŽ‰ðŸš€**\n",
    "\n",
    "**Instructor:** Amir Charkhi  \n",
    "**AI Tech Institute** | *Building Tomorrow's AI Engineers Today*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
