{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 8 - Template Notebook: Machine Learning Model Lifecycle\n",
    "**Instructor:** Amir Charkhi | **Goal:** Full ML Pipeline: From Data to Deployment\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the complete ML workflow from data loading to model evaluation\n",
    "- Learn proper data splitting to avoid data leakage\n",
    "- Compare linear and tree-based models\n",
    "- Master cross-validation and hyperparameter tuning\n",
    "- Apply best practices for model evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "**What you need to do:**  \n",
    "Import all necessary libraries for data manipulation, visualization, and machine learning.\n",
    "\n",
    "**Required imports:**\n",
    "- NumPy and Pandas for data handling\n",
    "- Matplotlib and Seaborn for visualization\n",
    "- Scikit-learn for dataset, preprocessing, models, and evaluation\n",
    "\n",
    "**üí° Hint:** Import `train_test_split`, `LinearRegression`, `DecisionTreeRegressor`, `cross_val_score`, `GridSearchCV`, and regression metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Import all necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load the Dataset\n",
    "\n",
    "**What you need to do:**  \n",
    "Load the California Housing dataset using sklearn's built-in dataset.\n",
    "\n",
    "**Theory:**  \n",
    "The California Housing dataset contains information from the 1990 census with features like median income, house age, and location. The target variable is the median house value.\n",
    "\n",
    "**üí° Hint:** Use `fetch_california_housing()` and convert to a pandas DataFrame. Set `as_frame=True` for easy handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Load the California Housing dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Initial Data Inspection\n",
    "\n",
    "**What you need to do:**  \n",
    "Perform a quick inspection of the dataset before any splitting.\n",
    "\n",
    "**Tasks:**\n",
    "- Display the first few rows\n",
    "- Check dataset shape\n",
    "- Display feature names and target variable\n",
    "- Check for missing values\n",
    "\n",
    "**üí° Hint:** Use `.head()`, `.shape`, `.info()`, and `.isnull().sum()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Inspect the dataset structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train-Validation-Test Split\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL: Split BEFORE detailed EDA to prevent data leakage!**\n",
    "\n",
    "**What you need to do:**  \n",
    "Split the data into three sets:\n",
    "- **Training set (60%)**: For model training\n",
    "- **Validation set (20%)**: For model selection and hyperparameter tuning\n",
    "- **Test set (20%)**: For final, unbiased evaluation (DO NOT TOUCH until the very end!)\n",
    "\n",
    "**Theory:**  \n",
    "The test set represents unseen data in production. It must remain completely isolated from all training decisions to give an honest estimate of model performance.\n",
    "\n",
    "**üí° Hint:** Use `train_test_split()` twice. First split into train+val (80%) and test (20%), then split train+val into train (75% of 80% = 60% total) and validation (25% of 80% = 20% total). Set `random_state=42` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Split data into train, validation, and test sets\n",
    "# Remember: Test set should be locked away!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Perform EDA ONLY on the training set to avoid data leakage!**\n",
    "\n",
    "**What you need to do:**  \n",
    "Analyze the training data to understand patterns, distributions, and relationships.\n",
    "\n",
    "**Tasks:**\n",
    "1. Display summary statistics for all features\n",
    "2. Visualize target variable distribution (histogram)\n",
    "3. Create a correlation heatmap\n",
    "4. Identify the top 3 features most correlated with the target\n",
    "5. Create scatter plots for top correlated features vs target\n",
    "6. Check for outliers using box plots\n",
    "\n",
    "**üí° Hint:** Use `.describe()`, `plt.hist()`, `sns.heatmap()`, and `sns.scatterplot()` on training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Target variable distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Correlation analysis and heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Scatter plots for top features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Baseline Model: Linear Regression\n",
    "\n",
    "**Theory:**  \n",
    "Linear Regression assumes a linear relationship between features and target. It's fast, interpretable, and serves as an excellent baseline. The model learns coefficients (weights) for each feature to minimize the sum of squared errors.\n",
    "\n",
    "**What you need to do:**  \n",
    "Train a Linear Regression model and evaluate it on the validation set.\n",
    "\n",
    "**Tasks:**\n",
    "1. Initialize the Linear Regression model\n",
    "2. Train (fit) the model on training data\n",
    "3. Make predictions on validation set\n",
    "4. Calculate and display:\n",
    "   - Mean Absolute Error (MAE)\n",
    "   - Mean Squared Error (MSE)\n",
    "   - Root Mean Squared Error (RMSE)\n",
    "   - R¬≤ Score\n",
    "\n",
    "**üí° Hint:** Use `.fit()`, `.predict()`, and metrics from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Train Linear Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Make predictions and calculate metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Cross-Validation for Linear Regression\n",
    "\n",
    "**Theory:**  \n",
    "Cross-validation provides a more robust estimate of model performance by training and evaluating the model multiple times on different subsets of data. K-Fold CV splits data into K folds, trains on K-1 folds, and validates on the remaining fold, rotating through all combinations.\n",
    "\n",
    "**What you need to do:**  \n",
    "Perform 5-fold cross-validation on the training set to get a better estimate of model performance.\n",
    "\n",
    "**Tasks:**\n",
    "1. Use `cross_val_score()` with 5 folds\n",
    "2. Calculate RMSE for each fold (use `scoring='neg_mean_squared_error'` and take square root)\n",
    "3. Display mean and standard deviation of CV scores\n",
    "\n",
    "**üí° Hint:** `cross_val_score()` returns negative MSE, so you need to negate and take the square root. Use `scoring='neg_root_mean_squared_error'` if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Perform cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Tree-Based Model: Decision Tree Regressor\n",
    "\n",
    "**Theory:**  \n",
    "Decision Trees partition the feature space into regions through recursive binary splits. They can capture non-linear relationships and interactions between features without requiring feature scaling. However, they tend to overfit if not properly regularized.\n",
    "\n",
    "**What you need to do:**  \n",
    "Train a Decision Tree Regressor and compare its performance to Linear Regression.\n",
    "\n",
    "**Tasks:**\n",
    "1. Initialize a Decision Tree Regressor with `random_state=42`\n",
    "2. Train on training data\n",
    "3. Evaluate on validation set\n",
    "4. Calculate the same metrics as Linear Regression\n",
    "5. Compare performance to Linear Regression\n",
    "\n",
    "**üí° Hint:** Without constraints, Decision Trees can perfectly memorize training data. We'll tune this in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Train Decision Tree model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Make predictions and calculate metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Cross-Validation for Decision Tree\n",
    "\n",
    "**What you need to do:**  \n",
    "Perform 5-fold cross-validation on the Decision Tree model.\n",
    "\n",
    "**üí° Hint:** If CV scores vary significantly from validation scores, the model may be overfitting. This motivates hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Perform cross-validation for Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Hyperparameter Tuning: Decision Tree\n",
    "\n",
    "**Theory:**  \n",
    "Hyperparameter tuning finds the optimal model configuration that balances bias and variance. For Decision Trees, key hyperparameters include:\n",
    "- `max_depth`: Maximum tree depth (prevents overfitting)\n",
    "- `min_samples_split`: Minimum samples required to split a node\n",
    "- `min_samples_leaf`: Minimum samples required at leaf nodes\n",
    "- `max_features`: Number of features to consider for each split\n",
    "\n",
    "**What you need to do:**  \n",
    "Use GridSearchCV to find the best hyperparameters for the Decision Tree.\n",
    "\n",
    "**Tasks:**\n",
    "1. Define a parameter grid with:\n",
    "   - `max_depth`: [3, 5, 7, 10, None]\n",
    "   - `min_samples_split`: [2, 5, 10]\n",
    "   - `min_samples_leaf`: [1, 2, 4]\n",
    "2. Use GridSearchCV with 5-fold CV\n",
    "3. Fit on training data\n",
    "4. Display best parameters and best CV score\n",
    "5. Evaluate the best model on validation set\n",
    "\n",
    "**üí° Hint:** Use `scoring='neg_mean_squared_error'` and set `n_jobs=-1` to use all CPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Define parameter grid and perform GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Display best parameters and evaluate on validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Model Comparison\n",
    "\n",
    "**What you need to do:**  \n",
    "Create a summary comparison of all models tested.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a DataFrame or table comparing:\n",
    "   - Linear Regression\n",
    "   - Decision Tree (default)\n",
    "   - Decision Tree (tuned)\n",
    "2. Include metrics: RMSE, MAE, R¬≤\n",
    "3. Identify which model performs best on validation data\n",
    "\n",
    "**üí° Hint:** Store all results in a dictionary and convert to a pandas DataFrame for clean visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Create model comparison table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Final Evaluation on Test Set\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL: This is your ONE AND ONLY test set evaluation!**\n",
    "\n",
    "**Theory:**  \n",
    "The test set provides an unbiased estimate of how your model will perform on completely unseen data in production. This is your final report card. If you used the test set during development, this number would be artificially optimistic.\n",
    "\n",
    "**What you need to do:**  \n",
    "Evaluate your best model (from validation performance) on the held-out test set.\n",
    "\n",
    "**Tasks:**\n",
    "1. Select your best model based on validation performance\n",
    "2. Make predictions on the test set\n",
    "3. Calculate final metrics: RMSE, MAE, R¬≤\n",
    "4. Compare test set performance to validation performance\n",
    "5. Create a scatter plot: Actual vs Predicted values\n",
    "6. Display residuals distribution\n",
    "\n",
    "**üí° Hint:** If test performance is significantly worse than validation, your model may have overfit to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Final evaluation on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Visualize predictions vs actual values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Analyze residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Key Takeaways & Next Steps\n",
    "\n",
    "**What you should have learned:**\n",
    "1. ‚úÖ Proper data splitting prevents data leakage\n",
    "2. ‚úÖ EDA helps understand data before modeling\n",
    "3. ‚úÖ Start with simple baselines (Linear Regression)\n",
    "4. ‚úÖ Cross-validation provides robust performance estimates\n",
    "5. ‚úÖ Hyperparameter tuning improves model performance\n",
    "6. ‚úÖ Test set evaluation gives final, unbiased performance\n",
    "\n",
    "**Reflection Questions:**\n",
    "- Which model performed better and why?\n",
    "- How did hyperparameter tuning affect Decision Tree performance?\n",
    "- What's the difference between validation and test set performance?\n",
    "- Which features were most important for prediction?\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Extension Activities\n",
    "\n",
    "**This notebook structure is ready for plug-and-play with other models!**\n",
    "\n",
    "Try replacing the Decision Tree with:\n",
    "- **Random Forest Regressor** (ensemble of trees)\n",
    "- **Gradient Boosting Regressor** (sequential boosting)\n",
    "- **XGBoost Regressor** (optimized gradient boosting)\n",
    "- **LightGBM Regressor** (fast gradient boosting)\n",
    "- **Support Vector Regressor** (SVR)\n",
    "\n",
    "For each new model:\n",
    "1. Follow the same workflow (sections 8-10)\n",
    "2. Use appropriate hyperparameters for that model\n",
    "3. Compare results in section 11\n",
    "4. Update final evaluation if it becomes the best model\n",
    "\n",
    "---\n",
    "\n",
    "**AI Tech Institute** | *Building Tomorrow's AI Engineers Today*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
