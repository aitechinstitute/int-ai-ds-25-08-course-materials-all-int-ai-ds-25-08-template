{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Dimensionality Reduction - Visualizing High-Dimensional Data\n",
    "**Instructor:** Amir Charkhi | **Dataset:** MNIST Handwritten Digits\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "**Theory:**\n",
    "- The curse of dimensionality\n",
    "- Principal Component Analysis (PCA)\n",
    "- t-SNE for visualization\n",
    "- Manifold learning (Isomap, LLE)\n",
    "- When to use each method\n",
    "\n",
    "**Practice:**\n",
    "- Reduce 784 dimensions to 2D\n",
    "- Interactive Plotly visualizations\n",
    "- Compare all methods\n",
    "- Real-world applications\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory: The Curse of Dimensionality\n",
    "\n",
    "### ‚ùì What is the Problem?\n",
    "\n",
    "**Imagine you have data with 784 features...**\n",
    "```\n",
    "Each image = 28√ó28 pixels = 784 dimensions\n",
    "\n",
    "Problem:\n",
    "- Can't visualize 784 dimensions!\n",
    "- Models become slow\n",
    "- Need huge amounts of data\n",
    "- Distance metrics break down\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Why Does This Happen?\n",
    "\n",
    "**The Volume Problem:**\n",
    "```\n",
    "1D: Line of length 10\n",
    "    Volume = 10\n",
    "\n",
    "2D: Square 10√ó10\n",
    "    Volume = 100\n",
    "\n",
    "3D: Cube 10√ó10√ó10\n",
    "    Volume = 1,000\n",
    "\n",
    "784D: Hypercube 10^784\n",
    "    Volume = ASTRONOMICAL!\n",
    "\n",
    "Result: Data becomes extremely sparse\n",
    "```\n",
    "\n",
    "**The Distance Problem:**\n",
    "```\n",
    "In high dimensions:\n",
    "- All points seem equally far\n",
    "- Near and far become meaningless\n",
    "- Clustering becomes difficult\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí° The Solution: Dimensionality Reduction\n",
    "\n",
    "**Goal: Compress information**\n",
    "```\n",
    "784 dimensions ‚Üí 2 or 3 dimensions\n",
    "\n",
    "While preserving:\n",
    "- Important patterns\n",
    "- Relationships\n",
    "- Structure\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Visualize data\n",
    "- ‚úÖ Faster training\n",
    "- ‚úÖ Remove noise\n",
    "- ‚úÖ Better performance\n",
    "- ‚úÖ Easier interpretation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly for visualizations\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction methods\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Load MNIST Digits Dataset\n",
    "\n",
    "**Dataset:** Handwritten digits (0-9)\n",
    "- 8√ó8 pixel images = 64 features\n",
    "- 1,797 samples\n",
    "- Perfect for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "print(f\"üìä Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the images look like?\n",
    "print(f\"Feature range: {X.min():.1f} to {X.max():.1f}\")\n",
    "print(f\"Labels: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 10 digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {y[i]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features (important for distance-based methods!)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"‚úÖ Data scaled (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset for faster computation (optional)\n",
    "n_samples = 1000  # Use 1000 samples\n",
    "indices = np.random.choice(len(X_scaled), n_samples, replace=False)\n",
    "X_subset = X_scaled[indices]\n",
    "y_subset = y[indices]\n",
    "\n",
    "print(f\"‚úÖ Working with {n_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Method 1: PCA (Principal Component Analysis)\n",
    "\n",
    "### üìñ Theory: How PCA Works\n",
    "\n",
    "**Goal:** Find directions of maximum variance\n",
    "\n",
    "**The Idea:**\n",
    "```\n",
    "Imagine a 3D cloud of points:\n",
    "\n",
    "      ‚óè\n",
    "    ‚óè ‚óè ‚óè\n",
    "  ‚óè ‚óè ‚óè ‚óè ‚óè\n",
    "    ‚óè ‚óè ‚óè\n",
    "      ‚óè\n",
    "\n",
    "PCA finds:\n",
    "PC1: Direction with most spread ‚Üí\n",
    "PC2: Second most spread (perpendicular) ‚Üë\n",
    "PC3: Third most spread (perpendicular to both)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ What Are Principal Components?\n",
    "\n",
    "**Principal Components = New axes**\n",
    "```\n",
    "PC1: Captures most variance\n",
    "PC2: Captures second most\n",
    "PC3: Captures third most\n",
    "...\n",
    "\n",
    "Together: Capture total variance\n",
    "```\n",
    "\n",
    "**Key Properties:**\n",
    "- Perpendicular (orthogonal)\n",
    "- Ordered by importance\n",
    "- Linear combinations of original features\n",
    "\n",
    "---\n",
    "\n",
    "### üí™ PCA Advantages\n",
    "\n",
    "‚úÖ **Fast** - Linear algebra only\n",
    "\n",
    "‚úÖ **Interpretable** - Can see which features matter\n",
    "\n",
    "‚úÖ **Scalable** - Works on large datasets\n",
    "\n",
    "‚úÖ **Removes correlation** - New features independent\n",
    "\n",
    "‚ùå **Linear only** - Can't capture complex patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA model (reduce to 2D)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "\n",
    "print(\"‚úÖ PCA model created (2 components)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform\n",
    "X_pca = pca.fit_transform(X_subset)\n",
    "\n",
    "print(f\"‚úÖ Reduced from {X_subset.shape[1]}D to {X_pca.shape[1]}D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much variance captured?\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "\n",
    "print(f\"PC1 captures: {variance_explained[0]:.1%} of variance\")\n",
    "print(f\"PC2 captures: {variance_explained[1]:.1%} of variance\")\n",
    "print(f\"Total: {variance_explained.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualize PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for plotting\n",
    "df_pca = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Digit': y_subset.astype(str)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive PCA plot\n",
    "fig = px.scatter(\n",
    "    df_pca,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='Digit',\n",
    "    title=f'PCA: 64D ‚Üí 2D ({variance_explained.sum():.1%} variance preserved)',\n",
    "    labels={'PC1': f'PC1 ({variance_explained[0]:.1%})', \n",
    "            'PC2': f'PC2 ({variance_explained[1]:.1%})'},\n",
    "    template='plotly_white',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Interpretation:**\n",
    "- Similar digits cluster together\n",
    "- Linear projection - some overlap\n",
    "- Notice smooth transitions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà Scree Plot: How Many Components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA with all components\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_subset)\n",
    "\n",
    "print(\"‚úÖ Full PCA computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative variance\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Find number of components for 95% variance\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Components needed for 95% variance: {n_components_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scree plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Individual variance\n",
    "fig.add_trace(go.Bar(\n",
    "    x=list(range(1, 21)),\n",
    "    y=pca_full.explained_variance_ratio_[:20],\n",
    "    name='Individual',\n",
    "    marker_color='lightblue'\n",
    "))\n",
    "\n",
    "# Cumulative variance\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, 21)),\n",
    "    y=cumulative_variance[:20],\n",
    "    name='Cumulative',\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='red', width=3),\n",
    "    marker=dict(size=8),\n",
    "    yaxis='y2'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Scree Plot: Variance Explained by Component',\n",
    "    xaxis_title='Principal Component',\n",
    "    yaxis_title='Variance Explained',\n",
    "    yaxis2=dict(title='Cumulative Variance', overlaying='y', side='right', range=[0, 1]),\n",
    "    template='plotly_white',\n",
    "    width=900,\n",
    "    height=500,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **How to use:**\n",
    "- Look for \"elbow\" in the curve\n",
    "- Or choose components to reach target variance (e.g., 95%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 2: t-SNE\n",
    "\n",
    "### üìñ Theory: t-Distributed Stochastic Neighbor Embedding\n",
    "\n",
    "**Goal:** Preserve local structure (keep similar points close)\n",
    "\n",
    "**The Idea:**\n",
    "```\n",
    "High-dimensional space:    Low-dimensional space:\n",
    "    A‚îÄB                        A‚îÄB\n",
    "    ‚îÇ ‚îÇ                        ‚îÇ ‚îÇ  \n",
    "    C D                        C D\n",
    "    ‚Üì ‚Üì                        (same relationships!)\n",
    "    E F\n",
    "\n",
    "Keep neighbors together\n",
    "Distant points can move\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ How t-SNE Works\n",
    "\n",
    "**Step 1:** Measure similarity in high-D\n",
    "```\n",
    "\"How similar is point A to point B?\"\n",
    "Use Gaussian distribution\n",
    "```\n",
    "\n",
    "**Step 2:** Create random low-D layout\n",
    "```\n",
    "Start with random positions\n",
    "```\n",
    "\n",
    "**Step 3:** Iteratively adjust\n",
    "```\n",
    "Move points to preserve similarities\n",
    "Minimize difference between high-D and low-D similarities\n",
    "Use gradient descent\n",
    "```\n",
    "\n",
    "**Step 4:** Use t-distribution in low-D\n",
    "```\n",
    "Heavy tails ‚Üí Better separation of clusters\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí™ t-SNE Advantages\n",
    "\n",
    "‚úÖ **Non-linear** - Captures complex patterns\n",
    "\n",
    "‚úÖ **Beautiful visualizations** - Clear clusters\n",
    "\n",
    "‚úÖ **Preserves local structure** - Neighbors stay close\n",
    "\n",
    "‚ùå **Slow** - Computationally expensive\n",
    "\n",
    "‚ùå **Non-deterministic** - Different runs give different results\n",
    "\n",
    "‚ùå **Can't transform new data** - Need to rerun\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Key Parameters\n",
    "\n",
    "**perplexity:**\n",
    "```\n",
    "\"How many neighbors to consider?\"\n",
    "Range: 5-50 (default 30)\n",
    "Larger dataset ‚Üí Higher perplexity\n",
    "```\n",
    "\n",
    "**learning_rate:**\n",
    "```\n",
    "Step size for optimization\n",
    "Range: 10-1000 (default 200)\n",
    "```\n",
    "\n",
    "**n_iter:**\n",
    "```\n",
    "Number of optimization steps\n",
    "Default: 1000\n",
    "More = better (but slower)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Apply t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create t-SNE model\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    learning_rate=200,\n",
    "    n_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ t-SNE model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform (this takes a moment...)\n",
    "print(\"üîÑ Running t-SNE (this takes ~30 seconds)...\")\n",
    "X_tsne = tsne.fit_transform(X_subset)\n",
    "\n",
    "print(\"‚úÖ t-SNE complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualize t-SNE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df_tsne = pd.DataFrame({\n",
    "    'Dim1': X_tsne[:, 0],\n",
    "    'Dim2': X_tsne[:, 1],\n",
    "    'Digit': y_subset.astype(str)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive t-SNE plot\n",
    "fig = px.scatter(\n",
    "    df_tsne,\n",
    "    x='Dim1',\n",
    "    y='Dim2',\n",
    "    color='Digit',\n",
    "    title='t-SNE: 64D ‚Üí 2D (Non-linear)',\n",
    "    labels={'Dim1': 't-SNE Dimension 1', 'Dim2': 't-SNE Dimension 2'},\n",
    "    template='plotly_white',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Notice the difference from PCA:**\n",
    "- Much clearer clusters!\n",
    "- Better separation between digits\n",
    "- Non-linear transformation preserves local structure\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method 3: Isomap (Manifold Learning)\n",
    "\n",
    "### üìñ Theory: Isometric Mapping\n",
    "\n",
    "**Goal:** Preserve geodesic distances (distances along manifold)\n",
    "\n",
    "**The Manifold Hypothesis:**\n",
    "```\n",
    "High-dimensional data often lies on\n",
    "a lower-dimensional curved surface\n",
    "(a manifold)\n",
    "\n",
    "Example: Swiss Roll\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ     ‚îÇ  \n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚Üê Unroll to 2D!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ How Isomap Works\n",
    "\n",
    "**Step 1:** Build neighborhood graph\n",
    "```\n",
    "Connect each point to K nearest neighbors\n",
    "```\n",
    "\n",
    "**Step 2:** Compute shortest paths\n",
    "```\n",
    "Find geodesic distances along graph\n",
    "(not straight-line distances!)\n",
    "```\n",
    "\n",
    "**Step 3:** Classical MDS\n",
    "```\n",
    "Create low-D embedding that preserves distances\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí™ Isomap Advantages\n",
    "\n",
    "‚úÖ **Non-linear** - Follows curved manifolds\n",
    "\n",
    "‚úÖ **Global structure** - Preserves overall geometry\n",
    "\n",
    "‚úÖ **Deterministic** - Same result every time\n",
    "\n",
    "‚ùå **Sensitive to neighbors** - K matters a lot\n",
    "\n",
    "‚ùå **Doesn't handle holes** - Needs connected manifold\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Apply Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Isomap model\n",
    "isomap = Isomap(n_components=2, n_neighbors=10)\n",
    "\n",
    "print(\"‚úÖ Isomap model created (10 neighbors)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform\n",
    "print(\"üîÑ Running Isomap...\")\n",
    "X_isomap = isomap.fit_transform(X_subset)\n",
    "\n",
    "print(\"‚úÖ Isomap complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualize Isomap Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df_isomap = pd.DataFrame({\n",
    "    'Dim1': X_isomap[:, 0],\n",
    "    'Dim2': X_isomap[:, 1],\n",
    "    'Digit': y_subset.astype(str)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Isomap plot\n",
    "fig = px.scatter(\n",
    "    df_isomap,\n",
    "    x='Dim1',\n",
    "    y='Dim2',\n",
    "    color='Digit',\n",
    "    title='Isomap: 64D ‚Üí 2D (Manifold Learning)',\n",
    "    labels={'Dim1': 'Isomap Dimension 1', 'Dim2': 'Isomap Dimension 2'},\n",
    "    template='plotly_white',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Isomap characteristics:**\n",
    "- Preserves global structure\n",
    "- Curved paths respected\n",
    "- Middle ground between PCA and t-SNE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method 4: LLE (Locally Linear Embedding)\n",
    "\n",
    "### üìñ Theory: Local Linear Structure\n",
    "\n",
    "**Goal:** Preserve local linear relationships\n",
    "\n",
    "**The Idea:**\n",
    "```\n",
    "Each point can be reconstructed from neighbors\n",
    "\n",
    "Point X = w1√óA + w2√óB + w3√óC\n",
    "          (weighted sum of neighbors)\n",
    "\n",
    "Find low-D embedding with same weights!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ How LLE Works\n",
    "\n",
    "**Step 1:** Find K nearest neighbors\n",
    "```\n",
    "For each point, identify local neighborhood\n",
    "```\n",
    "\n",
    "**Step 2:** Compute reconstruction weights\n",
    "```\n",
    "How to express point as weighted sum of neighbors?\n",
    "```\n",
    "\n",
    "**Step 3:** Find low-D embedding\n",
    "```\n",
    "Keep the same weights in lower dimensions\n",
    "Solve eigenvalue problem\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí™ LLE Advantages\n",
    "\n",
    "‚úÖ **Non-linear** - Handles curved manifolds\n",
    "\n",
    "‚úÖ **Preserves local geometry** - Neighborhood structure\n",
    "\n",
    "‚úÖ **Single optimization** - No iterations needed\n",
    "\n",
    "‚ùå **Sensitive to neighbors** - K choice critical\n",
    "\n",
    "‚ùå **Can have instabilities** - Regularization needed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Apply LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLE model\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
    "\n",
    "print(\"‚úÖ LLE model created (10 neighbors)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform\n",
    "print(\"üîÑ Running LLE...\")\n",
    "X_lle = lle.fit_transform(X_subset)\n",
    "\n",
    "print(\"‚úÖ LLE complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualize LLE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df_lle = pd.DataFrame({\n",
    "    'Dim1': X_lle[:, 0],\n",
    "    'Dim2': X_lle[:, 1],\n",
    "    'Digit': y_subset.astype(str)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive LLE plot\n",
    "fig = px.scatter(\n",
    "    df_lle,\n",
    "    x='Dim1',\n",
    "    y='Dim2',\n",
    "    color='Digit',\n",
    "    title='LLE: 64D ‚Üí 2D (Local Linear Embedding)',\n",
    "    labels={'Dim1': 'LLE Dimension 1', 'Dim2': 'LLE Dimension 2'},\n",
    "    template='plotly_white',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Compare All Methods\n",
    "\n",
    "### üìä Side-by-Side Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 subplot comparison\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('PCA (Linear)', 't-SNE (Non-linear)', \n",
    "                    'Isomap (Manifold)', 'LLE (Local Linear)'),\n",
    "    horizontal_spacing=0.1,\n",
    "    vertical_spacing=0.15\n",
    ")\n",
    "\n",
    "# PCA\n",
    "for digit in range(10):\n",
    "    mask = df_pca['Digit'] == str(digit)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_pca[mask]['PC1'],\n",
    "            y=df_pca[mask]['PC2'],\n",
    "            mode='markers',\n",
    "            name=str(digit),\n",
    "            marker=dict(size=5),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# t-SNE\n",
    "for digit in range(10):\n",
    "    mask = df_tsne['Digit'] == str(digit)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_tsne[mask]['Dim1'],\n",
    "            y=df_tsne[mask]['Dim2'],\n",
    "            mode='markers',\n",
    "            name=str(digit),\n",
    "            marker=dict(size=5),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Isomap\n",
    "for digit in range(10):\n",
    "    mask = df_isomap['Digit'] == str(digit)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_isomap[mask]['Dim1'],\n",
    "            y=df_isomap[mask]['Dim2'],\n",
    "            mode='markers',\n",
    "            name=str(digit),\n",
    "            marker=dict(size=5),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# LLE\n",
    "for digit in range(10):\n",
    "    mask = df_lle['Digit'] == str(digit)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_lle[mask]['Dim1'],\n",
    "            y=df_lle[mask]['Dim2'],\n",
    "            mode='markers',\n",
    "            name=str(digit),\n",
    "            marker=dict(size=5),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Dimensionality Reduction Methods Comparison\",\n",
    "    height=900,\n",
    "    width=1200,\n",
    "    template='plotly_white',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Notice the differences:**\n",
    "- **PCA:** Linear, some overlap\n",
    "- **t-SNE:** Best cluster separation\n",
    "- **Isomap:** Preserves global structure\n",
    "- **LLE:** Local linear relationships\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Method Comparison Table\n",
    "\n",
    "### üìã When to Use Each Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Method': ['PCA', 't-SNE', 'Isomap', 'LLE'],\n",
    "    'Type': ['Linear', 'Non-linear', 'Non-linear', 'Non-linear'],\n",
    "    'Speed': ['Fast', 'Slow', 'Medium', 'Medium'],\n",
    "    'Deterministic': ['Yes', 'No', 'Yes', 'Yes'],\n",
    "    'Preserves': ['Global variance', 'Local structure', 'Geodesic distance', 'Local linearity'],\n",
    "    'Best For': ['Quick EDA', 'Visualization', 'Manifolds', 'Local structure']\n",
    "})\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Choosing the Right Method\n",
    "\n",
    "### üéØ Decision Guide\n",
    "\n",
    "**Use PCA when:**\n",
    "```\n",
    "‚úÖ Need interpretable components\n",
    "‚úÖ Want to remove correlation\n",
    "‚úÖ Have large dataset (scalable)\n",
    "‚úÖ Need to transform new data\n",
    "‚úÖ Linear relationships sufficient\n",
    "‚úÖ Want to know variance explained\n",
    "```\n",
    "\n",
    "**Use t-SNE when:**\n",
    "```\n",
    "‚úÖ Creating visualizations only\n",
    "‚úÖ Want clear cluster separation\n",
    "‚úÖ Local structure matters most\n",
    "‚úÖ Have time for computation\n",
    "‚úÖ Don't need to transform new data\n",
    "```\n",
    "\n",
    "**Use Isomap when:**\n",
    "```\n",
    "‚úÖ Data lies on curved manifold\n",
    "‚úÖ Global structure important\n",
    "‚úÖ Need deterministic results\n",
    "‚úÖ Have well-connected data\n",
    "```\n",
    "\n",
    "**Use LLE when:**\n",
    "```\n",
    "‚úÖ Local geometry critical\n",
    "‚úÖ Data has local linear structure\n",
    "‚úÖ Need single optimization\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üíº Real-World Workflow\n",
    "\n",
    "**Step 1:** Start with PCA\n",
    "```\n",
    "- Fast baseline\n",
    "- See variance explained\n",
    "- Understand data structure\n",
    "```\n",
    "\n",
    "**Step 2:** If PCA unsatisfactory ‚Üí Try t-SNE\n",
    "```\n",
    "- Better cluster visualization\n",
    "- Validate PCA results\n",
    "```\n",
    "\n",
    "**Step 3:** For manifold data ‚Üí Try Isomap/LLE\n",
    "```\n",
    "- When data has known structure\n",
    "- Swiss roll, S-curve, etc.\n",
    "```\n",
    "\n",
    "**Step 4:** Compare multiple methods\n",
    "```\n",
    "- Different methods reveal different aspects\n",
    "- No single \"best\" method\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Practical Applications\n",
    "\n",
    "### üåç Where Is This Used?\n",
    "\n",
    "**1. Data Visualization**\n",
    "```\n",
    "Problem: 1000-dimensional data\n",
    "Solution: Reduce to 2D/3D for plotting\n",
    "Example: Gene expression analysis\n",
    "```\n",
    "\n",
    "**2. Feature Engineering**\n",
    "```\n",
    "Problem: Too many correlated features\n",
    "Solution: PCA to create independent components\n",
    "Example: Image preprocessing\n",
    "```\n",
    "\n",
    "**3. Noise Reduction**\n",
    "```\n",
    "Problem: Noisy measurements\n",
    "Solution: Keep only top principal components\n",
    "Example: Signal processing\n",
    "```\n",
    "\n",
    "**4. Preprocessing for ML**\n",
    "```\n",
    "Problem: Curse of dimensionality\n",
    "Solution: Reduce dimensions before training\n",
    "Example: Text classification (TF-IDF ‚Üí PCA)\n",
    "```\n",
    "\n",
    "**5. Anomaly Detection**\n",
    "```\n",
    "Problem: Outliers in high dimensions\n",
    "Solution: Project to low-D, find outliers\n",
    "Example: Fraud detection\n",
    "```\n",
    "\n",
    "**6. Exploratory Data Analysis**\n",
    "```\n",
    "Problem: Understanding data structure\n",
    "Solution: Visualize in 2D/3D\n",
    "Example: Customer segmentation\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways\n",
    "\n",
    "### ‚úÖ What We Learned\n",
    "\n",
    "**1. The Curse of Dimensionality:**\n",
    "- High dimensions ‚Üí Sparse data\n",
    "- Distance metrics break down\n",
    "- Need massive amounts of data\n",
    "- Solution: Dimensionality reduction\n",
    "\n",
    "**2. Four Key Methods:**\n",
    "\n",
    "**PCA (Principal Component Analysis):**\n",
    "- Linear transformation\n",
    "- Finds directions of maximum variance\n",
    "- Fast and interpretable\n",
    "- Good for initial exploration\n",
    "\n",
    "**t-SNE (t-Distributed Stochastic Neighbor Embedding):**\n",
    "- Non-linear, preserves local structure\n",
    "- Beautiful cluster visualizations\n",
    "- Slow, non-deterministic\n",
    "- Best for visualization only\n",
    "\n",
    "**Isomap (Isometric Mapping):**\n",
    "- Non-linear, preserves geodesic distances\n",
    "- Good for manifold data\n",
    "- Deterministic, moderate speed\n",
    "- Preserves global structure\n",
    "\n",
    "**LLE (Locally Linear Embedding):**\n",
    "- Non-linear, preserves local linearity\n",
    "- Single optimization step\n",
    "- Good for locally linear manifolds\n",
    "\n",
    "**3. Choosing Method:**\n",
    "- Start with PCA (fast baseline)\n",
    "- Use t-SNE for visualization\n",
    "- Try Isomap/LLE for manifolds\n",
    "- Compare multiple methods\n",
    "\n",
    "**4. Practical Tips:**\n",
    "- Always scale features first\n",
    "- PCA for features, t-SNE for visualization\n",
    "- No single \"best\" method\n",
    "- Domain knowledge crucial\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Best Practices\n",
    "\n",
    "**Always:**\n",
    "- ‚úÖ Scale features (StandardScaler)\n",
    "- ‚úÖ Try PCA first\n",
    "- ‚úÖ Visualize results\n",
    "- ‚úÖ Check explained variance (PCA)\n",
    "- ‚úÖ Tune hyperparameters\n",
    "\n",
    "**Never:**\n",
    "- ‚ùå Skip scaling\n",
    "- ‚ùå Use t-SNE for feature engineering\n",
    "- ‚ùå Trust one method only\n",
    "- ‚ùå Ignore original features\n",
    "- ‚ùå Over-interpret distances in t-SNE\n",
    "\n",
    "**Remember:**\n",
    "```\n",
    "PCA = Fast exploration\n",
    "t-SNE = Beautiful plots\n",
    "Isomap/LLE = Manifold data\n",
    "\n",
    "Different methods = Different insights!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You can now visualize high-dimensional data!** üéâ\n",
    "\n",
    "**Next Steps:**\n",
    "- Apply to your own data\n",
    "- Try different parameters\n",
    "- Combine with clustering\n",
    "- Explore UMAP (modern alternative)\n",
    "\n",
    "---\n",
    "\n",
    "**AI Tech Institute** | *Building Tomorrow's AI Engineers Today*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
